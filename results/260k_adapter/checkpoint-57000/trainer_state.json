{
  "best_global_step": 56000,
  "best_metric": 1.3063772916793823,
  "best_model_checkpoint": "./results/output/checkpoint-56000",
  "epoch": 2.6307360356306324,
  "eval_steps": 1000,
  "global_step": 57000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0023076834319868,
      "grad_norm": 3.234070301055908,
      "learning_rate": 4.7e-06,
      "loss": 2.7128,
      "step": 50
    },
    {
      "epoch": 0.0046153668639736,
      "grad_norm": 1.803808569908142,
      "learning_rate": 9.7e-06,
      "loss": 1.9984,
      "step": 100
    },
    {
      "epoch": 0.0069230502959604,
      "grad_norm": 1.185814380645752,
      "learning_rate": 9.999987060052761e-06,
      "loss": 1.5177,
      "step": 150
    },
    {
      "epoch": 0.0092307337279472,
      "grad_norm": 1.1732913255691528,
      "learning_rate": 9.999944883751735e-06,
      "loss": 1.5309,
      "step": 200
    },
    {
      "epoch": 0.011538417159934,
      "grad_norm": 1.0128954648971558,
      "learning_rate": 9.999873418623491e-06,
      "loss": 1.5033,
      "step": 250
    },
    {
      "epoch": 0.0138461005919208,
      "grad_norm": 0.9635249376296997,
      "learning_rate": 9.99977266508666e-06,
      "loss": 1.4592,
      "step": 300
    },
    {
      "epoch": 0.0161537840239076,
      "grad_norm": 1.2935932874679565,
      "learning_rate": 9.999642623731437e-06,
      "loss": 1.4804,
      "step": 350
    },
    {
      "epoch": 0.0184614674558944,
      "grad_norm": 0.9319048523902893,
      "learning_rate": 9.999483295319584e-06,
      "loss": 1.4481,
      "step": 400
    },
    {
      "epoch": 0.0207691508878812,
      "grad_norm": 1.2098811864852905,
      "learning_rate": 9.99929468078442e-06,
      "loss": 1.4476,
      "step": 450
    },
    {
      "epoch": 0.023076834319868,
      "grad_norm": 0.9458542466163635,
      "learning_rate": 9.999076781230813e-06,
      "loss": 1.464,
      "step": 500
    },
    {
      "epoch": 0.0253845177518548,
      "grad_norm": 1.1508913040161133,
      "learning_rate": 9.998829597935187e-06,
      "loss": 1.4152,
      "step": 550
    },
    {
      "epoch": 0.0276922011838416,
      "grad_norm": 1.1195052862167358,
      "learning_rate": 9.998553132345496e-06,
      "loss": 1.4352,
      "step": 600
    },
    {
      "epoch": 0.0299998846158284,
      "grad_norm": 1.4136531352996826,
      "learning_rate": 9.99824738608123e-06,
      "loss": 1.4686,
      "step": 650
    },
    {
      "epoch": 0.0323075680478152,
      "grad_norm": 1.3209282159805298,
      "learning_rate": 9.997912360933398e-06,
      "loss": 1.4112,
      "step": 700
    },
    {
      "epoch": 0.034615251479802,
      "grad_norm": 1.325654149055481,
      "learning_rate": 9.99754805886452e-06,
      "loss": 1.4074,
      "step": 750
    },
    {
      "epoch": 0.0369229349117888,
      "grad_norm": 0.9531615972518921,
      "learning_rate": 9.997154482008617e-06,
      "loss": 1.4206,
      "step": 800
    },
    {
      "epoch": 0.0392306183437756,
      "grad_norm": 1.0985593795776367,
      "learning_rate": 9.996731632671196e-06,
      "loss": 1.4087,
      "step": 850
    },
    {
      "epoch": 0.0415383017757624,
      "grad_norm": 0.97088623046875,
      "learning_rate": 9.996279513329232e-06,
      "loss": 1.433,
      "step": 900
    },
    {
      "epoch": 0.043845985207749204,
      "grad_norm": 1.0757375955581665,
      "learning_rate": 9.995798126631166e-06,
      "loss": 1.4161,
      "step": 950
    },
    {
      "epoch": 0.046153668639736,
      "grad_norm": 1.1121803522109985,
      "learning_rate": 9.995287475396883e-06,
      "loss": 1.3952,
      "step": 1000
    },
    {
      "epoch": 0.046153668639736,
      "eval_loss": 1.4266554117202759,
      "eval_runtime": 183.5883,
      "eval_samples_per_second": 27.235,
      "eval_steps_per_second": 1.138,
      "step": 1000
    },
    {
      "epoch": 0.0484613520717228,
      "grad_norm": 1.230531096458435,
      "learning_rate": 9.994747562617686e-06,
      "loss": 1.364,
      "step": 1050
    },
    {
      "epoch": 0.0507690355037096,
      "grad_norm": 1.0545494556427002,
      "learning_rate": 9.994178391456295e-06,
      "loss": 1.4094,
      "step": 1100
    },
    {
      "epoch": 0.053076718935696404,
      "grad_norm": 1.0936639308929443,
      "learning_rate": 9.993579965246816e-06,
      "loss": 1.4264,
      "step": 1150
    },
    {
      "epoch": 0.0553844023676832,
      "grad_norm": 1.2801318168640137,
      "learning_rate": 9.99295228749473e-06,
      "loss": 1.4113,
      "step": 1200
    },
    {
      "epoch": 0.05769208579967,
      "grad_norm": 1.0804117918014526,
      "learning_rate": 9.992295361876865e-06,
      "loss": 1.4042,
      "step": 1250
    },
    {
      "epoch": 0.0599997692316568,
      "grad_norm": 0.9686274528503418,
      "learning_rate": 9.99160919224138e-06,
      "loss": 1.4135,
      "step": 1300
    },
    {
      "epoch": 0.062307452663643605,
      "grad_norm": 1.0597426891326904,
      "learning_rate": 9.990893782607742e-06,
      "loss": 1.4013,
      "step": 1350
    },
    {
      "epoch": 0.0646151360956304,
      "grad_norm": 1.1714166402816772,
      "learning_rate": 9.990149137166696e-06,
      "loss": 1.4446,
      "step": 1400
    },
    {
      "epoch": 0.06692281952761721,
      "grad_norm": 0.9853427410125732,
      "learning_rate": 9.989375260280251e-06,
      "loss": 1.4196,
      "step": 1450
    },
    {
      "epoch": 0.069230502959604,
      "grad_norm": 1.3195018768310547,
      "learning_rate": 9.988572156481644e-06,
      "loss": 1.4196,
      "step": 1500
    },
    {
      "epoch": 0.0715381863915908,
      "grad_norm": 1.314433217048645,
      "learning_rate": 9.987739830475323e-06,
      "loss": 1.3807,
      "step": 1550
    },
    {
      "epoch": 0.0738458698235776,
      "grad_norm": 1.0599256753921509,
      "learning_rate": 9.986878287136909e-06,
      "loss": 1.4288,
      "step": 1600
    },
    {
      "epoch": 0.0761535532555644,
      "grad_norm": 1.3608887195587158,
      "learning_rate": 9.98598753151318e-06,
      "loss": 1.372,
      "step": 1650
    },
    {
      "epoch": 0.0784612366875512,
      "grad_norm": 1.1401894092559814,
      "learning_rate": 9.985067568822028e-06,
      "loss": 1.4289,
      "step": 1700
    },
    {
      "epoch": 0.080768920119538,
      "grad_norm": 1.1807911396026611,
      "learning_rate": 9.98411840445244e-06,
      "loss": 1.4145,
      "step": 1750
    },
    {
      "epoch": 0.0830766035515248,
      "grad_norm": 1.1952358484268188,
      "learning_rate": 9.98314004396446e-06,
      "loss": 1.3852,
      "step": 1800
    },
    {
      "epoch": 0.0853842869835116,
      "grad_norm": 1.017669439315796,
      "learning_rate": 9.982132493089152e-06,
      "loss": 1.4089,
      "step": 1850
    },
    {
      "epoch": 0.08769197041549841,
      "grad_norm": 1.3019542694091797,
      "learning_rate": 9.981095757728586e-06,
      "loss": 1.4239,
      "step": 1900
    },
    {
      "epoch": 0.0899996538474852,
      "grad_norm": 1.105987787246704,
      "learning_rate": 9.980029843955777e-06,
      "loss": 1.4363,
      "step": 1950
    },
    {
      "epoch": 0.092307337279472,
      "grad_norm": 1.2253038883209229,
      "learning_rate": 9.978934758014667e-06,
      "loss": 1.4083,
      "step": 2000
    },
    {
      "epoch": 0.092307337279472,
      "eval_loss": 1.3999137878417969,
      "eval_runtime": 178.4021,
      "eval_samples_per_second": 28.027,
      "eval_steps_per_second": 1.172,
      "step": 2000
    },
    {
      "epoch": 0.0946150207114588,
      "grad_norm": 1.37126624584198,
      "learning_rate": 9.977810506320084e-06,
      "loss": 1.4233,
      "step": 2050
    },
    {
      "epoch": 0.0969227041434456,
      "grad_norm": 1.2563042640686035,
      "learning_rate": 9.976657095457702e-06,
      "loss": 1.4098,
      "step": 2100
    },
    {
      "epoch": 0.0992303875754324,
      "grad_norm": 1.2131456136703491,
      "learning_rate": 9.975474532184008e-06,
      "loss": 1.4131,
      "step": 2150
    },
    {
      "epoch": 0.1015380710074192,
      "grad_norm": 0.9997296333312988,
      "learning_rate": 9.974262823426256e-06,
      "loss": 1.3923,
      "step": 2200
    },
    {
      "epoch": 0.103845754439406,
      "grad_norm": 1.4654428958892822,
      "learning_rate": 9.973021976282426e-06,
      "loss": 1.3666,
      "step": 2250
    },
    {
      "epoch": 0.10615343787139281,
      "grad_norm": 1.2952613830566406,
      "learning_rate": 9.971751998021196e-06,
      "loss": 1.4195,
      "step": 2300
    },
    {
      "epoch": 0.1084611213033796,
      "grad_norm": 1.2366816997528076,
      "learning_rate": 9.970452896081878e-06,
      "loss": 1.4043,
      "step": 2350
    },
    {
      "epoch": 0.1107688047353664,
      "grad_norm": 1.4446766376495361,
      "learning_rate": 9.969124678074394e-06,
      "loss": 1.4059,
      "step": 2400
    },
    {
      "epoch": 0.1130764881673532,
      "grad_norm": 1.1339999437332153,
      "learning_rate": 9.967767351779215e-06,
      "loss": 1.3928,
      "step": 2450
    },
    {
      "epoch": 0.11538417159934,
      "grad_norm": 1.231937050819397,
      "learning_rate": 9.96638092514733e-06,
      "loss": 1.4294,
      "step": 2500
    },
    {
      "epoch": 0.1176918550313268,
      "grad_norm": 0.9418694376945496,
      "learning_rate": 9.964965406300191e-06,
      "loss": 1.3899,
      "step": 2550
    },
    {
      "epoch": 0.1199995384633136,
      "grad_norm": 1.3084807395935059,
      "learning_rate": 9.963520803529669e-06,
      "loss": 1.3939,
      "step": 2600
    },
    {
      "epoch": 0.1223072218953004,
      "grad_norm": 1.187669038772583,
      "learning_rate": 9.962047125297995e-06,
      "loss": 1.3726,
      "step": 2650
    },
    {
      "epoch": 0.12461490532728721,
      "grad_norm": 1.2251622676849365,
      "learning_rate": 9.960544380237733e-06,
      "loss": 1.4191,
      "step": 2700
    },
    {
      "epoch": 0.126922588759274,
      "grad_norm": 1.2395092248916626,
      "learning_rate": 9.959043497924318e-06,
      "loss": 1.3833,
      "step": 2750
    },
    {
      "epoch": 0.1292302721912608,
      "grad_norm": 1.1666330099105835,
      "learning_rate": 9.957483226677583e-06,
      "loss": 1.3938,
      "step": 2800
    },
    {
      "epoch": 0.1315379556232476,
      "grad_norm": 1.6935616731643677,
      "learning_rate": 9.955893915336796e-06,
      "loss": 1.3768,
      "step": 2850
    },
    {
      "epoch": 0.13384563905523442,
      "grad_norm": 1.2206794023513794,
      "learning_rate": 9.954275573211878e-06,
      "loss": 1.4052,
      "step": 2900
    },
    {
      "epoch": 0.1361533224872212,
      "grad_norm": 1.1947776079177856,
      "learning_rate": 9.952628209782797e-06,
      "loss": 1.3868,
      "step": 2950
    },
    {
      "epoch": 0.138461005919208,
      "grad_norm": 1.5884712934494019,
      "learning_rate": 9.950951834699532e-06,
      "loss": 1.3989,
      "step": 3000
    },
    {
      "epoch": 0.138461005919208,
      "eval_loss": 1.3870929479599,
      "eval_runtime": 178.4755,
      "eval_samples_per_second": 28.015,
      "eval_steps_per_second": 1.171,
      "step": 3000
    },
    {
      "epoch": 0.1407686893511948,
      "grad_norm": 1.354844093322754,
      "learning_rate": 9.949246457782003e-06,
      "loss": 1.4001,
      "step": 3050
    },
    {
      "epoch": 0.1430763727831816,
      "grad_norm": 1.1765773296356201,
      "learning_rate": 9.947512089020014e-06,
      "loss": 1.3649,
      "step": 3100
    },
    {
      "epoch": 0.1453840562151684,
      "grad_norm": 1.1801015138626099,
      "learning_rate": 9.945748738573206e-06,
      "loss": 1.3866,
      "step": 3150
    },
    {
      "epoch": 0.1476917396471552,
      "grad_norm": 1.680984616279602,
      "learning_rate": 9.943956416770987e-06,
      "loss": 1.377,
      "step": 3200
    },
    {
      "epoch": 0.149999423079142,
      "grad_norm": 1.4463222026824951,
      "learning_rate": 9.94213513411247e-06,
      "loss": 1.3594,
      "step": 3250
    },
    {
      "epoch": 0.1523071065111288,
      "grad_norm": 1.2378607988357544,
      "learning_rate": 9.940284901266422e-06,
      "loss": 1.3786,
      "step": 3300
    },
    {
      "epoch": 0.15461478994311562,
      "grad_norm": 1.2128461599349976,
      "learning_rate": 9.938405729071192e-06,
      "loss": 1.3976,
      "step": 3350
    },
    {
      "epoch": 0.1569224733751024,
      "grad_norm": 1.3348947763442993,
      "learning_rate": 9.93649762853465e-06,
      "loss": 1.4038,
      "step": 3400
    },
    {
      "epoch": 0.1592301568070892,
      "grad_norm": 1.1455196142196655,
      "learning_rate": 9.934560610834126e-06,
      "loss": 1.4103,
      "step": 3450
    },
    {
      "epoch": 0.161537840239076,
      "grad_norm": 1.3384920358657837,
      "learning_rate": 9.93259468731634e-06,
      "loss": 1.3464,
      "step": 3500
    },
    {
      "epoch": 0.1638455236710628,
      "grad_norm": 1.3076852560043335,
      "learning_rate": 9.930599869497337e-06,
      "loss": 1.3428,
      "step": 3550
    },
    {
      "epoch": 0.1661532071030496,
      "grad_norm": 1.3590813875198364,
      "learning_rate": 9.928576169062422e-06,
      "loss": 1.3962,
      "step": 3600
    },
    {
      "epoch": 0.1684608905350364,
      "grad_norm": 1.1356443166732788,
      "learning_rate": 9.926523597866088e-06,
      "loss": 1.3988,
      "step": 3650
    },
    {
      "epoch": 0.1707685739670232,
      "grad_norm": 1.2136253118515015,
      "learning_rate": 9.924442167931947e-06,
      "loss": 1.3752,
      "step": 3700
    },
    {
      "epoch": 0.17307625739901,
      "grad_norm": 1.24173903465271,
      "learning_rate": 9.922331891452662e-06,
      "loss": 1.4051,
      "step": 3750
    },
    {
      "epoch": 0.17538394083099682,
      "grad_norm": 1.1268192529678345,
      "learning_rate": 9.920192780789875e-06,
      "loss": 1.4034,
      "step": 3800
    },
    {
      "epoch": 0.1776916242629836,
      "grad_norm": 1.4889854192733765,
      "learning_rate": 9.918024848474133e-06,
      "loss": 1.3583,
      "step": 3850
    },
    {
      "epoch": 0.1799993076949704,
      "grad_norm": 1.4490572214126587,
      "learning_rate": 9.915828107204812e-06,
      "loss": 1.3918,
      "step": 3900
    },
    {
      "epoch": 0.1823069911269572,
      "grad_norm": 1.299573540687561,
      "learning_rate": 9.913602569850052e-06,
      "loss": 1.3809,
      "step": 3950
    },
    {
      "epoch": 0.184614674558944,
      "grad_norm": 1.1006134748458862,
      "learning_rate": 9.91134824944667e-06,
      "loss": 1.4005,
      "step": 4000
    },
    {
      "epoch": 0.184614674558944,
      "eval_loss": 1.3781589269638062,
      "eval_runtime": 178.243,
      "eval_samples_per_second": 28.052,
      "eval_steps_per_second": 1.173,
      "step": 4000
    },
    {
      "epoch": 0.1869223579909308,
      "grad_norm": 1.521079659461975,
      "learning_rate": 9.909065159200095e-06,
      "loss": 1.3297,
      "step": 4050
    },
    {
      "epoch": 0.1892300414229176,
      "grad_norm": 1.354052186012268,
      "learning_rate": 9.90675331248428e-06,
      "loss": 1.4013,
      "step": 4100
    },
    {
      "epoch": 0.19153772485490442,
      "grad_norm": 1.0919792652130127,
      "learning_rate": 9.90441272284163e-06,
      "loss": 1.3962,
      "step": 4150
    },
    {
      "epoch": 0.1938454082868912,
      "grad_norm": 1.2446045875549316,
      "learning_rate": 9.90204340398292e-06,
      "loss": 1.3906,
      "step": 4200
    },
    {
      "epoch": 0.19615309171887801,
      "grad_norm": 1.2204394340515137,
      "learning_rate": 9.899645369787218e-06,
      "loss": 1.3781,
      "step": 4250
    },
    {
      "epoch": 0.1984607751508648,
      "grad_norm": 1.2081555128097534,
      "learning_rate": 9.897218634301802e-06,
      "loss": 1.362,
      "step": 4300
    },
    {
      "epoch": 0.2007684585828516,
      "grad_norm": 1.366284728050232,
      "learning_rate": 9.894763211742073e-06,
      "loss": 1.3705,
      "step": 4350
    },
    {
      "epoch": 0.2030761420148384,
      "grad_norm": 1.4689913988113403,
      "learning_rate": 9.892279116491483e-06,
      "loss": 1.378,
      "step": 4400
    },
    {
      "epoch": 0.2053838254468252,
      "grad_norm": 1.130577564239502,
      "learning_rate": 9.889766363101435e-06,
      "loss": 1.3889,
      "step": 4450
    },
    {
      "epoch": 0.207691508878812,
      "grad_norm": 1.274696946144104,
      "learning_rate": 9.887224966291217e-06,
      "loss": 1.3782,
      "step": 4500
    },
    {
      "epoch": 0.2099991923107988,
      "grad_norm": 1.26731276512146,
      "learning_rate": 9.884654940947896e-06,
      "loss": 1.3854,
      "step": 4550
    },
    {
      "epoch": 0.21230687574278562,
      "grad_norm": 1.329776644706726,
      "learning_rate": 9.882056302126242e-06,
      "loss": 1.3524,
      "step": 4600
    },
    {
      "epoch": 0.2146145591747724,
      "grad_norm": 1.4293302297592163,
      "learning_rate": 9.879429065048642e-06,
      "loss": 1.3673,
      "step": 4650
    },
    {
      "epoch": 0.2169222426067592,
      "grad_norm": 1.2220356464385986,
      "learning_rate": 9.876773245105004e-06,
      "loss": 1.3608,
      "step": 4700
    },
    {
      "epoch": 0.219229926038746,
      "grad_norm": 1.3201549053192139,
      "learning_rate": 9.874088857852668e-06,
      "loss": 1.3813,
      "step": 4750
    },
    {
      "epoch": 0.2215376094707328,
      "grad_norm": 1.3053706884384155,
      "learning_rate": 9.871375919016321e-06,
      "loss": 1.3924,
      "step": 4800
    },
    {
      "epoch": 0.2238452929027196,
      "grad_norm": 1.4297142028808594,
      "learning_rate": 9.868634444487897e-06,
      "loss": 1.3255,
      "step": 4850
    },
    {
      "epoch": 0.2261529763347064,
      "grad_norm": 1.3589943647384644,
      "learning_rate": 9.865864450326486e-06,
      "loss": 1.3542,
      "step": 4900
    },
    {
      "epoch": 0.2284606597666932,
      "grad_norm": 1.2394944429397583,
      "learning_rate": 9.863065952758244e-06,
      "loss": 1.3465,
      "step": 4950
    },
    {
      "epoch": 0.23076834319868,
      "grad_norm": 1.2589763402938843,
      "learning_rate": 9.860238968176294e-06,
      "loss": 1.3988,
      "step": 5000
    },
    {
      "epoch": 0.23076834319868,
      "eval_loss": 1.3694864511489868,
      "eval_runtime": 178.5036,
      "eval_samples_per_second": 28.011,
      "eval_steps_per_second": 1.171,
      "step": 5000
    },
    {
      "epoch": 0.23307602663066682,
      "grad_norm": 1.3532823324203491,
      "learning_rate": 9.85738351314063e-06,
      "loss": 1.366,
      "step": 5050
    },
    {
      "epoch": 0.2353837100626536,
      "grad_norm": 1.283898949623108,
      "learning_rate": 9.854499604378026e-06,
      "loss": 1.3993,
      "step": 5100
    },
    {
      "epoch": 0.2376913934946404,
      "grad_norm": 1.2848609685897827,
      "learning_rate": 9.851587258781925e-06,
      "loss": 1.3527,
      "step": 5150
    },
    {
      "epoch": 0.2399990769266272,
      "grad_norm": 1.5865778923034668,
      "learning_rate": 9.848646493412353e-06,
      "loss": 1.3894,
      "step": 5200
    },
    {
      "epoch": 0.242306760358614,
      "grad_norm": 1.4455169439315796,
      "learning_rate": 9.845677325495817e-06,
      "loss": 1.3928,
      "step": 5250
    },
    {
      "epoch": 0.2446144437906008,
      "grad_norm": 1.4260966777801514,
      "learning_rate": 9.842679772425195e-06,
      "loss": 1.3702,
      "step": 5300
    },
    {
      "epoch": 0.2469221272225876,
      "grad_norm": 1.4814893007278442,
      "learning_rate": 9.839653851759643e-06,
      "loss": 1.3692,
      "step": 5350
    },
    {
      "epoch": 0.24922981065457442,
      "grad_norm": 1.3308700323104858,
      "learning_rate": 9.836660944348468e-06,
      "loss": 1.3882,
      "step": 5400
    },
    {
      "epoch": 0.25153749408656123,
      "grad_norm": 1.29794180393219,
      "learning_rate": 9.83357890829827e-06,
      "loss": 1.3738,
      "step": 5450
    },
    {
      "epoch": 0.253845177518548,
      "grad_norm": 1.4045895338058472,
      "learning_rate": 9.830468557964456e-06,
      "loss": 1.4094,
      "step": 5500
    },
    {
      "epoch": 0.2561528609505348,
      "grad_norm": 1.7498154640197754,
      "learning_rate": 9.827329911566933e-06,
      "loss": 1.3872,
      "step": 5550
    },
    {
      "epoch": 0.2584605443825216,
      "grad_norm": 1.1452780961990356,
      "learning_rate": 9.824162987491357e-06,
      "loss": 1.3707,
      "step": 5600
    },
    {
      "epoch": 0.2607682278145084,
      "grad_norm": 1.6340456008911133,
      "learning_rate": 9.820967804289028e-06,
      "loss": 1.3751,
      "step": 5650
    },
    {
      "epoch": 0.2630759112464952,
      "grad_norm": 1.6047037839889526,
      "learning_rate": 9.817744380676791e-06,
      "loss": 1.362,
      "step": 5700
    },
    {
      "epoch": 0.265383594678482,
      "grad_norm": 1.2555086612701416,
      "learning_rate": 9.814492735536912e-06,
      "loss": 1.3356,
      "step": 5750
    },
    {
      "epoch": 0.26769127811046883,
      "grad_norm": 1.6483103036880493,
      "learning_rate": 9.811212887916972e-06,
      "loss": 1.353,
      "step": 5800
    },
    {
      "epoch": 0.2699989615424556,
      "grad_norm": 1.5018279552459717,
      "learning_rate": 9.807904857029766e-06,
      "loss": 1.4009,
      "step": 5850
    },
    {
      "epoch": 0.2723066449744424,
      "grad_norm": 1.3301727771759033,
      "learning_rate": 9.804568662253174e-06,
      "loss": 1.3332,
      "step": 5900
    },
    {
      "epoch": 0.2746143284064292,
      "grad_norm": 1.4625303745269775,
      "learning_rate": 9.801204323130058e-06,
      "loss": 1.3539,
      "step": 5950
    },
    {
      "epoch": 0.276922011838416,
      "grad_norm": 1.6215753555297852,
      "learning_rate": 9.797811859368144e-06,
      "loss": 1.3484,
      "step": 6000
    },
    {
      "epoch": 0.276922011838416,
      "eval_loss": 1.3653181791305542,
      "eval_runtime": 178.3849,
      "eval_samples_per_second": 28.029,
      "eval_steps_per_second": 1.172,
      "step": 6000
    },
    {
      "epoch": 0.2792296952704028,
      "grad_norm": 1.5025418996810913,
      "learning_rate": 9.794391290839909e-06,
      "loss": 1.3474,
      "step": 6050
    },
    {
      "epoch": 0.2815373787023896,
      "grad_norm": 1.3979206085205078,
      "learning_rate": 9.790942637582463e-06,
      "loss": 1.3727,
      "step": 6100
    },
    {
      "epoch": 0.2838450621343764,
      "grad_norm": 1.3955585956573486,
      "learning_rate": 9.787465919797428e-06,
      "loss": 1.3827,
      "step": 6150
    },
    {
      "epoch": 0.2861527455663632,
      "grad_norm": 1.208298683166504,
      "learning_rate": 9.783961157850827e-06,
      "loss": 1.3455,
      "step": 6200
    },
    {
      "epoch": 0.28846042899835,
      "grad_norm": 1.371996521949768,
      "learning_rate": 9.780428372272963e-06,
      "loss": 1.3849,
      "step": 6250
    },
    {
      "epoch": 0.2907681124303368,
      "grad_norm": 1.1958187818527222,
      "learning_rate": 9.776867583758288e-06,
      "loss": 1.3522,
      "step": 6300
    },
    {
      "epoch": 0.29307579586232363,
      "grad_norm": 1.290692687034607,
      "learning_rate": 9.773278813165297e-06,
      "loss": 1.3854,
      "step": 6350
    },
    {
      "epoch": 0.2953834792943104,
      "grad_norm": 1.248901128768921,
      "learning_rate": 9.769662081516403e-06,
      "loss": 1.3683,
      "step": 6400
    },
    {
      "epoch": 0.2976911627262972,
      "grad_norm": 1.3705945014953613,
      "learning_rate": 9.766017409997798e-06,
      "loss": 1.3962,
      "step": 6450
    },
    {
      "epoch": 0.299998846158284,
      "grad_norm": 1.7356164455413818,
      "learning_rate": 9.762344819959353e-06,
      "loss": 1.3933,
      "step": 6500
    },
    {
      "epoch": 0.3023065295902708,
      "grad_norm": 1.2354319095611572,
      "learning_rate": 9.758644332914476e-06,
      "loss": 1.3677,
      "step": 6550
    },
    {
      "epoch": 0.3046142130222576,
      "grad_norm": 1.3022233247756958,
      "learning_rate": 9.754915970539988e-06,
      "loss": 1.3249,
      "step": 6600
    },
    {
      "epoch": 0.3069218964542444,
      "grad_norm": 1.2888805866241455,
      "learning_rate": 9.751159754676005e-06,
      "loss": 1.3635,
      "step": 6650
    },
    {
      "epoch": 0.30922957988623123,
      "grad_norm": 1.5069547891616821,
      "learning_rate": 9.747375707325802e-06,
      "loss": 1.3738,
      "step": 6700
    },
    {
      "epoch": 0.311537263318218,
      "grad_norm": 1.3925191164016724,
      "learning_rate": 9.74356385065568e-06,
      "loss": 1.3843,
      "step": 6750
    },
    {
      "epoch": 0.3138449467502048,
      "grad_norm": 1.4308773279190063,
      "learning_rate": 9.739724206994852e-06,
      "loss": 1.3964,
      "step": 6800
    },
    {
      "epoch": 0.3161526301821916,
      "grad_norm": 1.3309776782989502,
      "learning_rate": 9.735856798835298e-06,
      "loss": 1.3931,
      "step": 6850
    },
    {
      "epoch": 0.3184603136141784,
      "grad_norm": 1.4930305480957031,
      "learning_rate": 9.731961648831633e-06,
      "loss": 1.3549,
      "step": 6900
    },
    {
      "epoch": 0.3207679970461652,
      "grad_norm": 1.4148837327957153,
      "learning_rate": 9.72803877980099e-06,
      "loss": 1.359,
      "step": 6950
    },
    {
      "epoch": 0.323075680478152,
      "grad_norm": 1.4344557523727417,
      "learning_rate": 9.724088214722865e-06,
      "loss": 1.3907,
      "step": 7000
    },
    {
      "epoch": 0.323075680478152,
      "eval_loss": 1.359694004058838,
      "eval_runtime": 178.2029,
      "eval_samples_per_second": 28.058,
      "eval_steps_per_second": 1.173,
      "step": 7000
    },
    {
      "epoch": 0.32538336391013883,
      "grad_norm": 1.8040902614593506,
      "learning_rate": 9.720109976738996e-06,
      "loss": 1.3905,
      "step": 7050
    },
    {
      "epoch": 0.3276910473421256,
      "grad_norm": 1.456432819366455,
      "learning_rate": 9.716104089153227e-06,
      "loss": 1.3578,
      "step": 7100
    },
    {
      "epoch": 0.3299987307741124,
      "grad_norm": 1.3788949251174927,
      "learning_rate": 9.712070575431364e-06,
      "loss": 1.3808,
      "step": 7150
    },
    {
      "epoch": 0.3323064142060992,
      "grad_norm": 1.2134976387023926,
      "learning_rate": 9.70800945920105e-06,
      "loss": 1.3642,
      "step": 7200
    },
    {
      "epoch": 0.334614097638086,
      "grad_norm": 1.3637040853500366,
      "learning_rate": 9.70392076425161e-06,
      "loss": 1.3558,
      "step": 7250
    },
    {
      "epoch": 0.3369217810700728,
      "grad_norm": 1.5762923955917358,
      "learning_rate": 9.69980451453392e-06,
      "loss": 1.3519,
      "step": 7300
    },
    {
      "epoch": 0.3392294645020596,
      "grad_norm": 1.3395864963531494,
      "learning_rate": 9.695660734160278e-06,
      "loss": 1.3572,
      "step": 7350
    },
    {
      "epoch": 0.3415371479340464,
      "grad_norm": 1.251217007637024,
      "learning_rate": 9.691489447404243e-06,
      "loss": 1.3549,
      "step": 7400
    },
    {
      "epoch": 0.3438448313660332,
      "grad_norm": 1.5076048374176025,
      "learning_rate": 9.687374923238843e-06,
      "loss": 1.3796,
      "step": 7450
    },
    {
      "epoch": 0.34615251479802,
      "grad_norm": 1.688606858253479,
      "learning_rate": 9.683149246088034e-06,
      "loss": 1.3657,
      "step": 7500
    },
    {
      "epoch": 0.3484601982300068,
      "grad_norm": 1.6821999549865723,
      "learning_rate": 9.678896135845002e-06,
      "loss": 1.3846,
      "step": 7550
    },
    {
      "epoch": 0.35076788166199363,
      "grad_norm": 1.3190609216690063,
      "learning_rate": 9.674615617423742e-06,
      "loss": 1.3494,
      "step": 7600
    },
    {
      "epoch": 0.3530755650939804,
      "grad_norm": 1.5519264936447144,
      "learning_rate": 9.670307715898805e-06,
      "loss": 1.3549,
      "step": 7650
    },
    {
      "epoch": 0.3553832485259672,
      "grad_norm": 1.4892072677612305,
      "learning_rate": 9.665972456505145e-06,
      "loss": 1.3914,
      "step": 7700
    },
    {
      "epoch": 0.357690931957954,
      "grad_norm": 1.4824330806732178,
      "learning_rate": 9.661609864637977e-06,
      "loss": 1.3622,
      "step": 7750
    },
    {
      "epoch": 0.3599986153899408,
      "grad_norm": 1.4167470932006836,
      "learning_rate": 9.657219965852618e-06,
      "loss": 1.3643,
      "step": 7800
    },
    {
      "epoch": 0.3623062988219276,
      "grad_norm": 1.3888047933578491,
      "learning_rate": 9.652802785864355e-06,
      "loss": 1.3542,
      "step": 7850
    },
    {
      "epoch": 0.3646139822539144,
      "grad_norm": 1.3904517889022827,
      "learning_rate": 9.648358350548272e-06,
      "loss": 1.3771,
      "step": 7900
    },
    {
      "epoch": 0.36692166568590123,
      "grad_norm": 1.47262704372406,
      "learning_rate": 9.643886685939118e-06,
      "loss": 1.3588,
      "step": 7950
    },
    {
      "epoch": 0.369229349117888,
      "grad_norm": 1.4519085884094238,
      "learning_rate": 9.639387818231146e-06,
      "loss": 1.3621,
      "step": 8000
    },
    {
      "epoch": 0.369229349117888,
      "eval_loss": 1.3545523881912231,
      "eval_runtime": 177.9328,
      "eval_samples_per_second": 28.1,
      "eval_steps_per_second": 1.175,
      "step": 8000
    },
    {
      "epoch": 0.3715370325498748,
      "grad_norm": 1.5121536254882812,
      "learning_rate": 9.634861773777955e-06,
      "loss": 1.3809,
      "step": 8050
    },
    {
      "epoch": 0.3738447159818616,
      "grad_norm": 1.3477240800857544,
      "learning_rate": 9.630308579092345e-06,
      "loss": 1.3356,
      "step": 8100
    },
    {
      "epoch": 0.3761523994138484,
      "grad_norm": 1.442193865776062,
      "learning_rate": 9.62572826084616e-06,
      "loss": 1.3533,
      "step": 8150
    },
    {
      "epoch": 0.3784600828458352,
      "grad_norm": 1.2611267566680908,
      "learning_rate": 9.621120845870118e-06,
      "loss": 1.3531,
      "step": 8200
    },
    {
      "epoch": 0.380767766277822,
      "grad_norm": 1.3847886323928833,
      "learning_rate": 9.61648636115368e-06,
      "loss": 1.3867,
      "step": 8250
    },
    {
      "epoch": 0.38307544970980884,
      "grad_norm": 1.456662654876709,
      "learning_rate": 9.611824833844867e-06,
      "loss": 1.3421,
      "step": 8300
    },
    {
      "epoch": 0.3853831331417956,
      "grad_norm": 1.6888097524642944,
      "learning_rate": 9.607136291250112e-06,
      "loss": 1.3445,
      "step": 8350
    },
    {
      "epoch": 0.3876908165737824,
      "grad_norm": 1.6469125747680664,
      "learning_rate": 9.602420760834104e-06,
      "loss": 1.3955,
      "step": 8400
    },
    {
      "epoch": 0.3899985000057692,
      "grad_norm": 1.3542736768722534,
      "learning_rate": 9.597678270219615e-06,
      "loss": 1.3801,
      "step": 8450
    },
    {
      "epoch": 0.39230618343775603,
      "grad_norm": 1.4657344818115234,
      "learning_rate": 9.59290884718735e-06,
      "loss": 1.3491,
      "step": 8500
    },
    {
      "epoch": 0.3946138668697428,
      "grad_norm": 1.368537187576294,
      "learning_rate": 9.588112519675782e-06,
      "loss": 1.3544,
      "step": 8550
    },
    {
      "epoch": 0.3969215503017296,
      "grad_norm": 1.546828269958496,
      "learning_rate": 9.583289315780978e-06,
      "loss": 1.3648,
      "step": 8600
    },
    {
      "epoch": 0.3992292337337164,
      "grad_norm": 1.4719271659851074,
      "learning_rate": 9.578439263756447e-06,
      "loss": 1.3543,
      "step": 8650
    },
    {
      "epoch": 0.4015369171657032,
      "grad_norm": 1.4975672960281372,
      "learning_rate": 9.573562392012972e-06,
      "loss": 1.3714,
      "step": 8700
    },
    {
      "epoch": 0.40384460059769,
      "grad_norm": 1.3723787069320679,
      "learning_rate": 9.568658729118435e-06,
      "loss": 1.3617,
      "step": 8750
    },
    {
      "epoch": 0.4061522840296768,
      "grad_norm": 1.436517596244812,
      "learning_rate": 9.563728303797661e-06,
      "loss": 1.3722,
      "step": 8800
    },
    {
      "epoch": 0.40845996746166363,
      "grad_norm": 1.4031198024749756,
      "learning_rate": 9.558771144932246e-06,
      "loss": 1.3656,
      "step": 8850
    },
    {
      "epoch": 0.4107676508936504,
      "grad_norm": 1.3483961820602417,
      "learning_rate": 9.55378728156038e-06,
      "loss": 1.3665,
      "step": 8900
    },
    {
      "epoch": 0.4130753343256372,
      "grad_norm": 1.3667676448822021,
      "learning_rate": 9.54877674287669e-06,
      "loss": 1.3638,
      "step": 8950
    },
    {
      "epoch": 0.415383017757624,
      "grad_norm": 1.4517261981964111,
      "learning_rate": 9.543739558232061e-06,
      "loss": 1.392,
      "step": 9000
    },
    {
      "epoch": 0.415383017757624,
      "eval_loss": 1.3481671810150146,
      "eval_runtime": 178.0117,
      "eval_samples_per_second": 28.088,
      "eval_steps_per_second": 1.174,
      "step": 9000
    },
    {
      "epoch": 0.4176907011896108,
      "grad_norm": 1.2423149347305298,
      "learning_rate": 9.538675757133462e-06,
      "loss": 1.3688,
      "step": 9050
    },
    {
      "epoch": 0.4199983846215976,
      "grad_norm": 1.3997743129730225,
      "learning_rate": 9.53358536924378e-06,
      "loss": 1.3767,
      "step": 9100
    },
    {
      "epoch": 0.4223060680535844,
      "grad_norm": 1.3724242448806763,
      "learning_rate": 9.528468424381641e-06,
      "loss": 1.3665,
      "step": 9150
    },
    {
      "epoch": 0.42461375148557123,
      "grad_norm": 1.3290592432022095,
      "learning_rate": 9.52332495252124e-06,
      "loss": 1.3483,
      "step": 9200
    },
    {
      "epoch": 0.426921434917558,
      "grad_norm": 1.2846637964248657,
      "learning_rate": 9.518154983792158e-06,
      "loss": 1.3479,
      "step": 9250
    },
    {
      "epoch": 0.4292291183495448,
      "grad_norm": 1.3611632585525513,
      "learning_rate": 9.512958548479197e-06,
      "loss": 1.3537,
      "step": 9300
    },
    {
      "epoch": 0.4315368017815316,
      "grad_norm": 1.3824471235275269,
      "learning_rate": 9.507735677022187e-06,
      "loss": 1.3743,
      "step": 9350
    },
    {
      "epoch": 0.4338444852135184,
      "grad_norm": 1.3227802515029907,
      "learning_rate": 9.502486400015825e-06,
      "loss": 1.3415,
      "step": 9400
    },
    {
      "epoch": 0.4361521686455052,
      "grad_norm": 1.3371866941452026,
      "learning_rate": 9.497210748209483e-06,
      "loss": 1.3652,
      "step": 9450
    },
    {
      "epoch": 0.438459852077492,
      "grad_norm": 1.4511524438858032,
      "learning_rate": 9.491908752507031e-06,
      "loss": 1.3399,
      "step": 9500
    },
    {
      "epoch": 0.44076753550947884,
      "grad_norm": 1.4281114339828491,
      "learning_rate": 9.48658044396666e-06,
      "loss": 1.3591,
      "step": 9550
    },
    {
      "epoch": 0.4430752189414656,
      "grad_norm": 1.2893288135528564,
      "learning_rate": 9.481225853800695e-06,
      "loss": 1.3416,
      "step": 9600
    },
    {
      "epoch": 0.4453829023734524,
      "grad_norm": 1.2424618005752563,
      "learning_rate": 9.475845013375414e-06,
      "loss": 1.3406,
      "step": 9650
    },
    {
      "epoch": 0.4476905858054392,
      "grad_norm": 1.462271809577942,
      "learning_rate": 9.470437954210867e-06,
      "loss": 1.3494,
      "step": 9700
    },
    {
      "epoch": 0.44999826923742603,
      "grad_norm": 1.5905342102050781,
      "learning_rate": 9.465113629332928e-06,
      "loss": 1.3238,
      "step": 9750
    },
    {
      "epoch": 0.4523059526694128,
      "grad_norm": 1.5316884517669678,
      "learning_rate": 9.459654750656025e-06,
      "loss": 1.3939,
      "step": 9800
    },
    {
      "epoch": 0.4546136361013996,
      "grad_norm": 1.7744826078414917,
      "learning_rate": 9.45416974807966e-06,
      "loss": 1.3844,
      "step": 9850
    },
    {
      "epoch": 0.4569213195333864,
      "grad_norm": 1.655947208404541,
      "learning_rate": 9.448658653734049e-06,
      "loss": 1.3542,
      "step": 9900
    },
    {
      "epoch": 0.4592290029653732,
      "grad_norm": 1.4580295085906982,
      "learning_rate": 9.443121499902246e-06,
      "loss": 1.3656,
      "step": 9950
    },
    {
      "epoch": 0.46153668639736,
      "grad_norm": 1.4543321132659912,
      "learning_rate": 9.437558319019955e-06,
      "loss": 1.3697,
      "step": 10000
    },
    {
      "epoch": 0.46153668639736,
      "eval_loss": 1.3464746475219727,
      "eval_runtime": 177.9944,
      "eval_samples_per_second": 28.091,
      "eval_steps_per_second": 1.174,
      "step": 10000
    },
    {
      "epoch": 0.4638443698293468,
      "grad_norm": 1.535687804222107,
      "learning_rate": 9.431969143675344e-06,
      "loss": 1.3692,
      "step": 10050
    },
    {
      "epoch": 0.46615205326133363,
      "grad_norm": 1.4299414157867432,
      "learning_rate": 9.426354006608854e-06,
      "loss": 1.3286,
      "step": 10100
    },
    {
      "epoch": 0.4684597366933204,
      "grad_norm": 1.2419962882995605,
      "learning_rate": 9.420712940713005e-06,
      "loss": 1.3508,
      "step": 10150
    },
    {
      "epoch": 0.4707674201253072,
      "grad_norm": 1.462646484375,
      "learning_rate": 9.415045979032195e-06,
      "loss": 1.3471,
      "step": 10200
    },
    {
      "epoch": 0.473075103557294,
      "grad_norm": 1.3636424541473389,
      "learning_rate": 9.40935315476253e-06,
      "loss": 1.3624,
      "step": 10250
    },
    {
      "epoch": 0.4753827869892808,
      "grad_norm": 1.422682762145996,
      "learning_rate": 9.403634501251602e-06,
      "loss": 1.3293,
      "step": 10300
    },
    {
      "epoch": 0.4776904704212676,
      "grad_norm": 1.711004376411438,
      "learning_rate": 9.397890051998314e-06,
      "loss": 1.3475,
      "step": 10350
    },
    {
      "epoch": 0.4799981538532544,
      "grad_norm": 2.9169723987579346,
      "learning_rate": 9.392119840652671e-06,
      "loss": 1.356,
      "step": 10400
    },
    {
      "epoch": 0.48230583728524123,
      "grad_norm": 1.256858229637146,
      "learning_rate": 9.386323901015593e-06,
      "loss": 1.3458,
      "step": 10450
    },
    {
      "epoch": 0.484613520717228,
      "grad_norm": 1.8683758974075317,
      "learning_rate": 9.380502267038707e-06,
      "loss": 1.3842,
      "step": 10500
    },
    {
      "epoch": 0.4869212041492148,
      "grad_norm": 1.2782706022262573,
      "learning_rate": 9.374654972824156e-06,
      "loss": 1.3601,
      "step": 10550
    },
    {
      "epoch": 0.4892288875812016,
      "grad_norm": 1.3258230686187744,
      "learning_rate": 9.368782052624395e-06,
      "loss": 1.3434,
      "step": 10600
    },
    {
      "epoch": 0.49153657101318843,
      "grad_norm": 1.5476065874099731,
      "learning_rate": 9.362883540841992e-06,
      "loss": 1.3461,
      "step": 10650
    },
    {
      "epoch": 0.4938442544451752,
      "grad_norm": 1.7180019617080688,
      "learning_rate": 9.356959472029428e-06,
      "loss": 1.3506,
      "step": 10700
    },
    {
      "epoch": 0.496151937877162,
      "grad_norm": 1.3189632892608643,
      "learning_rate": 9.35100988088889e-06,
      "loss": 1.3525,
      "step": 10750
    },
    {
      "epoch": 0.49845962130914884,
      "grad_norm": 1.5152833461761475,
      "learning_rate": 9.34503480227207e-06,
      "loss": 1.3871,
      "step": 10800
    },
    {
      "epoch": 0.5007673047411356,
      "grad_norm": 1.3487995862960815,
      "learning_rate": 9.339034271179968e-06,
      "loss": 1.3548,
      "step": 10850
    },
    {
      "epoch": 0.5030749881731225,
      "grad_norm": 1.6817939281463623,
      "learning_rate": 9.333008322762669e-06,
      "loss": 1.3669,
      "step": 10900
    },
    {
      "epoch": 0.5053826716051092,
      "grad_norm": 1.573663592338562,
      "learning_rate": 9.326956992319157e-06,
      "loss": 1.3592,
      "step": 10950
    },
    {
      "epoch": 0.507690355037096,
      "grad_norm": 1.494926929473877,
      "learning_rate": 9.3208803152971e-06,
      "loss": 1.3333,
      "step": 11000
    },
    {
      "epoch": 0.507690355037096,
      "eval_loss": 1.341208577156067,
      "eval_runtime": 178.0467,
      "eval_samples_per_second": 28.083,
      "eval_steps_per_second": 1.174,
      "step": 11000
    },
    {
      "epoch": 0.5099980384690828,
      "grad_norm": 1.8129562139511108,
      "learning_rate": 9.314778327292632e-06,
      "loss": 1.3695,
      "step": 11050
    },
    {
      "epoch": 0.5123057219010696,
      "grad_norm": 1.274186372756958,
      "learning_rate": 9.308651064050169e-06,
      "loss": 1.3466,
      "step": 11100
    },
    {
      "epoch": 0.5146134053330564,
      "grad_norm": 1.3488510847091675,
      "learning_rate": 9.302498561462173e-06,
      "loss": 1.3534,
      "step": 11150
    },
    {
      "epoch": 0.5169210887650432,
      "grad_norm": 1.7703368663787842,
      "learning_rate": 9.296320855568962e-06,
      "loss": 1.3471,
      "step": 11200
    },
    {
      "epoch": 0.51922877219703,
      "grad_norm": 1.9980889558792114,
      "learning_rate": 9.290117982558482e-06,
      "loss": 1.309,
      "step": 11250
    },
    {
      "epoch": 0.5215364556290168,
      "grad_norm": 1.403945803642273,
      "learning_rate": 9.283889978766113e-06,
      "loss": 1.3585,
      "step": 11300
    },
    {
      "epoch": 0.5238441390610036,
      "grad_norm": 1.4045027494430542,
      "learning_rate": 9.27763688067444e-06,
      "loss": 1.3724,
      "step": 11350
    },
    {
      "epoch": 0.5261518224929904,
      "grad_norm": 1.4969336986541748,
      "learning_rate": 9.27135872491305e-06,
      "loss": 1.3512,
      "step": 11400
    },
    {
      "epoch": 0.5284595059249773,
      "grad_norm": 1.667027473449707,
      "learning_rate": 9.265055548258313e-06,
      "loss": 1.3572,
      "step": 11450
    },
    {
      "epoch": 0.530767189356964,
      "grad_norm": 1.2891933917999268,
      "learning_rate": 9.258727387633163e-06,
      "loss": 1.3773,
      "step": 11500
    },
    {
      "epoch": 0.5330748727889508,
      "grad_norm": 1.5664368867874146,
      "learning_rate": 9.252374280106894e-06,
      "loss": 1.3428,
      "step": 11550
    },
    {
      "epoch": 0.5353825562209377,
      "grad_norm": 1.5353076457977295,
      "learning_rate": 9.245996262894927e-06,
      "loss": 1.3695,
      "step": 11600
    },
    {
      "epoch": 0.5376902396529244,
      "grad_norm": 1.2636135816574097,
      "learning_rate": 9.239593373358602e-06,
      "loss": 1.3402,
      "step": 11650
    },
    {
      "epoch": 0.5399979230849112,
      "grad_norm": 1.2685757875442505,
      "learning_rate": 9.23316564900496e-06,
      "loss": 1.3442,
      "step": 11700
    },
    {
      "epoch": 0.542305606516898,
      "grad_norm": 1.5822128057479858,
      "learning_rate": 9.226713127486517e-06,
      "loss": 1.3363,
      "step": 11750
    },
    {
      "epoch": 0.5446132899488848,
      "grad_norm": 1.482696533203125,
      "learning_rate": 9.220235846601044e-06,
      "loss": 1.3503,
      "step": 11800
    },
    {
      "epoch": 0.5469209733808716,
      "grad_norm": 1.5130283832550049,
      "learning_rate": 9.213733844291357e-06,
      "loss": 1.3426,
      "step": 11850
    },
    {
      "epoch": 0.5492286568128584,
      "grad_norm": 1.6295862197875977,
      "learning_rate": 9.207207158645075e-06,
      "loss": 1.3706,
      "step": 11900
    },
    {
      "epoch": 0.5515363402448452,
      "grad_norm": 1.4432355165481567,
      "learning_rate": 9.200655827894417e-06,
      "loss": 1.3427,
      "step": 11950
    },
    {
      "epoch": 0.553844023676832,
      "grad_norm": 1.4398125410079956,
      "learning_rate": 9.194079890415964e-06,
      "loss": 1.3815,
      "step": 12000
    },
    {
      "epoch": 0.553844023676832,
      "eval_loss": 1.340593695640564,
      "eval_runtime": 178.0064,
      "eval_samples_per_second": 28.089,
      "eval_steps_per_second": 1.174,
      "step": 12000
    },
    {
      "epoch": 0.5561517071088188,
      "grad_norm": 1.3201764822006226,
      "learning_rate": 9.187479384730437e-06,
      "loss": 1.3524,
      "step": 12050
    },
    {
      "epoch": 0.5584593905408056,
      "grad_norm": 1.5014488697052002,
      "learning_rate": 9.180854349502479e-06,
      "loss": 1.3361,
      "step": 12100
    },
    {
      "epoch": 0.5607670739727925,
      "grad_norm": 1.5211293697357178,
      "learning_rate": 9.174204823540421e-06,
      "loss": 1.3546,
      "step": 12150
    },
    {
      "epoch": 0.5630747574047792,
      "grad_norm": 1.6825107336044312,
      "learning_rate": 9.167530845796052e-06,
      "loss": 1.3712,
      "step": 12200
    },
    {
      "epoch": 0.565382440836766,
      "grad_norm": 2.0130507946014404,
      "learning_rate": 9.160832455364406e-06,
      "loss": 1.3443,
      "step": 12250
    },
    {
      "epoch": 0.5676901242687528,
      "grad_norm": 1.5414998531341553,
      "learning_rate": 9.154109691483507e-06,
      "loss": 1.3664,
      "step": 12300
    },
    {
      "epoch": 0.5699978077007396,
      "grad_norm": 1.3753067255020142,
      "learning_rate": 9.14736259353417e-06,
      "loss": 1.3683,
      "step": 12350
    },
    {
      "epoch": 0.5723054911327264,
      "grad_norm": 1.6157268285751343,
      "learning_rate": 9.140591201039745e-06,
      "loss": 1.3163,
      "step": 12400
    },
    {
      "epoch": 0.5746131745647132,
      "grad_norm": 1.525922417640686,
      "learning_rate": 9.133795553665898e-06,
      "loss": 1.3457,
      "step": 12450
    },
    {
      "epoch": 0.5769208579967,
      "grad_norm": 1.5506274700164795,
      "learning_rate": 9.126975691220377e-06,
      "loss": 1.3841,
      "step": 12500
    },
    {
      "epoch": 0.5792285414286868,
      "grad_norm": 1.2893446683883667,
      "learning_rate": 9.120131653652777e-06,
      "loss": 1.3629,
      "step": 12550
    },
    {
      "epoch": 0.5815362248606736,
      "grad_norm": 1.4902284145355225,
      "learning_rate": 9.113263481054304e-06,
      "loss": 1.3318,
      "step": 12600
    },
    {
      "epoch": 0.5838439082926604,
      "grad_norm": 1.3008276224136353,
      "learning_rate": 9.10637121365755e-06,
      "loss": 1.3682,
      "step": 12650
    },
    {
      "epoch": 0.5861515917246473,
      "grad_norm": 1.6307209730148315,
      "learning_rate": 9.09945489183624e-06,
      "loss": 1.3639,
      "step": 12700
    },
    {
      "epoch": 0.588459275156634,
      "grad_norm": 1.5027633905410767,
      "learning_rate": 9.09251455610502e-06,
      "loss": 1.3377,
      "step": 12750
    },
    {
      "epoch": 0.5907669585886208,
      "grad_norm": 1.6512293815612793,
      "learning_rate": 9.08555024711919e-06,
      "loss": 1.3832,
      "step": 12800
    },
    {
      "epoch": 0.5930746420206077,
      "grad_norm": 1.3286153078079224,
      "learning_rate": 9.07856200567449e-06,
      "loss": 1.3599,
      "step": 12850
    },
    {
      "epoch": 0.5953823254525944,
      "grad_norm": 1.4552720785140991,
      "learning_rate": 9.071549872706851e-06,
      "loss": 1.3287,
      "step": 12900
    },
    {
      "epoch": 0.5976900088845812,
      "grad_norm": 1.525847315788269,
      "learning_rate": 9.064513889292156e-06,
      "loss": 1.3165,
      "step": 12950
    },
    {
      "epoch": 0.599997692316568,
      "grad_norm": 1.602961778640747,
      "learning_rate": 9.057454096646002e-06,
      "loss": 1.3423,
      "step": 13000
    },
    {
      "epoch": 0.599997692316568,
      "eval_loss": 1.338531255722046,
      "eval_runtime": 178.0498,
      "eval_samples_per_second": 28.082,
      "eval_steps_per_second": 1.174,
      "step": 13000
    },
    {
      "epoch": 0.6023053757485548,
      "grad_norm": 1.1471598148345947,
      "learning_rate": 9.05037053612345e-06,
      "loss": 1.3653,
      "step": 13050
    },
    {
      "epoch": 0.6046130591805416,
      "grad_norm": 1.3355554342269897,
      "learning_rate": 9.043263249218795e-06,
      "loss": 1.3471,
      "step": 13100
    },
    {
      "epoch": 0.6069207426125284,
      "grad_norm": 1.7779704332351685,
      "learning_rate": 9.036132277565316e-06,
      "loss": 1.3624,
      "step": 13150
    },
    {
      "epoch": 0.6092284260445152,
      "grad_norm": 1.419787883758545,
      "learning_rate": 9.028977662935032e-06,
      "loss": 1.3465,
      "step": 13200
    },
    {
      "epoch": 0.611536109476502,
      "grad_norm": 1.3596655130386353,
      "learning_rate": 9.021799447238463e-06,
      "loss": 1.3472,
      "step": 13250
    },
    {
      "epoch": 0.6138437929084888,
      "grad_norm": 1.2903145551681519,
      "learning_rate": 9.014597672524372e-06,
      "loss": 1.3297,
      "step": 13300
    },
    {
      "epoch": 0.6161514763404756,
      "grad_norm": 1.412043809890747,
      "learning_rate": 9.00737238097953e-06,
      "loss": 1.3592,
      "step": 13350
    },
    {
      "epoch": 0.6184591597724625,
      "grad_norm": 1.5850248336791992,
      "learning_rate": 9.000123614928473e-06,
      "loss": 1.3556,
      "step": 13400
    },
    {
      "epoch": 0.6207668432044492,
      "grad_norm": 1.6944992542266846,
      "learning_rate": 8.992851416833235e-06,
      "loss": 1.3611,
      "step": 13450
    },
    {
      "epoch": 0.623074526636436,
      "grad_norm": 1.4669299125671387,
      "learning_rate": 8.985555829293117e-06,
      "loss": 1.3927,
      "step": 13500
    },
    {
      "epoch": 0.6253822100684228,
      "grad_norm": 1.3399789333343506,
      "learning_rate": 8.978236895044435e-06,
      "loss": 1.3539,
      "step": 13550
    },
    {
      "epoch": 0.6276898935004096,
      "grad_norm": 1.6167569160461426,
      "learning_rate": 8.970894656960256e-06,
      "loss": 1.3035,
      "step": 13600
    },
    {
      "epoch": 0.6299975769323964,
      "grad_norm": 1.4771947860717773,
      "learning_rate": 8.963529158050164e-06,
      "loss": 1.3276,
      "step": 13650
    },
    {
      "epoch": 0.6323052603643832,
      "grad_norm": 1.8537935018539429,
      "learning_rate": 8.956140441460001e-06,
      "loss": 1.3488,
      "step": 13700
    },
    {
      "epoch": 0.63461294379637,
      "grad_norm": 1.3998725414276123,
      "learning_rate": 8.948728550471613e-06,
      "loss": 1.3653,
      "step": 13750
    },
    {
      "epoch": 0.6369206272283569,
      "grad_norm": 1.3860598802566528,
      "learning_rate": 8.941293528502597e-06,
      "loss": 1.3522,
      "step": 13800
    },
    {
      "epoch": 0.6392283106603436,
      "grad_norm": 1.6995534896850586,
      "learning_rate": 8.933835419106047e-06,
      "loss": 1.3276,
      "step": 13850
    },
    {
      "epoch": 0.6415359940923304,
      "grad_norm": 1.5709260702133179,
      "learning_rate": 8.926504114578434e-06,
      "loss": 1.39,
      "step": 13900
    },
    {
      "epoch": 0.6438436775243173,
      "grad_norm": 1.5842280387878418,
      "learning_rate": 8.919000421094792e-06,
      "loss": 1.3504,
      "step": 13950
    },
    {
      "epoch": 0.646151360956304,
      "grad_norm": 1.4734750986099243,
      "learning_rate": 8.911473770772852e-06,
      "loss": 1.3112,
      "step": 14000
    },
    {
      "epoch": 0.646151360956304,
      "eval_loss": 1.3382893800735474,
      "eval_runtime": 178.1453,
      "eval_samples_per_second": 28.067,
      "eval_steps_per_second": 1.173,
      "step": 14000
    },
    {
      "epoch": 0.6484590443882908,
      "grad_norm": 1.6101367473602295,
      "learning_rate": 8.903924207702448e-06,
      "loss": 1.3713,
      "step": 14050
    },
    {
      "epoch": 0.6507667278202777,
      "grad_norm": 1.4159103631973267,
      "learning_rate": 8.89635177610764e-06,
      "loss": 1.331,
      "step": 14100
    },
    {
      "epoch": 0.6530744112522644,
      "grad_norm": 1.466037631034851,
      "learning_rate": 8.88875652034645e-06,
      "loss": 1.3973,
      "step": 14150
    },
    {
      "epoch": 0.6553820946842512,
      "grad_norm": 1.5703160762786865,
      "learning_rate": 8.881138484910585e-06,
      "loss": 1.3564,
      "step": 14200
    },
    {
      "epoch": 0.657689778116238,
      "grad_norm": 1.448097586631775,
      "learning_rate": 8.873497714425207e-06,
      "loss": 1.3467,
      "step": 14250
    },
    {
      "epoch": 0.6599974615482248,
      "grad_norm": 1.468119740486145,
      "learning_rate": 8.865834253648651e-06,
      "loss": 1.303,
      "step": 14300
    },
    {
      "epoch": 0.6623051449802116,
      "grad_norm": 1.4920796155929565,
      "learning_rate": 8.858148147472169e-06,
      "loss": 1.3244,
      "step": 14350
    },
    {
      "epoch": 0.6646128284121984,
      "grad_norm": 1.4383323192596436,
      "learning_rate": 8.850439440919661e-06,
      "loss": 1.354,
      "step": 14400
    },
    {
      "epoch": 0.6669205118441852,
      "grad_norm": 1.750296711921692,
      "learning_rate": 8.84270817914742e-06,
      "loss": 1.3121,
      "step": 14450
    },
    {
      "epoch": 0.669228195276172,
      "grad_norm": 1.56887948513031,
      "learning_rate": 8.834954407443866e-06,
      "loss": 1.3678,
      "step": 14500
    },
    {
      "epoch": 0.6715358787081588,
      "grad_norm": 1.5623135566711426,
      "learning_rate": 8.827178171229271e-06,
      "loss": 1.341,
      "step": 14550
    },
    {
      "epoch": 0.6738435621401456,
      "grad_norm": 1.3034453392028809,
      "learning_rate": 8.81937951605551e-06,
      "loss": 1.3243,
      "step": 14600
    },
    {
      "epoch": 0.6761512455721325,
      "grad_norm": 1.7497217655181885,
      "learning_rate": 8.811558487605779e-06,
      "loss": 1.3372,
      "step": 14650
    },
    {
      "epoch": 0.6784589290041192,
      "grad_norm": 1.539458990097046,
      "learning_rate": 8.803715131694327e-06,
      "loss": 1.346,
      "step": 14700
    },
    {
      "epoch": 0.680766612436106,
      "grad_norm": 1.3741787672042847,
      "learning_rate": 8.795849494266209e-06,
      "loss": 1.3264,
      "step": 14750
    },
    {
      "epoch": 0.6830742958680928,
      "grad_norm": 1.3552931547164917,
      "learning_rate": 8.787961621396985e-06,
      "loss": 1.3236,
      "step": 14800
    },
    {
      "epoch": 0.6853819793000796,
      "grad_norm": 1.6060442924499512,
      "learning_rate": 8.780051559292476e-06,
      "loss": 1.3505,
      "step": 14850
    },
    {
      "epoch": 0.6876896627320664,
      "grad_norm": 1.7316741943359375,
      "learning_rate": 8.772119354288478e-06,
      "loss": 1.3459,
      "step": 14900
    },
    {
      "epoch": 0.6899973461640532,
      "grad_norm": 1.6779654026031494,
      "learning_rate": 8.764165052850505e-06,
      "loss": 1.3565,
      "step": 14950
    },
    {
      "epoch": 0.69230502959604,
      "grad_norm": 1.6175156831741333,
      "learning_rate": 8.7561887015735e-06,
      "loss": 1.3297,
      "step": 15000
    },
    {
      "epoch": 0.69230502959604,
      "eval_loss": 1.33516263961792,
      "eval_runtime": 178.3673,
      "eval_samples_per_second": 28.032,
      "eval_steps_per_second": 1.172,
      "step": 15000
    },
    {
      "epoch": 0.6946127130280269,
      "grad_norm": 1.3470591306686401,
      "learning_rate": 8.748190347181573e-06,
      "loss": 1.3295,
      "step": 15050
    },
    {
      "epoch": 0.6969203964600136,
      "grad_norm": 1.5127140283584595,
      "learning_rate": 8.740170036527724e-06,
      "loss": 1.3462,
      "step": 15100
    },
    {
      "epoch": 0.6992280798920004,
      "grad_norm": 1.6227591037750244,
      "learning_rate": 8.73212781659357e-06,
      "loss": 1.3285,
      "step": 15150
    },
    {
      "epoch": 0.7015357633239873,
      "grad_norm": 1.3522510528564453,
      "learning_rate": 8.72406373448907e-06,
      "loss": 1.3659,
      "step": 15200
    },
    {
      "epoch": 0.703843446755974,
      "grad_norm": 1.5781714916229248,
      "learning_rate": 8.71597783745224e-06,
      "loss": 1.3435,
      "step": 15250
    },
    {
      "epoch": 0.7061511301879608,
      "grad_norm": 1.8387417793273926,
      "learning_rate": 8.707870172848899e-06,
      "loss": 1.3477,
      "step": 15300
    },
    {
      "epoch": 0.7084588136199477,
      "grad_norm": 1.3478269577026367,
      "learning_rate": 8.699740788172362e-06,
      "loss": 1.3425,
      "step": 15350
    },
    {
      "epoch": 0.7107664970519344,
      "grad_norm": 1.5211037397384644,
      "learning_rate": 8.691589731043186e-06,
      "loss": 1.3533,
      "step": 15400
    },
    {
      "epoch": 0.7130741804839212,
      "grad_norm": 1.657016396522522,
      "learning_rate": 8.683417049208876e-06,
      "loss": 1.3283,
      "step": 15450
    },
    {
      "epoch": 0.715381863915908,
      "grad_norm": 1.3118754625320435,
      "learning_rate": 8.675222790543613e-06,
      "loss": 1.347,
      "step": 15500
    },
    {
      "epoch": 0.7176895473478948,
      "grad_norm": 1.5550662279129028,
      "learning_rate": 8.667007003047971e-06,
      "loss": 1.3418,
      "step": 15550
    },
    {
      "epoch": 0.7199972307798816,
      "grad_norm": 1.380224347114563,
      "learning_rate": 8.65876973484864e-06,
      "loss": 1.3485,
      "step": 15600
    },
    {
      "epoch": 0.7223049142118684,
      "grad_norm": 1.6031453609466553,
      "learning_rate": 8.650511034198132e-06,
      "loss": 1.3571,
      "step": 15650
    },
    {
      "epoch": 0.7246125976438552,
      "grad_norm": 1.7599836587905884,
      "learning_rate": 8.642230949474517e-06,
      "loss": 1.3765,
      "step": 15700
    },
    {
      "epoch": 0.7269202810758421,
      "grad_norm": 1.7591116428375244,
      "learning_rate": 8.633929529181118e-06,
      "loss": 1.3542,
      "step": 15750
    },
    {
      "epoch": 0.7292279645078288,
      "grad_norm": 1.4726672172546387,
      "learning_rate": 8.625606821946248e-06,
      "loss": 1.3669,
      "step": 15800
    },
    {
      "epoch": 0.7315356479398156,
      "grad_norm": 1.2454782724380493,
      "learning_rate": 8.61726287652291e-06,
      "loss": 1.3514,
      "step": 15850
    },
    {
      "epoch": 0.7338433313718025,
      "grad_norm": 1.4706190824508667,
      "learning_rate": 8.608897741788517e-06,
      "loss": 1.3363,
      "step": 15900
    },
    {
      "epoch": 0.7361510148037892,
      "grad_norm": 1.6180036067962646,
      "learning_rate": 8.600511466744609e-06,
      "loss": 1.3957,
      "step": 15950
    },
    {
      "epoch": 0.738458698235776,
      "grad_norm": 1.484878420829773,
      "learning_rate": 8.592272454216384e-06,
      "loss": 1.3449,
      "step": 16000
    },
    {
      "epoch": 0.738458698235776,
      "eval_loss": 1.3344852924346924,
      "eval_runtime": 178.4196,
      "eval_samples_per_second": 28.024,
      "eval_steps_per_second": 1.171,
      "step": 16000
    },
    {
      "epoch": 0.7407663816677628,
      "grad_norm": 1.4906708002090454,
      "learning_rate": 8.583844466408378e-06,
      "loss": 1.3708,
      "step": 16050
    },
    {
      "epoch": 0.7430740650997496,
      "grad_norm": 1.4625091552734375,
      "learning_rate": 8.575395485048685e-06,
      "loss": 1.3407,
      "step": 16100
    },
    {
      "epoch": 0.7453817485317364,
      "grad_norm": 1.8032640218734741,
      "learning_rate": 8.56692555963e-06,
      "loss": 1.3699,
      "step": 16150
    },
    {
      "epoch": 0.7476894319637232,
      "grad_norm": 1.3891280889511108,
      "learning_rate": 8.558434739767707e-06,
      "loss": 1.3192,
      "step": 16200
    },
    {
      "epoch": 0.74999711539571,
      "grad_norm": 1.402127981185913,
      "learning_rate": 8.549923075199587e-06,
      "loss": 1.3317,
      "step": 16250
    },
    {
      "epoch": 0.7523047988276969,
      "grad_norm": 1.563159704208374,
      "learning_rate": 8.54156146844021e-06,
      "loss": 1.3629,
      "step": 16300
    },
    {
      "epoch": 0.7546124822596836,
      "grad_norm": 1.3163034915924072,
      "learning_rate": 8.533008678568575e-06,
      "loss": 1.2992,
      "step": 16350
    },
    {
      "epoch": 0.7569201656916704,
      "grad_norm": 1.4140312671661377,
      "learning_rate": 8.524435192932653e-06,
      "loss": 1.3226,
      "step": 16400
    },
    {
      "epoch": 0.7592278491236573,
      "grad_norm": 1.5803618431091309,
      "learning_rate": 8.515841061754471e-06,
      "loss": 1.3509,
      "step": 16450
    },
    {
      "epoch": 0.761535532555644,
      "grad_norm": 1.6125673055648804,
      "learning_rate": 8.507226335376983e-06,
      "loss": 1.3469,
      "step": 16500
    },
    {
      "epoch": 0.7638432159876308,
      "grad_norm": 1.7636903524398804,
      "learning_rate": 8.498591064263797e-06,
      "loss": 1.3635,
      "step": 16550
    },
    {
      "epoch": 0.7661508994196177,
      "grad_norm": 1.4397954940795898,
      "learning_rate": 8.489935298998862e-06,
      "loss": 1.3474,
      "step": 16600
    },
    {
      "epoch": 0.7684585828516044,
      "grad_norm": 1.3513367176055908,
      "learning_rate": 8.481259090286176e-06,
      "loss": 1.335,
      "step": 16650
    },
    {
      "epoch": 0.7707662662835912,
      "grad_norm": 1.3669722080230713,
      "learning_rate": 8.472562488949498e-06,
      "loss": 1.3265,
      "step": 16700
    },
    {
      "epoch": 0.773073949715578,
      "grad_norm": 1.6688573360443115,
      "learning_rate": 8.463845545932038e-06,
      "loss": 1.3434,
      "step": 16750
    },
    {
      "epoch": 0.7753816331475648,
      "grad_norm": 1.4472894668579102,
      "learning_rate": 8.455108312296172e-06,
      "loss": 1.366,
      "step": 16800
    },
    {
      "epoch": 0.7776893165795516,
      "grad_norm": 1.6176066398620605,
      "learning_rate": 8.446350839223123e-06,
      "loss": 1.3463,
      "step": 16850
    },
    {
      "epoch": 0.7799970000115384,
      "grad_norm": 1.628206491470337,
      "learning_rate": 8.437573178012683e-06,
      "loss": 1.3531,
      "step": 16900
    },
    {
      "epoch": 0.7823046834435252,
      "grad_norm": 1.803006649017334,
      "learning_rate": 8.428775380082899e-06,
      "loss": 1.3503,
      "step": 16950
    },
    {
      "epoch": 0.7846123668755121,
      "grad_norm": 1.8269245624542236,
      "learning_rate": 8.419957496969773e-06,
      "loss": 1.3411,
      "step": 17000
    },
    {
      "epoch": 0.7846123668755121,
      "eval_loss": 1.331333041191101,
      "eval_runtime": 178.162,
      "eval_samples_per_second": 28.064,
      "eval_steps_per_second": 1.173,
      "step": 17000
    },
    {
      "epoch": 0.7869200503074988,
      "grad_norm": 1.6790103912353516,
      "learning_rate": 8.41111958032697e-06,
      "loss": 1.3541,
      "step": 17050
    },
    {
      "epoch": 0.7892277337394856,
      "grad_norm": 1.375511646270752,
      "learning_rate": 8.4022616819255e-06,
      "loss": 1.3207,
      "step": 17100
    },
    {
      "epoch": 0.7915354171714725,
      "grad_norm": 1.3344649076461792,
      "learning_rate": 8.393383853653428e-06,
      "loss": 1.3502,
      "step": 17150
    },
    {
      "epoch": 0.7938431006034592,
      "grad_norm": 1.4117732048034668,
      "learning_rate": 8.38448614751556e-06,
      "loss": 1.3465,
      "step": 17200
    },
    {
      "epoch": 0.796150784035446,
      "grad_norm": 1.4475502967834473,
      "learning_rate": 8.37556861563315e-06,
      "loss": 1.3591,
      "step": 17250
    },
    {
      "epoch": 0.7984584674674328,
      "grad_norm": 1.5313818454742432,
      "learning_rate": 8.366631310243583e-06,
      "loss": 1.3257,
      "step": 17300
    },
    {
      "epoch": 0.8007661508994196,
      "grad_norm": 1.5936108827590942,
      "learning_rate": 8.357674283700072e-06,
      "loss": 1.3714,
      "step": 17350
    },
    {
      "epoch": 0.8030738343314064,
      "grad_norm": 1.8506720066070557,
      "learning_rate": 8.34869758847136e-06,
      "loss": 1.3441,
      "step": 17400
    },
    {
      "epoch": 0.8053815177633932,
      "grad_norm": 1.5051336288452148,
      "learning_rate": 8.339701277141398e-06,
      "loss": 1.3474,
      "step": 17450
    },
    {
      "epoch": 0.80768920119538,
      "grad_norm": 1.5725475549697876,
      "learning_rate": 8.330685402409052e-06,
      "loss": 1.338,
      "step": 17500
    },
    {
      "epoch": 0.8099968846273669,
      "grad_norm": 1.507179856300354,
      "learning_rate": 8.321650017087779e-06,
      "loss": 1.3445,
      "step": 17550
    },
    {
      "epoch": 0.8123045680593536,
      "grad_norm": 1.5497490167617798,
      "learning_rate": 8.312595174105334e-06,
      "loss": 1.3271,
      "step": 17600
    },
    {
      "epoch": 0.8146122514913404,
      "grad_norm": 1.4190579652786255,
      "learning_rate": 8.303520926503448e-06,
      "loss": 1.3766,
      "step": 17650
    },
    {
      "epoch": 0.8169199349233273,
      "grad_norm": 1.4886947870254517,
      "learning_rate": 8.29442732743752e-06,
      "loss": 1.3322,
      "step": 17700
    },
    {
      "epoch": 0.819227618355314,
      "grad_norm": 1.925368070602417,
      "learning_rate": 8.285314430176306e-06,
      "loss": 1.3391,
      "step": 17750
    },
    {
      "epoch": 0.8215353017873008,
      "grad_norm": 1.58493971824646,
      "learning_rate": 8.276182288101612e-06,
      "loss": 1.336,
      "step": 17800
    },
    {
      "epoch": 0.8238429852192877,
      "grad_norm": 1.72731351852417,
      "learning_rate": 8.267030954707973e-06,
      "loss": 1.343,
      "step": 17850
    },
    {
      "epoch": 0.8261506686512744,
      "grad_norm": 1.4787688255310059,
      "learning_rate": 8.257860483602345e-06,
      "loss": 1.3483,
      "step": 17900
    },
    {
      "epoch": 0.8284583520832612,
      "grad_norm": 1.3548074960708618,
      "learning_rate": 8.248670928503789e-06,
      "loss": 1.3031,
      "step": 17950
    },
    {
      "epoch": 0.830766035515248,
      "grad_norm": 1.6566789150238037,
      "learning_rate": 8.239462343243152e-06,
      "loss": 1.339,
      "step": 18000
    },
    {
      "epoch": 0.830766035515248,
      "eval_loss": 1.3311997652053833,
      "eval_runtime": 178.2369,
      "eval_samples_per_second": 28.053,
      "eval_steps_per_second": 1.173,
      "step": 18000
    },
    {
      "epoch": 0.8330737189472348,
      "grad_norm": 1.6684271097183228,
      "learning_rate": 8.230234781762768e-06,
      "loss": 1.3236,
      "step": 18050
    },
    {
      "epoch": 0.8353814023792216,
      "grad_norm": 1.5920462608337402,
      "learning_rate": 8.22098829811612e-06,
      "loss": 1.3277,
      "step": 18100
    },
    {
      "epoch": 0.8376890858112084,
      "grad_norm": 1.5497463941574097,
      "learning_rate": 8.211722946467536e-06,
      "loss": 1.3465,
      "step": 18150
    },
    {
      "epoch": 0.8399967692431952,
      "grad_norm": 1.2911112308502197,
      "learning_rate": 8.202438781091875e-06,
      "loss": 1.3849,
      "step": 18200
    },
    {
      "epoch": 0.8423044526751821,
      "grad_norm": 1.4156789779663086,
      "learning_rate": 8.193135856374196e-06,
      "loss": 1.3318,
      "step": 18250
    },
    {
      "epoch": 0.8446121361071688,
      "grad_norm": 1.224666953086853,
      "learning_rate": 8.183814226809454e-06,
      "loss": 1.3552,
      "step": 18300
    },
    {
      "epoch": 0.8469198195391556,
      "grad_norm": 1.1783015727996826,
      "learning_rate": 8.174473947002168e-06,
      "loss": 1.2931,
      "step": 18350
    },
    {
      "epoch": 0.8492275029711425,
      "grad_norm": 1.466350793838501,
      "learning_rate": 8.16511507166611e-06,
      "loss": 1.3156,
      "step": 18400
    },
    {
      "epoch": 0.8515351864031292,
      "grad_norm": 1.3802824020385742,
      "learning_rate": 8.15573765562398e-06,
      "loss": 1.3487,
      "step": 18450
    },
    {
      "epoch": 0.853842869835116,
      "grad_norm": 1.4043760299682617,
      "learning_rate": 8.14634175380709e-06,
      "loss": 1.3377,
      "step": 18500
    },
    {
      "epoch": 0.8561505532671028,
      "grad_norm": 1.5139362812042236,
      "learning_rate": 8.136927421255033e-06,
      "loss": 1.3512,
      "step": 18550
    },
    {
      "epoch": 0.8584582366990896,
      "grad_norm": 1.8767757415771484,
      "learning_rate": 8.127494713115371e-06,
      "loss": 1.3597,
      "step": 18600
    },
    {
      "epoch": 0.8607659201310764,
      "grad_norm": 1.9257469177246094,
      "learning_rate": 8.118043684643303e-06,
      "loss": 1.3163,
      "step": 18650
    },
    {
      "epoch": 0.8630736035630632,
      "grad_norm": 1.4926862716674805,
      "learning_rate": 8.108574391201346e-06,
      "loss": 1.3649,
      "step": 18700
    },
    {
      "epoch": 0.86538128699505,
      "grad_norm": 1.5768615007400513,
      "learning_rate": 8.099086888259015e-06,
      "loss": 1.342,
      "step": 18750
    },
    {
      "epoch": 0.8676889704270369,
      "grad_norm": 1.289449691772461,
      "learning_rate": 8.089581231392487e-06,
      "loss": 1.3548,
      "step": 18800
    },
    {
      "epoch": 0.8699966538590236,
      "grad_norm": 1.2331749200820923,
      "learning_rate": 8.080057476284285e-06,
      "loss": 1.3406,
      "step": 18850
    },
    {
      "epoch": 0.8723043372910104,
      "grad_norm": 1.3210111856460571,
      "learning_rate": 8.070515678722946e-06,
      "loss": 1.3558,
      "step": 18900
    },
    {
      "epoch": 0.8746120207229973,
      "grad_norm": 1.650985598564148,
      "learning_rate": 8.0609558946027e-06,
      "loss": 1.3377,
      "step": 18950
    },
    {
      "epoch": 0.876919704154984,
      "grad_norm": 1.5832804441452026,
      "learning_rate": 8.051378179923139e-06,
      "loss": 1.3607,
      "step": 19000
    },
    {
      "epoch": 0.876919704154984,
      "eval_loss": 1.3270646333694458,
      "eval_runtime": 178.1397,
      "eval_samples_per_second": 28.068,
      "eval_steps_per_second": 1.173,
      "step": 19000
    },
    {
      "epoch": 0.8792273875869708,
      "grad_norm": 1.4276368618011475,
      "learning_rate": 8.041782590788883e-06,
      "loss": 1.3479,
      "step": 19050
    },
    {
      "epoch": 0.8815350710189577,
      "grad_norm": 1.5199190378189087,
      "learning_rate": 8.032169183409265e-06,
      "loss": 1.3461,
      "step": 19100
    },
    {
      "epoch": 0.8838427544509444,
      "grad_norm": 1.4788326025009155,
      "learning_rate": 8.022538014097991e-06,
      "loss": 1.3545,
      "step": 19150
    },
    {
      "epoch": 0.8861504378829312,
      "grad_norm": 1.4923261404037476,
      "learning_rate": 8.012889139272812e-06,
      "loss": 1.3628,
      "step": 19200
    },
    {
      "epoch": 0.888458121314918,
      "grad_norm": 1.6061010360717773,
      "learning_rate": 8.0032226154552e-06,
      "loss": 1.3811,
      "step": 19250
    },
    {
      "epoch": 0.8907658047469048,
      "grad_norm": 1.652191162109375,
      "learning_rate": 7.993538499270006e-06,
      "loss": 1.3047,
      "step": 19300
    },
    {
      "epoch": 0.8930734881788917,
      "grad_norm": 1.519932508468628,
      "learning_rate": 7.983836847445137e-06,
      "loss": 1.2999,
      "step": 19350
    },
    {
      "epoch": 0.8953811716108784,
      "grad_norm": 1.380921721458435,
      "learning_rate": 7.974117716811219e-06,
      "loss": 1.3157,
      "step": 19400
    },
    {
      "epoch": 0.8976888550428652,
      "grad_norm": 1.2659926414489746,
      "learning_rate": 7.964381164301269e-06,
      "loss": 1.3309,
      "step": 19450
    },
    {
      "epoch": 0.8999965384748521,
      "grad_norm": 1.4286543130874634,
      "learning_rate": 7.954627246950354e-06,
      "loss": 1.3473,
      "step": 19500
    },
    {
      "epoch": 0.9023042219068388,
      "grad_norm": 1.533440113067627,
      "learning_rate": 7.944856021895267e-06,
      "loss": 1.3496,
      "step": 19550
    },
    {
      "epoch": 0.9046119053388256,
      "grad_norm": 1.2446553707122803,
      "learning_rate": 7.935067546374182e-06,
      "loss": 1.3636,
      "step": 19600
    },
    {
      "epoch": 0.9069195887708125,
      "grad_norm": 1.5450561046600342,
      "learning_rate": 7.925261877726325e-06,
      "loss": 1.3744,
      "step": 19650
    },
    {
      "epoch": 0.9092272722027992,
      "grad_norm": 1.528748869895935,
      "learning_rate": 7.915635697036055e-06,
      "loss": 1.3619,
      "step": 19700
    },
    {
      "epoch": 0.911534955634786,
      "grad_norm": 1.5182384252548218,
      "learning_rate": 7.90579615555324e-06,
      "loss": 1.32,
      "step": 19750
    },
    {
      "epoch": 0.9138426390667728,
      "grad_norm": 1.5863394737243652,
      "learning_rate": 7.895939592410485e-06,
      "loss": 1.3179,
      "step": 19800
    },
    {
      "epoch": 0.9161503224987596,
      "grad_norm": 1.4974424839019775,
      "learning_rate": 7.886066065345857e-06,
      "loss": 1.3449,
      "step": 19850
    },
    {
      "epoch": 0.9184580059307464,
      "grad_norm": 1.7135976552963257,
      "learning_rate": 7.876175632196807e-06,
      "loss": 1.3654,
      "step": 19900
    },
    {
      "epoch": 0.9207656893627332,
      "grad_norm": 1.9739112854003906,
      "learning_rate": 7.866268350899806e-06,
      "loss": 1.327,
      "step": 19950
    },
    {
      "epoch": 0.92307337279472,
      "grad_norm": 1.597627878189087,
      "learning_rate": 7.856344279490025e-06,
      "loss": 1.3789,
      "step": 20000
    },
    {
      "epoch": 0.92307337279472,
      "eval_loss": 1.3264912366867065,
      "eval_runtime": 178.2088,
      "eval_samples_per_second": 28.057,
      "eval_steps_per_second": 1.173,
      "step": 20000
    },
    {
      "epoch": 0.9253810562267069,
      "grad_norm": 1.3870409727096558,
      "learning_rate": 7.846403476100987e-06,
      "loss": 1.3678,
      "step": 20050
    },
    {
      "epoch": 0.9276887396586936,
      "grad_norm": 1.799749493598938,
      "learning_rate": 7.83644599896423e-06,
      "loss": 1.3484,
      "step": 20100
    },
    {
      "epoch": 0.9299964230906804,
      "grad_norm": 1.4055681228637695,
      "learning_rate": 7.826471906408962e-06,
      "loss": 1.363,
      "step": 20150
    },
    {
      "epoch": 0.9323041065226673,
      "grad_norm": 1.7922816276550293,
      "learning_rate": 7.81648125686172e-06,
      "loss": 1.3446,
      "step": 20200
    },
    {
      "epoch": 0.934611789954654,
      "grad_norm": 1.8308813571929932,
      "learning_rate": 7.806474108846032e-06,
      "loss": 1.3647,
      "step": 20250
    },
    {
      "epoch": 0.9369194733866408,
      "grad_norm": 1.5982370376586914,
      "learning_rate": 7.79645052098207e-06,
      "loss": 1.3618,
      "step": 20300
    },
    {
      "epoch": 0.9392271568186277,
      "grad_norm": 1.483974814414978,
      "learning_rate": 7.786410551986308e-06,
      "loss": 1.3435,
      "step": 20350
    },
    {
      "epoch": 0.9415348402506144,
      "grad_norm": 1.8436840772628784,
      "learning_rate": 7.776354260671179e-06,
      "loss": 1.3479,
      "step": 20400
    },
    {
      "epoch": 0.9438425236826012,
      "grad_norm": 1.7362895011901855,
      "learning_rate": 7.766281705944724e-06,
      "loss": 1.3087,
      "step": 20450
    },
    {
      "epoch": 0.946150207114588,
      "grad_norm": 1.5720298290252686,
      "learning_rate": 7.75619294681026e-06,
      "loss": 1.3522,
      "step": 20500
    },
    {
      "epoch": 0.9484578905465748,
      "grad_norm": 1.6359012126922607,
      "learning_rate": 7.746088042366022e-06,
      "loss": 1.3691,
      "step": 20550
    },
    {
      "epoch": 0.9507655739785617,
      "grad_norm": 1.911936640739441,
      "learning_rate": 7.73616962887668e-06,
      "loss": 1.3358,
      "step": 20600
    },
    {
      "epoch": 0.9530732574105484,
      "grad_norm": 1.6155567169189453,
      "learning_rate": 7.72603293144054e-06,
      "loss": 1.3499,
      "step": 20650
    },
    {
      "epoch": 0.9553809408425352,
      "grad_norm": 1.7216105461120605,
      "learning_rate": 7.715880265366871e-06,
      "loss": 1.328,
      "step": 20700
    },
    {
      "epoch": 0.9576886242745221,
      "grad_norm": 2.00793719291687,
      "learning_rate": 7.70571169012826e-06,
      "loss": 1.339,
      "step": 20750
    },
    {
      "epoch": 0.9599963077065088,
      "grad_norm": 1.5276354551315308,
      "learning_rate": 7.695527265290499e-06,
      "loss": 1.3146,
      "step": 20800
    },
    {
      "epoch": 0.9623039911384956,
      "grad_norm": 1.4077256917953491,
      "learning_rate": 7.685327050512213e-06,
      "loss": 1.3463,
      "step": 20850
    },
    {
      "epoch": 0.9646116745704825,
      "grad_norm": 1.691112756729126,
      "learning_rate": 7.675111105544527e-06,
      "loss": 1.3394,
      "step": 20900
    },
    {
      "epoch": 0.9669193580024692,
      "grad_norm": 1.4213206768035889,
      "learning_rate": 7.664879490230712e-06,
      "loss": 1.3309,
      "step": 20950
    },
    {
      "epoch": 0.969227041434456,
      "grad_norm": 1.2321707010269165,
      "learning_rate": 7.65463226450583e-06,
      "loss": 1.3674,
      "step": 21000
    },
    {
      "epoch": 0.969227041434456,
      "eval_loss": 1.326181411743164,
      "eval_runtime": 177.9371,
      "eval_samples_per_second": 28.1,
      "eval_steps_per_second": 1.175,
      "step": 21000
    },
    {
      "epoch": 0.9715347248664428,
      "grad_norm": 1.3540774583816528,
      "learning_rate": 7.644369488396386e-06,
      "loss": 1.3471,
      "step": 21050
    },
    {
      "epoch": 0.9738424082984296,
      "grad_norm": 1.325292944908142,
      "learning_rate": 7.63409122201998e-06,
      "loss": 1.3293,
      "step": 21100
    },
    {
      "epoch": 0.9761500917304164,
      "grad_norm": 1.307486891746521,
      "learning_rate": 7.623797525584951e-06,
      "loss": 1.3625,
      "step": 21150
    },
    {
      "epoch": 0.9784577751624032,
      "grad_norm": 1.5488615036010742,
      "learning_rate": 7.613488459390017e-06,
      "loss": 1.3512,
      "step": 21200
    },
    {
      "epoch": 0.98076545859439,
      "grad_norm": 1.3815244436264038,
      "learning_rate": 7.603164083823942e-06,
      "loss": 1.3216,
      "step": 21250
    },
    {
      "epoch": 0.9830731420263769,
      "grad_norm": 1.4075684547424316,
      "learning_rate": 7.592824459365158e-06,
      "loss": 1.3091,
      "step": 21300
    },
    {
      "epoch": 0.9853808254583636,
      "grad_norm": 1.2745556831359863,
      "learning_rate": 7.58246964658143e-06,
      "loss": 1.3696,
      "step": 21350
    },
    {
      "epoch": 0.9876885088903504,
      "grad_norm": 1.5707776546478271,
      "learning_rate": 7.572099706129491e-06,
      "loss": 1.3204,
      "step": 21400
    },
    {
      "epoch": 0.9899961923223373,
      "grad_norm": 1.4639017581939697,
      "learning_rate": 7.56171469875469e-06,
      "loss": 1.3304,
      "step": 21450
    },
    {
      "epoch": 0.992303875754324,
      "grad_norm": 1.3724855184555054,
      "learning_rate": 7.551314685290634e-06,
      "loss": 1.3056,
      "step": 21500
    },
    {
      "epoch": 0.9946115591863108,
      "grad_norm": 1.4995297193527222,
      "learning_rate": 7.5408997266588325e-06,
      "loss": 1.3735,
      "step": 21550
    },
    {
      "epoch": 0.9969192426182977,
      "grad_norm": 1.2436519861221313,
      "learning_rate": 7.530469883868345e-06,
      "loss": 1.3335,
      "step": 21600
    },
    {
      "epoch": 0.9992269260502844,
      "grad_norm": 1.4747809171676636,
      "learning_rate": 7.520025218015418e-06,
      "loss": 1.3606,
      "step": 21650
    },
    {
      "epoch": 1.0015230710651113,
      "grad_norm": 1.8452646732330322,
      "learning_rate": 7.509565790283127e-06,
      "loss": 1.3364,
      "step": 21700
    },
    {
      "epoch": 1.0038307544970981,
      "grad_norm": 1.5465571880340576,
      "learning_rate": 7.499091661941022e-06,
      "loss": 1.3631,
      "step": 21750
    },
    {
      "epoch": 1.006138437929085,
      "grad_norm": 1.5941966772079468,
      "learning_rate": 7.488602894344769e-06,
      "loss": 1.314,
      "step": 21800
    },
    {
      "epoch": 1.0084461213610716,
      "grad_norm": 1.6954563856124878,
      "learning_rate": 7.478099548935782e-06,
      "loss": 1.3592,
      "step": 21850
    },
    {
      "epoch": 1.0107538047930584,
      "grad_norm": 1.5080246925354004,
      "learning_rate": 7.467581687240875e-06,
      "loss": 1.359,
      "step": 21900
    },
    {
      "epoch": 1.0130614882250453,
      "grad_norm": 1.4714487791061401,
      "learning_rate": 7.457049370871893e-06,
      "loss": 1.3099,
      "step": 21950
    },
    {
      "epoch": 1.015369171657032,
      "grad_norm": 1.4338195323944092,
      "learning_rate": 7.446502661525355e-06,
      "loss": 1.319,
      "step": 22000
    },
    {
      "epoch": 1.015369171657032,
      "eval_loss": 1.322632908821106,
      "eval_runtime": 178.3513,
      "eval_samples_per_second": 28.035,
      "eval_steps_per_second": 1.172,
      "step": 22000
    },
    {
      "epoch": 1.017676855089019,
      "grad_norm": 1.564414143562317,
      "learning_rate": 7.435941620982093e-06,
      "loss": 1.3401,
      "step": 22050
    },
    {
      "epoch": 1.0199845385210058,
      "grad_norm": 1.3972090482711792,
      "learning_rate": 7.425366311106887e-06,
      "loss": 1.3396,
      "step": 22100
    },
    {
      "epoch": 1.0222922219529924,
      "grad_norm": 2.105135917663574,
      "learning_rate": 7.414776793848102e-06,
      "loss": 1.3284,
      "step": 22150
    },
    {
      "epoch": 1.0245999053849792,
      "grad_norm": 1.5100202560424805,
      "learning_rate": 7.404173131237333e-06,
      "loss": 1.3314,
      "step": 22200
    },
    {
      "epoch": 1.026907588816966,
      "grad_norm": 1.4356976747512817,
      "learning_rate": 7.3935553853890305e-06,
      "loss": 1.3072,
      "step": 22250
    },
    {
      "epoch": 1.029215272248953,
      "grad_norm": 1.612356424331665,
      "learning_rate": 7.382923618500148e-06,
      "loss": 1.3249,
      "step": 22300
    },
    {
      "epoch": 1.0315229556809398,
      "grad_norm": 1.5615500211715698,
      "learning_rate": 7.3722778928497676e-06,
      "loss": 1.3358,
      "step": 22350
    },
    {
      "epoch": 1.0338306391129264,
      "grad_norm": 1.3899110555648804,
      "learning_rate": 7.36161827079874e-06,
      "loss": 1.3303,
      "step": 22400
    },
    {
      "epoch": 1.0361383225449132,
      "grad_norm": 1.4234883785247803,
      "learning_rate": 7.350944814789318e-06,
      "loss": 1.3308,
      "step": 22450
    },
    {
      "epoch": 1.0384460059769,
      "grad_norm": 1.606736183166504,
      "learning_rate": 7.340257587344794e-06,
      "loss": 1.3256,
      "step": 22500
    },
    {
      "epoch": 1.040753689408887,
      "grad_norm": 1.5634912252426147,
      "learning_rate": 7.329556651069131e-06,
      "loss": 1.371,
      "step": 22550
    },
    {
      "epoch": 1.0430613728408737,
      "grad_norm": 1.3398995399475098,
      "learning_rate": 7.318842068646593e-06,
      "loss": 1.3347,
      "step": 22600
    },
    {
      "epoch": 1.0453690562728606,
      "grad_norm": 1.4180899858474731,
      "learning_rate": 7.308113902841382e-06,
      "loss": 1.3497,
      "step": 22650
    },
    {
      "epoch": 1.0476767397048472,
      "grad_norm": 1.4001169204711914,
      "learning_rate": 7.297372216497271e-06,
      "loss": 1.3166,
      "step": 22700
    },
    {
      "epoch": 1.049984423136834,
      "grad_norm": 1.3159528970718384,
      "learning_rate": 7.2866170725372306e-06,
      "loss": 1.3135,
      "step": 22750
    },
    {
      "epoch": 1.0522921065688209,
      "grad_norm": 1.6109669208526611,
      "learning_rate": 7.275848533963069e-06,
      "loss": 1.3771,
      "step": 22800
    },
    {
      "epoch": 1.0545997900008077,
      "grad_norm": 1.6259294748306274,
      "learning_rate": 7.2650666638550535e-06,
      "loss": 1.2996,
      "step": 22850
    },
    {
      "epoch": 1.0569074734327946,
      "grad_norm": 1.7084343433380127,
      "learning_rate": 7.254271525371546e-06,
      "loss": 1.3527,
      "step": 22900
    },
    {
      "epoch": 1.0592151568647812,
      "grad_norm": 1.4496484994888306,
      "learning_rate": 7.2434631817486335e-06,
      "loss": 1.3186,
      "step": 22950
    },
    {
      "epoch": 1.061522840296768,
      "grad_norm": 1.4842808246612549,
      "learning_rate": 7.232641696299754e-06,
      "loss": 1.3162,
      "step": 23000
    },
    {
      "epoch": 1.061522840296768,
      "eval_loss": 1.323289155960083,
      "eval_runtime": 178.3834,
      "eval_samples_per_second": 28.03,
      "eval_steps_per_second": 1.172,
      "step": 23000
    },
    {
      "epoch": 1.0638305237287549,
      "grad_norm": 1.389695405960083,
      "learning_rate": 7.221807132415331e-06,
      "loss": 1.3397,
      "step": 23050
    },
    {
      "epoch": 1.0661382071607417,
      "grad_norm": 1.8950284719467163,
      "learning_rate": 7.210959553562397e-06,
      "loss": 1.3553,
      "step": 23100
    },
    {
      "epoch": 1.0684458905927285,
      "grad_norm": 1.6522051095962524,
      "learning_rate": 7.200099023284227e-06,
      "loss": 1.3126,
      "step": 23150
    },
    {
      "epoch": 1.0707535740247154,
      "grad_norm": 1.5844911336898804,
      "learning_rate": 7.18922560519996e-06,
      "loss": 1.3167,
      "step": 23200
    },
    {
      "epoch": 1.073061257456702,
      "grad_norm": 1.579250693321228,
      "learning_rate": 7.178339363004232e-06,
      "loss": 1.3529,
      "step": 23250
    },
    {
      "epoch": 1.0753689408886888,
      "grad_norm": 1.6130703687667847,
      "learning_rate": 7.1674403604667965e-06,
      "loss": 1.3012,
      "step": 23300
    },
    {
      "epoch": 1.0776766243206757,
      "grad_norm": 1.3401845693588257,
      "learning_rate": 7.15652866143216e-06,
      "loss": 1.3316,
      "step": 23350
    },
    {
      "epoch": 1.0799843077526625,
      "grad_norm": 1.6394455432891846,
      "learning_rate": 7.1456043298192e-06,
      "loss": 1.3151,
      "step": 23400
    },
    {
      "epoch": 1.0822919911846494,
      "grad_norm": 1.5628552436828613,
      "learning_rate": 7.134667429620796e-06,
      "loss": 1.3306,
      "step": 23450
    },
    {
      "epoch": 1.0845996746166362,
      "grad_norm": 1.7079850435256958,
      "learning_rate": 7.123718024903446e-06,
      "loss": 1.2924,
      "step": 23500
    },
    {
      "epoch": 1.0869073580486228,
      "grad_norm": 1.40892493724823,
      "learning_rate": 7.112756179806906e-06,
      "loss": 1.3187,
      "step": 23550
    },
    {
      "epoch": 1.0892150414806097,
      "grad_norm": 1.729163646697998,
      "learning_rate": 7.101781958543797e-06,
      "loss": 1.3345,
      "step": 23600
    },
    {
      "epoch": 1.0915227249125965,
      "grad_norm": 1.53681218624115,
      "learning_rate": 7.090795425399246e-06,
      "loss": 1.3362,
      "step": 23650
    },
    {
      "epoch": 1.0938304083445833,
      "grad_norm": 1.477318286895752,
      "learning_rate": 7.079796644730495e-06,
      "loss": 1.3274,
      "step": 23700
    },
    {
      "epoch": 1.0961380917765702,
      "grad_norm": 1.6210815906524658,
      "learning_rate": 7.068785680966531e-06,
      "loss": 1.3076,
      "step": 23750
    },
    {
      "epoch": 1.0984457752085568,
      "grad_norm": 1.7492475509643555,
      "learning_rate": 7.057762598607709e-06,
      "loss": 1.2941,
      "step": 23800
    },
    {
      "epoch": 1.1007534586405436,
      "grad_norm": 1.4599584341049194,
      "learning_rate": 7.046727462225369e-06,
      "loss": 1.3485,
      "step": 23850
    },
    {
      "epoch": 1.1030611420725305,
      "grad_norm": 1.5947767496109009,
      "learning_rate": 7.035680336461467e-06,
      "loss": 1.2876,
      "step": 23900
    },
    {
      "epoch": 1.1053688255045173,
      "grad_norm": 1.6296190023422241,
      "learning_rate": 7.024621286028186e-06,
      "loss": 1.3387,
      "step": 23950
    },
    {
      "epoch": 1.1076765089365042,
      "grad_norm": 1.5378764867782593,
      "learning_rate": 7.013550375707567e-06,
      "loss": 1.3223,
      "step": 24000
    },
    {
      "epoch": 1.1076765089365042,
      "eval_loss": 1.32206392288208,
      "eval_runtime": 178.3097,
      "eval_samples_per_second": 28.041,
      "eval_steps_per_second": 1.172,
      "step": 24000
    },
    {
      "epoch": 1.1099841923684908,
      "grad_norm": 1.3424577713012695,
      "learning_rate": 7.0024676703511165e-06,
      "loss": 1.3293,
      "step": 24050
    },
    {
      "epoch": 1.1122918758004776,
      "grad_norm": 1.756030559539795,
      "learning_rate": 6.991373234879442e-06,
      "loss": 1.3289,
      "step": 24100
    },
    {
      "epoch": 1.1145995592324645,
      "grad_norm": 1.678093433380127,
      "learning_rate": 6.980267134281857e-06,
      "loss": 1.3163,
      "step": 24150
    },
    {
      "epoch": 1.1169072426644513,
      "grad_norm": 1.6513371467590332,
      "learning_rate": 6.969149433616015e-06,
      "loss": 1.3208,
      "step": 24200
    },
    {
      "epoch": 1.1192149260964381,
      "grad_norm": 1.587456226348877,
      "learning_rate": 6.958020198007513e-06,
      "loss": 1.3325,
      "step": 24250
    },
    {
      "epoch": 1.121522609528425,
      "grad_norm": 1.5659934282302856,
      "learning_rate": 6.946879492649525e-06,
      "loss": 1.3328,
      "step": 24300
    },
    {
      "epoch": 1.1238302929604116,
      "grad_norm": 1.7770127058029175,
      "learning_rate": 6.935727382802406e-06,
      "loss": 1.3301,
      "step": 24350
    },
    {
      "epoch": 1.1261379763923984,
      "grad_norm": 1.6546350717544556,
      "learning_rate": 6.924563933793321e-06,
      "loss": 1.3512,
      "step": 24400
    },
    {
      "epoch": 1.1284456598243853,
      "grad_norm": 1.6032334566116333,
      "learning_rate": 6.913389211015857e-06,
      "loss": 1.3514,
      "step": 24450
    },
    {
      "epoch": 1.1307533432563721,
      "grad_norm": 1.6513099670410156,
      "learning_rate": 6.902203279929641e-06,
      "loss": 1.3074,
      "step": 24500
    },
    {
      "epoch": 1.133061026688359,
      "grad_norm": 1.4707990884780884,
      "learning_rate": 6.891006206059956e-06,
      "loss": 1.3497,
      "step": 24550
    },
    {
      "epoch": 1.1353687101203458,
      "grad_norm": 1.5663785934448242,
      "learning_rate": 6.8797980549973556e-06,
      "loss": 1.3501,
      "step": 24600
    },
    {
      "epoch": 1.1376763935523324,
      "grad_norm": 1.5139249563217163,
      "learning_rate": 6.868578892397284e-06,
      "loss": 1.3235,
      "step": 24650
    },
    {
      "epoch": 1.1399840769843193,
      "grad_norm": 1.5288828611373901,
      "learning_rate": 6.857348783979689e-06,
      "loss": 1.3501,
      "step": 24700
    },
    {
      "epoch": 1.142291760416306,
      "grad_norm": 1.6603312492370605,
      "learning_rate": 6.846107795528638e-06,
      "loss": 1.3341,
      "step": 24750
    },
    {
      "epoch": 1.144599443848293,
      "grad_norm": 1.6459987163543701,
      "learning_rate": 6.834855992891929e-06,
      "loss": 1.3358,
      "step": 24800
    },
    {
      "epoch": 1.1469071272802798,
      "grad_norm": 1.7629539966583252,
      "learning_rate": 6.82359344198071e-06,
      "loss": 1.3302,
      "step": 24850
    },
    {
      "epoch": 1.1492148107122664,
      "grad_norm": 1.60916006565094,
      "learning_rate": 6.812320208769089e-06,
      "loss": 1.3221,
      "step": 24900
    },
    {
      "epoch": 1.1515224941442532,
      "grad_norm": 1.6998745203018188,
      "learning_rate": 6.801036359293751e-06,
      "loss": 1.3426,
      "step": 24950
    },
    {
      "epoch": 1.15383017757624,
      "grad_norm": 1.8979970216751099,
      "learning_rate": 6.789741959653567e-06,
      "loss": 1.2909,
      "step": 25000
    },
    {
      "epoch": 1.15383017757624,
      "eval_loss": 1.3221988677978516,
      "eval_runtime": 178.2117,
      "eval_samples_per_second": 28.057,
      "eval_steps_per_second": 1.173,
      "step": 25000
    },
    {
      "epoch": 1.156137861008227,
      "grad_norm": 1.9095135927200317,
      "learning_rate": 6.778437076009212e-06,
      "loss": 1.3588,
      "step": 25050
    },
    {
      "epoch": 1.1584455444402137,
      "grad_norm": 1.6465333700180054,
      "learning_rate": 6.76712177458277e-06,
      "loss": 1.3136,
      "step": 25100
    },
    {
      "epoch": 1.1607532278722006,
      "grad_norm": 1.5356884002685547,
      "learning_rate": 6.755796121657356e-06,
      "loss": 1.3489,
      "step": 25150
    },
    {
      "epoch": 1.1630609113041872,
      "grad_norm": 1.668105125427246,
      "learning_rate": 6.744460183576717e-06,
      "loss": 1.3155,
      "step": 25200
    },
    {
      "epoch": 1.165368594736174,
      "grad_norm": 1.3812769651412964,
      "learning_rate": 6.733114026744854e-06,
      "loss": 1.3415,
      "step": 25250
    },
    {
      "epoch": 1.1676762781681609,
      "grad_norm": 1.4423964023590088,
      "learning_rate": 6.721757717625623e-06,
      "loss": 1.339,
      "step": 25300
    },
    {
      "epoch": 1.1699839616001477,
      "grad_norm": 1.6931160688400269,
      "learning_rate": 6.710391322742356e-06,
      "loss": 1.3346,
      "step": 25350
    },
    {
      "epoch": 1.1722916450321346,
      "grad_norm": 1.5095406770706177,
      "learning_rate": 6.699014908677457e-06,
      "loss": 1.3441,
      "step": 25400
    },
    {
      "epoch": 1.1745993284641214,
      "grad_norm": 1.6033201217651367,
      "learning_rate": 6.687628542072029e-06,
      "loss": 1.3258,
      "step": 25450
    },
    {
      "epoch": 1.176907011896108,
      "grad_norm": 1.630974292755127,
      "learning_rate": 6.676232289625471e-06,
      "loss": 1.3544,
      "step": 25500
    },
    {
      "epoch": 1.1792146953280949,
      "grad_norm": 1.7806133031845093,
      "learning_rate": 6.664826218095093e-06,
      "loss": 1.361,
      "step": 25550
    },
    {
      "epoch": 1.1815223787600817,
      "grad_norm": 1.632522702217102,
      "learning_rate": 6.653410394295724e-06,
      "loss": 1.3257,
      "step": 25600
    },
    {
      "epoch": 1.1838300621920685,
      "grad_norm": 1.4933655261993408,
      "learning_rate": 6.641984885099317e-06,
      "loss": 1.3349,
      "step": 25650
    },
    {
      "epoch": 1.1861377456240554,
      "grad_norm": 1.7451590299606323,
      "learning_rate": 6.6305497574345654e-06,
      "loss": 1.3453,
      "step": 25700
    },
    {
      "epoch": 1.188445429056042,
      "grad_norm": 1.5291390419006348,
      "learning_rate": 6.619105078286502e-06,
      "loss": 1.3393,
      "step": 25750
    },
    {
      "epoch": 1.1907531124880288,
      "grad_norm": 1.6877292394638062,
      "learning_rate": 6.607650914696112e-06,
      "loss": 1.342,
      "step": 25800
    },
    {
      "epoch": 1.1930607959200157,
      "grad_norm": 1.5736799240112305,
      "learning_rate": 6.596187333759938e-06,
      "loss": 1.3376,
      "step": 25850
    },
    {
      "epoch": 1.1953684793520025,
      "grad_norm": 1.675697922706604,
      "learning_rate": 6.584714402629689e-06,
      "loss": 1.316,
      "step": 25900
    },
    {
      "epoch": 1.1976761627839894,
      "grad_norm": 1.8396027088165283,
      "learning_rate": 6.573232188511845e-06,
      "loss": 1.326,
      "step": 25950
    },
    {
      "epoch": 1.199983846215976,
      "grad_norm": 1.4962289333343506,
      "learning_rate": 6.561740758667266e-06,
      "loss": 1.2875,
      "step": 26000
    },
    {
      "epoch": 1.199983846215976,
      "eval_loss": 1.320682168006897,
      "eval_runtime": 177.8136,
      "eval_samples_per_second": 28.119,
      "eval_steps_per_second": 1.175,
      "step": 26000
    },
    {
      "epoch": 1.2022915296479628,
      "grad_norm": 1.4163408279418945,
      "learning_rate": 6.5504702811947095e-06,
      "loss": 1.324,
      "step": 26050
    },
    {
      "epoch": 1.2045992130799497,
      "grad_norm": 1.8788024187088013,
      "learning_rate": 6.5389608028550885e-06,
      "loss": 1.3312,
      "step": 26100
    },
    {
      "epoch": 1.2069068965119365,
      "grad_norm": 1.5148788690567017,
      "learning_rate": 6.527442309544685e-06,
      "loss": 1.332,
      "step": 26150
    },
    {
      "epoch": 1.2092145799439233,
      "grad_norm": 1.6821925640106201,
      "learning_rate": 6.515914868736871e-06,
      "loss": 1.3338,
      "step": 26200
    },
    {
      "epoch": 1.2115222633759102,
      "grad_norm": 1.794545292854309,
      "learning_rate": 6.504378547957439e-06,
      "loss": 1.3394,
      "step": 26250
    },
    {
      "epoch": 1.2138299468078968,
      "grad_norm": 1.5097174644470215,
      "learning_rate": 6.492833414784192e-06,
      "loss": 1.33,
      "step": 26300
    },
    {
      "epoch": 1.2161376302398836,
      "grad_norm": 1.6818313598632812,
      "learning_rate": 6.481279536846561e-06,
      "loss": 1.3305,
      "step": 26350
    },
    {
      "epoch": 1.2184453136718705,
      "grad_norm": 1.445190191268921,
      "learning_rate": 6.4697169818251945e-06,
      "loss": 1.35,
      "step": 26400
    },
    {
      "epoch": 1.2207529971038573,
      "grad_norm": 1.7883989810943604,
      "learning_rate": 6.4581458174515775e-06,
      "loss": 1.357,
      "step": 26450
    },
    {
      "epoch": 1.2230606805358442,
      "grad_norm": 1.5364338159561157,
      "learning_rate": 6.446566111507624e-06,
      "loss": 1.338,
      "step": 26500
    },
    {
      "epoch": 1.225368363967831,
      "grad_norm": 1.6638609170913696,
      "learning_rate": 6.434977931825281e-06,
      "loss": 1.3348,
      "step": 26550
    },
    {
      "epoch": 1.2276760473998176,
      "grad_norm": 1.9247432947158813,
      "learning_rate": 6.423381346286137e-06,
      "loss": 1.2879,
      "step": 26600
    },
    {
      "epoch": 1.2299837308318045,
      "grad_norm": 1.812583565711975,
      "learning_rate": 6.41177642282102e-06,
      "loss": 1.332,
      "step": 26650
    },
    {
      "epoch": 1.2322914142637913,
      "grad_norm": 1.5547165870666504,
      "learning_rate": 6.400163229409596e-06,
      "loss": 1.3281,
      "step": 26700
    },
    {
      "epoch": 1.2345990976957781,
      "grad_norm": 1.6260566711425781,
      "learning_rate": 6.38854183407998e-06,
      "loss": 1.3139,
      "step": 26750
    },
    {
      "epoch": 1.236906781127765,
      "grad_norm": 1.6591205596923828,
      "learning_rate": 6.376912304908329e-06,
      "loss": 1.3001,
      "step": 26800
    },
    {
      "epoch": 1.2392144645597516,
      "grad_norm": 1.7385751008987427,
      "learning_rate": 6.36527471001845e-06,
      "loss": 1.3151,
      "step": 26850
    },
    {
      "epoch": 1.2415221479917384,
      "grad_norm": 1.6535831689834595,
      "learning_rate": 6.353629117581395e-06,
      "loss": 1.3599,
      "step": 26900
    },
    {
      "epoch": 1.2438298314237253,
      "grad_norm": 1.626987099647522,
      "learning_rate": 6.341975595815062e-06,
      "loss": 1.3418,
      "step": 26950
    },
    {
      "epoch": 1.2461375148557121,
      "grad_norm": 1.6143946647644043,
      "learning_rate": 6.330314212983805e-06,
      "loss": 1.3288,
      "step": 27000
    },
    {
      "epoch": 1.2461375148557121,
      "eval_loss": 1.3209834098815918,
      "eval_runtime": 177.8793,
      "eval_samples_per_second": 28.109,
      "eval_steps_per_second": 1.175,
      "step": 27000
    },
    {
      "epoch": 1.248445198287699,
      "grad_norm": 1.8445202112197876,
      "learning_rate": 6.318645037398019e-06,
      "loss": 1.3286,
      "step": 27050
    },
    {
      "epoch": 1.2507528817196856,
      "grad_norm": 1.8495044708251953,
      "learning_rate": 6.3069681374137534e-06,
      "loss": 1.3672,
      "step": 27100
    },
    {
      "epoch": 1.2530605651516724,
      "grad_norm": 1.62735915184021,
      "learning_rate": 6.295283581432303e-06,
      "loss": 1.3481,
      "step": 27150
    },
    {
      "epoch": 1.2553682485836593,
      "grad_norm": 1.8508200645446777,
      "learning_rate": 6.2835914378998095e-06,
      "loss": 1.3393,
      "step": 27200
    },
    {
      "epoch": 1.257675932015646,
      "grad_norm": 1.5577661991119385,
      "learning_rate": 6.271891775306862e-06,
      "loss": 1.348,
      "step": 27250
    },
    {
      "epoch": 1.259983615447633,
      "grad_norm": 1.6574722528457642,
      "learning_rate": 6.260184662188097e-06,
      "loss": 1.315,
      "step": 27300
    },
    {
      "epoch": 1.2622912988796198,
      "grad_norm": 1.6579254865646362,
      "learning_rate": 6.248470167121792e-06,
      "loss": 1.3573,
      "step": 27350
    },
    {
      "epoch": 1.2645989823116066,
      "grad_norm": 1.5600484609603882,
      "learning_rate": 6.236748358729467e-06,
      "loss": 1.3412,
      "step": 27400
    },
    {
      "epoch": 1.2669066657435932,
      "grad_norm": 1.5787293910980225,
      "learning_rate": 6.225019305675484e-06,
      "loss": 1.2926,
      "step": 27450
    },
    {
      "epoch": 1.26921434917558,
      "grad_norm": 1.9914625883102417,
      "learning_rate": 6.213283076666643e-06,
      "loss": 1.3396,
      "step": 27500
    },
    {
      "epoch": 1.271522032607567,
      "grad_norm": 1.6024879217147827,
      "learning_rate": 6.201539740451777e-06,
      "loss": 1.3206,
      "step": 27550
    },
    {
      "epoch": 1.2738297160395537,
      "grad_norm": 1.8275507688522339,
      "learning_rate": 6.189789365821353e-06,
      "loss": 1.305,
      "step": 27600
    },
    {
      "epoch": 1.2761373994715406,
      "grad_norm": 1.9568958282470703,
      "learning_rate": 6.178032021607071e-06,
      "loss": 1.3215,
      "step": 27650
    },
    {
      "epoch": 1.2784450829035272,
      "grad_norm": 1.7022041082382202,
      "learning_rate": 6.166267776681451e-06,
      "loss": 1.3299,
      "step": 27700
    },
    {
      "epoch": 1.280752766335514,
      "grad_norm": 1.74421226978302,
      "learning_rate": 6.154496699957444e-06,
      "loss": 1.2877,
      "step": 27750
    },
    {
      "epoch": 1.2830604497675009,
      "grad_norm": 1.6282674074172974,
      "learning_rate": 6.142718860388014e-06,
      "loss": 1.3263,
      "step": 27800
    },
    {
      "epoch": 1.2853681331994877,
      "grad_norm": 1.5755274295806885,
      "learning_rate": 6.130934326965743e-06,
      "loss": 1.2993,
      "step": 27850
    },
    {
      "epoch": 1.2876758166314746,
      "grad_norm": 1.9579572677612305,
      "learning_rate": 6.119143168722425e-06,
      "loss": 1.3261,
      "step": 27900
    },
    {
      "epoch": 1.2899835000634612,
      "grad_norm": 1.882307529449463,
      "learning_rate": 6.1073454547286625e-06,
      "loss": 1.3318,
      "step": 27950
    },
    {
      "epoch": 1.292291183495448,
      "grad_norm": 1.939072608947754,
      "learning_rate": 6.095541254093457e-06,
      "loss": 1.3403,
      "step": 28000
    },
    {
      "epoch": 1.292291183495448,
      "eval_loss": 1.3176963329315186,
      "eval_runtime": 177.9203,
      "eval_samples_per_second": 28.102,
      "eval_steps_per_second": 1.175,
      "step": 28000
    },
    {
      "epoch": 1.2945988669274349,
      "grad_norm": 1.905798316001892,
      "learning_rate": 6.0837306359638084e-06,
      "loss": 1.3123,
      "step": 28050
    },
    {
      "epoch": 1.2969065503594217,
      "grad_norm": 1.7225983142852783,
      "learning_rate": 6.071913669524312e-06,
      "loss": 1.3491,
      "step": 28100
    },
    {
      "epoch": 1.2992142337914085,
      "grad_norm": 1.5382517576217651,
      "learning_rate": 6.060090423996746e-06,
      "loss": 1.3456,
      "step": 28150
    },
    {
      "epoch": 1.3015219172233952,
      "grad_norm": 1.6037620306015015,
      "learning_rate": 6.048260968639677e-06,
      "loss": 1.334,
      "step": 28200
    },
    {
      "epoch": 1.3038296006553822,
      "grad_norm": 1.6318944692611694,
      "learning_rate": 6.036425372748041e-06,
      "loss": 1.3406,
      "step": 28250
    },
    {
      "epoch": 1.3061372840873688,
      "grad_norm": 1.9311468601226807,
      "learning_rate": 6.024583705652744e-06,
      "loss": 1.3335,
      "step": 28300
    },
    {
      "epoch": 1.3084449675193557,
      "grad_norm": 1.40023672580719,
      "learning_rate": 6.012736036720266e-06,
      "loss": 1.3242,
      "step": 28350
    },
    {
      "epoch": 1.3107526509513425,
      "grad_norm": 1.8041404485702515,
      "learning_rate": 6.000882435352232e-06,
      "loss": 1.3097,
      "step": 28400
    },
    {
      "epoch": 1.3130603343833294,
      "grad_norm": 1.8807095289230347,
      "learning_rate": 5.989260217280482e-06,
      "loss": 1.3316,
      "step": 28450
    },
    {
      "epoch": 1.3153680178153162,
      "grad_norm": 1.8073108196258545,
      "learning_rate": 5.977395074574364e-06,
      "loss": 1.3468,
      "step": 28500
    },
    {
      "epoch": 1.3176757012473028,
      "grad_norm": 1.4988517761230469,
      "learning_rate": 5.965524206454043e-06,
      "loss": 1.3401,
      "step": 28550
    },
    {
      "epoch": 1.3199833846792897,
      "grad_norm": 1.6470049619674683,
      "learning_rate": 5.953647682457043e-06,
      "loss": 1.3353,
      "step": 28600
    },
    {
      "epoch": 1.3222910681112765,
      "grad_norm": 1.886756420135498,
      "learning_rate": 5.941765572154025e-06,
      "loss": 1.3338,
      "step": 28650
    },
    {
      "epoch": 1.3245987515432633,
      "grad_norm": 1.5149116516113281,
      "learning_rate": 5.929877945148369e-06,
      "loss": 1.3189,
      "step": 28700
    },
    {
      "epoch": 1.3269064349752502,
      "grad_norm": 1.4692649841308594,
      "learning_rate": 5.9179848710757745e-06,
      "loss": 1.3511,
      "step": 28750
    },
    {
      "epoch": 1.3292141184072368,
      "grad_norm": 1.442693829536438,
      "learning_rate": 5.906086419603849e-06,
      "loss": 1.3362,
      "step": 28800
    },
    {
      "epoch": 1.3315218018392236,
      "grad_norm": 1.5183508396148682,
      "learning_rate": 5.8941826604316976e-06,
      "loss": 1.2698,
      "step": 28850
    },
    {
      "epoch": 1.3338294852712105,
      "grad_norm": 1.9445852041244507,
      "learning_rate": 5.882273663289519e-06,
      "loss": 1.3407,
      "step": 28900
    },
    {
      "epoch": 1.3361371687031973,
      "grad_norm": 1.656011939048767,
      "learning_rate": 5.870359497938192e-06,
      "loss": 1.3581,
      "step": 28950
    },
    {
      "epoch": 1.3384448521351842,
      "grad_norm": 1.6777516603469849,
      "learning_rate": 5.858440234168873e-06,
      "loss": 1.3612,
      "step": 29000
    },
    {
      "epoch": 1.3384448521351842,
      "eval_loss": 1.3184033632278442,
      "eval_runtime": 177.8129,
      "eval_samples_per_second": 28.119,
      "eval_steps_per_second": 1.175,
      "step": 29000
    },
    {
      "epoch": 1.3407525355671708,
      "grad_norm": 1.6202195882797241,
      "learning_rate": 5.846515941802583e-06,
      "loss": 1.3244,
      "step": 29050
    },
    {
      "epoch": 1.3430602189991576,
      "grad_norm": 1.6824028491973877,
      "learning_rate": 5.8345866906898006e-06,
      "loss": 1.3287,
      "step": 29100
    },
    {
      "epoch": 1.3453679024311445,
      "grad_norm": 1.6453393697738647,
      "learning_rate": 5.822652550710051e-06,
      "loss": 1.3472,
      "step": 29150
    },
    {
      "epoch": 1.3476755858631313,
      "grad_norm": 1.6457468271255493,
      "learning_rate": 5.810713591771496e-06,
      "loss": 1.3055,
      "step": 29200
    },
    {
      "epoch": 1.3499832692951181,
      "grad_norm": 1.7113348245620728,
      "learning_rate": 5.79876988381053e-06,
      "loss": 1.3114,
      "step": 29250
    },
    {
      "epoch": 1.352290952727105,
      "grad_norm": 1.5823907852172852,
      "learning_rate": 5.786821496791363e-06,
      "loss": 1.3051,
      "step": 29300
    },
    {
      "epoch": 1.3545986361590918,
      "grad_norm": 1.6842974424362183,
      "learning_rate": 5.774868500705612e-06,
      "loss": 1.3388,
      "step": 29350
    },
    {
      "epoch": 1.3569063195910784,
      "grad_norm": 1.5409435033798218,
      "learning_rate": 5.762910965571902e-06,
      "loss": 1.342,
      "step": 29400
    },
    {
      "epoch": 1.3592140030230653,
      "grad_norm": 1.4931772947311401,
      "learning_rate": 5.750948961435437e-06,
      "loss": 1.3313,
      "step": 29450
    },
    {
      "epoch": 1.3615216864550521,
      "grad_norm": 1.355272650718689,
      "learning_rate": 5.7389825583676064e-06,
      "loss": 1.3331,
      "step": 29500
    },
    {
      "epoch": 1.363829369887039,
      "grad_norm": 1.4796850681304932,
      "learning_rate": 5.727011826465563e-06,
      "loss": 1.3147,
      "step": 29550
    },
    {
      "epoch": 1.3661370533190258,
      "grad_norm": 1.9794389009475708,
      "learning_rate": 5.715036835851821e-06,
      "loss": 1.3325,
      "step": 29600
    },
    {
      "epoch": 1.3684447367510124,
      "grad_norm": 1.6836137771606445,
      "learning_rate": 5.703057656673839e-06,
      "loss": 1.3347,
      "step": 29650
    },
    {
      "epoch": 1.3707524201829993,
      "grad_norm": 1.7027100324630737,
      "learning_rate": 5.691074359103612e-06,
      "loss": 1.3302,
      "step": 29700
    },
    {
      "epoch": 1.373060103614986,
      "grad_norm": 1.6504950523376465,
      "learning_rate": 5.679087013337262e-06,
      "loss": 1.3352,
      "step": 29750
    },
    {
      "epoch": 1.375367787046973,
      "grad_norm": 1.473349928855896,
      "learning_rate": 5.667095689594622e-06,
      "loss": 1.3203,
      "step": 29800
    },
    {
      "epoch": 1.3776754704789598,
      "grad_norm": 1.6065441370010376,
      "learning_rate": 5.655100458118828e-06,
      "loss": 1.3114,
      "step": 29850
    },
    {
      "epoch": 1.3799831539109464,
      "grad_norm": 1.7634202241897583,
      "learning_rate": 5.643101389175906e-06,
      "loss": 1.3419,
      "step": 29900
    },
    {
      "epoch": 1.3822908373429332,
      "grad_norm": 1.5125751495361328,
      "learning_rate": 5.631098553054363e-06,
      "loss": 1.3683,
      "step": 29950
    },
    {
      "epoch": 1.38459852077492,
      "grad_norm": 1.5530307292938232,
      "learning_rate": 5.619092020064774e-06,
      "loss": 1.3483,
      "step": 30000
    },
    {
      "epoch": 1.38459852077492,
      "eval_loss": 1.315229892730713,
      "eval_runtime": 178.2894,
      "eval_samples_per_second": 28.044,
      "eval_steps_per_second": 1.172,
      "step": 30000
    },
    {
      "epoch": 1.386906204206907,
      "grad_norm": 1.5027432441711426,
      "learning_rate": 5.607081860539365e-06,
      "loss": 1.3139,
      "step": 30050
    },
    {
      "epoch": 1.3892138876388938,
      "grad_norm": 1.672611117362976,
      "learning_rate": 5.595068144831613e-06,
      "loss": 1.3244,
      "step": 30100
    },
    {
      "epoch": 1.3915215710708804,
      "grad_norm": 1.5190799236297607,
      "learning_rate": 5.583050943315821e-06,
      "loss": 1.308,
      "step": 30150
    },
    {
      "epoch": 1.3938292545028674,
      "grad_norm": 1.6894713640213013,
      "learning_rate": 5.57103032638671e-06,
      "loss": 1.319,
      "step": 30200
    },
    {
      "epoch": 1.396136937934854,
      "grad_norm": 1.6881263256072998,
      "learning_rate": 5.559006364459017e-06,
      "loss": 1.3395,
      "step": 30250
    },
    {
      "epoch": 1.398444621366841,
      "grad_norm": 1.8194975852966309,
      "learning_rate": 5.546979127967061e-06,
      "loss": 1.362,
      "step": 30300
    },
    {
      "epoch": 1.4007523047988277,
      "grad_norm": 1.8812236785888672,
      "learning_rate": 5.53494868736435e-06,
      "loss": 1.3423,
      "step": 30350
    },
    {
      "epoch": 1.4030599882308146,
      "grad_norm": 1.5430397987365723,
      "learning_rate": 5.522915113123163e-06,
      "loss": 1.3204,
      "step": 30400
    },
    {
      "epoch": 1.4053676716628014,
      "grad_norm": 1.756072759628296,
      "learning_rate": 5.5108784757341285e-06,
      "loss": 1.3066,
      "step": 30450
    },
    {
      "epoch": 1.407675355094788,
      "grad_norm": 1.5048500299453735,
      "learning_rate": 5.498838845705824e-06,
      "loss": 1.3235,
      "step": 30500
    },
    {
      "epoch": 1.4099830385267749,
      "grad_norm": 1.8976207971572876,
      "learning_rate": 5.486796293564358e-06,
      "loss": 1.3302,
      "step": 30550
    },
    {
      "epoch": 1.4122907219587617,
      "grad_norm": 1.8265857696533203,
      "learning_rate": 5.474750889852951e-06,
      "loss": 1.3185,
      "step": 30600
    },
    {
      "epoch": 1.4145984053907485,
      "grad_norm": 1.6910853385925293,
      "learning_rate": 5.462702705131532e-06,
      "loss": 1.3398,
      "step": 30650
    },
    {
      "epoch": 1.4169060888227354,
      "grad_norm": 1.6413170099258423,
      "learning_rate": 5.4506518099763175e-06,
      "loss": 1.3293,
      "step": 30700
    },
    {
      "epoch": 1.419213772254722,
      "grad_norm": 1.83014714717865,
      "learning_rate": 5.438598274979403e-06,
      "loss": 1.3082,
      "step": 30750
    },
    {
      "epoch": 1.4215214556867088,
      "grad_norm": 1.113195538520813,
      "learning_rate": 5.42654217074835e-06,
      "loss": 1.3445,
      "step": 30800
    },
    {
      "epoch": 1.4238291391186957,
      "grad_norm": 1.5500813722610474,
      "learning_rate": 5.414483567905766e-06,
      "loss": 1.3315,
      "step": 30850
    },
    {
      "epoch": 1.4261368225506825,
      "grad_norm": 1.626527190208435,
      "learning_rate": 5.402422537088895e-06,
      "loss": 1.3232,
      "step": 30900
    },
    {
      "epoch": 1.4284445059826694,
      "grad_norm": 1.700847864151001,
      "learning_rate": 5.390359148949209e-06,
      "loss": 1.3036,
      "step": 30950
    },
    {
      "epoch": 1.430752189414656,
      "grad_norm": 1.5393304824829102,
      "learning_rate": 5.378293474151982e-06,
      "loss": 1.297,
      "step": 31000
    },
    {
      "epoch": 1.430752189414656,
      "eval_loss": 1.3150101900100708,
      "eval_runtime": 178.4612,
      "eval_samples_per_second": 28.017,
      "eval_steps_per_second": 1.171,
      "step": 31000
    },
    {
      "epoch": 1.4330598728466428,
      "grad_norm": 1.6852279901504517,
      "learning_rate": 5.366225583375888e-06,
      "loss": 1.3542,
      "step": 31050
    },
    {
      "epoch": 1.4353675562786297,
      "grad_norm": 1.7820152044296265,
      "learning_rate": 5.354155547312578e-06,
      "loss": 1.3164,
      "step": 31100
    },
    {
      "epoch": 1.4376752397106165,
      "grad_norm": 1.6267344951629639,
      "learning_rate": 5.342083436666274e-06,
      "loss": 1.3623,
      "step": 31150
    },
    {
      "epoch": 1.4399829231426033,
      "grad_norm": 1.4163271188735962,
      "learning_rate": 5.330009322153346e-06,
      "loss": 1.3326,
      "step": 31200
    },
    {
      "epoch": 1.44229060657459,
      "grad_norm": 1.7294559478759766,
      "learning_rate": 5.3179332745019066e-06,
      "loss": 1.3362,
      "step": 31250
    },
    {
      "epoch": 1.444598290006577,
      "grad_norm": 1.3484338521957397,
      "learning_rate": 5.305855364451387e-06,
      "loss": 1.3146,
      "step": 31300
    },
    {
      "epoch": 1.4469059734385636,
      "grad_norm": 1.6859561204910278,
      "learning_rate": 5.293775662752132e-06,
      "loss": 1.3369,
      "step": 31350
    },
    {
      "epoch": 1.4492136568705505,
      "grad_norm": 1.3987911939620972,
      "learning_rate": 5.281694240164984e-06,
      "loss": 1.325,
      "step": 31400
    },
    {
      "epoch": 1.4515213403025373,
      "grad_norm": 1.6584659814834595,
      "learning_rate": 5.2696111674608595e-06,
      "loss": 1.3167,
      "step": 31450
    },
    {
      "epoch": 1.4538290237345242,
      "grad_norm": 1.6789207458496094,
      "learning_rate": 5.257526515420346e-06,
      "loss": 1.3646,
      "step": 31500
    },
    {
      "epoch": 1.456136707166511,
      "grad_norm": 2.0503427982330322,
      "learning_rate": 5.245440354833281e-06,
      "loss": 1.3046,
      "step": 31550
    },
    {
      "epoch": 1.4584443905984976,
      "grad_norm": 1.4793339967727661,
      "learning_rate": 5.2333527564983365e-06,
      "loss": 1.3025,
      "step": 31600
    },
    {
      "epoch": 1.4607520740304845,
      "grad_norm": 1.9644734859466553,
      "learning_rate": 5.221263791222613e-06,
      "loss": 1.3526,
      "step": 31650
    },
    {
      "epoch": 1.4630597574624713,
      "grad_norm": 1.667043685913086,
      "learning_rate": 5.2091735298212095e-06,
      "loss": 1.3583,
      "step": 31700
    },
    {
      "epoch": 1.4653674408944581,
      "grad_norm": 1.7221484184265137,
      "learning_rate": 5.197082043116825e-06,
      "loss": 1.294,
      "step": 31750
    },
    {
      "epoch": 1.467675124326445,
      "grad_norm": 1.7707490921020508,
      "learning_rate": 5.1849894019393344e-06,
      "loss": 1.3462,
      "step": 31800
    },
    {
      "epoch": 1.4699828077584316,
      "grad_norm": 1.6015129089355469,
      "learning_rate": 5.172895677125371e-06,
      "loss": 1.3024,
      "step": 31850
    },
    {
      "epoch": 1.4722904911904184,
      "grad_norm": 1.5235953330993652,
      "learning_rate": 5.160800939517921e-06,
      "loss": 1.3101,
      "step": 31900
    },
    {
      "epoch": 1.4745981746224053,
      "grad_norm": 1.6029068231582642,
      "learning_rate": 5.1487052599659005e-06,
      "loss": 1.3627,
      "step": 31950
    },
    {
      "epoch": 1.4769058580543921,
      "grad_norm": 2.0530409812927246,
      "learning_rate": 5.136608709323745e-06,
      "loss": 1.3384,
      "step": 32000
    },
    {
      "epoch": 1.4769058580543921,
      "eval_loss": 1.3157286643981934,
      "eval_runtime": 178.1199,
      "eval_samples_per_second": 28.071,
      "eval_steps_per_second": 1.173,
      "step": 32000
    },
    {
      "epoch": 1.479213541486379,
      "grad_norm": 1.653455376625061,
      "learning_rate": 5.124511358450992e-06,
      "loss": 1.3291,
      "step": 32050
    },
    {
      "epoch": 1.4815212249183656,
      "grad_norm": 1.5709984302520752,
      "learning_rate": 5.112413278211866e-06,
      "loss": 1.3223,
      "step": 32100
    },
    {
      "epoch": 1.4838289083503524,
      "grad_norm": 1.7191838026046753,
      "learning_rate": 5.100314539474863e-06,
      "loss": 1.3005,
      "step": 32150
    },
    {
      "epoch": 1.4861365917823393,
      "grad_norm": 1.935687780380249,
      "learning_rate": 5.088215213112341e-06,
      "loss": 1.3163,
      "step": 32200
    },
    {
      "epoch": 1.488444275214326,
      "grad_norm": 1.8070385456085205,
      "learning_rate": 5.076115370000096e-06,
      "loss": 1.3119,
      "step": 32250
    },
    {
      "epoch": 1.490751958646313,
      "grad_norm": 1.796399474143982,
      "learning_rate": 5.064015081016951e-06,
      "loss": 1.3168,
      "step": 32300
    },
    {
      "epoch": 1.4930596420782998,
      "grad_norm": 1.7229018211364746,
      "learning_rate": 5.051914417044345e-06,
      "loss": 1.3127,
      "step": 32350
    },
    {
      "epoch": 1.4953673255102866,
      "grad_norm": 1.7965140342712402,
      "learning_rate": 5.0398134489659065e-06,
      "loss": 1.3307,
      "step": 32400
    },
    {
      "epoch": 1.4976750089422732,
      "grad_norm": 1.5418659448623657,
      "learning_rate": 5.027712247667051e-06,
      "loss": 1.2985,
      "step": 32450
    },
    {
      "epoch": 1.49998269237426,
      "grad_norm": NaN,
      "learning_rate": 5.015610884034561e-06,
      "loss": 1.3283,
      "step": 32500
    },
    {
      "epoch": 1.502290375806247,
      "grad_norm": 1.7440615892410278,
      "learning_rate": 5.003751458495398e-06,
      "loss": 1.3463,
      "step": 32550
    },
    {
      "epoch": 1.5045980592382338,
      "grad_norm": 1.8325858116149902,
      "learning_rate": 4.991649982575811e-06,
      "loss": 1.3392,
      "step": 32600
    },
    {
      "epoch": 1.5069057426702206,
      "grad_norm": 1.6905903816223145,
      "learning_rate": 4.979548555569206e-06,
      "loss": 1.3338,
      "step": 32650
    },
    {
      "epoch": 1.5092134261022072,
      "grad_norm": 1.6803754568099976,
      "learning_rate": 4.967447248363685e-06,
      "loss": 1.3184,
      "step": 32700
    },
    {
      "epoch": 1.511521109534194,
      "grad_norm": 1.9321707487106323,
      "learning_rate": 4.955346131846651e-06,
      "loss": 1.32,
      "step": 32750
    },
    {
      "epoch": 1.513828792966181,
      "grad_norm": 1.6525858640670776,
      "learning_rate": 4.943245276904386e-06,
      "loss": 1.3279,
      "step": 32800
    },
    {
      "epoch": 1.5161364763981677,
      "grad_norm": 1.8192074298858643,
      "learning_rate": 4.9311447544216424e-06,
      "loss": 1.326,
      "step": 32850
    },
    {
      "epoch": 1.5184441598301546,
      "grad_norm": 1.6635035276412964,
      "learning_rate": 4.919044635281223e-06,
      "loss": 1.3332,
      "step": 32900
    },
    {
      "epoch": 1.5207518432621412,
      "grad_norm": 1.7675615549087524,
      "learning_rate": 4.906944990363568e-06,
      "loss": 1.3128,
      "step": 32950
    },
    {
      "epoch": 1.5230595266941283,
      "grad_norm": 1.6585367918014526,
      "learning_rate": 4.8948458905463425e-06,
      "loss": 1.3321,
      "step": 33000
    },
    {
      "epoch": 1.5230595266941283,
      "eval_loss": 1.3168963193893433,
      "eval_runtime": 178.3191,
      "eval_samples_per_second": 28.04,
      "eval_steps_per_second": 1.172,
      "step": 33000
    },
    {
      "epoch": 1.5253672101261149,
      "grad_norm": 1.5624226331710815,
      "learning_rate": 4.882747406704014e-06,
      "loss": 1.3125,
      "step": 33050
    },
    {
      "epoch": 1.5276748935581017,
      "grad_norm": 1.6386594772338867,
      "learning_rate": 4.870649609707447e-06,
      "loss": 1.3174,
      "step": 33100
    },
    {
      "epoch": 1.5299825769900885,
      "grad_norm": 1.796095848083496,
      "learning_rate": 4.858552570423479e-06,
      "loss": 1.3118,
      "step": 33150
    },
    {
      "epoch": 1.5322902604220752,
      "grad_norm": 1.777958631515503,
      "learning_rate": 4.846456359714508e-06,
      "loss": 1.3098,
      "step": 33200
    },
    {
      "epoch": 1.5345979438540622,
      "grad_norm": 1.549810528755188,
      "learning_rate": 4.834361048438084e-06,
      "loss": 1.3154,
      "step": 33250
    },
    {
      "epoch": 1.5369056272860488,
      "grad_norm": 1.6462273597717285,
      "learning_rate": 4.822266707446481e-06,
      "loss": 1.2901,
      "step": 33300
    },
    {
      "epoch": 1.5392133107180357,
      "grad_norm": 1.5385078191757202,
      "learning_rate": 4.810173407586296e-06,
      "loss": 1.318,
      "step": 33350
    },
    {
      "epoch": 1.5415209941500225,
      "grad_norm": 1.6766544580459595,
      "learning_rate": 4.79808121969802e-06,
      "loss": 1.34,
      "step": 33400
    },
    {
      "epoch": 1.5438286775820091,
      "grad_norm": 1.6944488286972046,
      "learning_rate": 4.785990214615637e-06,
      "loss": 1.3429,
      "step": 33450
    },
    {
      "epoch": 1.5461363610139962,
      "grad_norm": 1.9097838401794434,
      "learning_rate": 4.773900463166197e-06,
      "loss": 1.3287,
      "step": 33500
    },
    {
      "epoch": 1.5484440444459828,
      "grad_norm": 1.6020125150680542,
      "learning_rate": 4.7618120361694124e-06,
      "loss": 1.3497,
      "step": 33550
    },
    {
      "epoch": 1.5507517278779697,
      "grad_norm": 1.7188425064086914,
      "learning_rate": 4.749725004437231e-06,
      "loss": 1.3128,
      "step": 33600
    },
    {
      "epoch": 1.5530594113099565,
      "grad_norm": 1.8802145719528198,
      "learning_rate": 4.737639438773431e-06,
      "loss": 1.3678,
      "step": 33650
    },
    {
      "epoch": 1.5553670947419433,
      "grad_norm": 1.562835454940796,
      "learning_rate": 4.7255554099732015e-06,
      "loss": 1.3424,
      "step": 33700
    },
    {
      "epoch": 1.5576747781739302,
      "grad_norm": 1.507915735244751,
      "learning_rate": 4.7134729888227296e-06,
      "loss": 1.3052,
      "step": 33750
    },
    {
      "epoch": 1.5599824616059168,
      "grad_norm": 1.9504438638687134,
      "learning_rate": 4.7013922460987814e-06,
      "loss": 1.326,
      "step": 33800
    },
    {
      "epoch": 1.5622901450379039,
      "grad_norm": 1.7027816772460938,
      "learning_rate": 4.6893132525683e-06,
      "loss": 1.3295,
      "step": 33850
    },
    {
      "epoch": 1.5645978284698905,
      "grad_norm": 1.7424260377883911,
      "learning_rate": 4.677236078987973e-06,
      "loss": 1.3163,
      "step": 33900
    },
    {
      "epoch": 1.5669055119018773,
      "grad_norm": 1.6165589094161987,
      "learning_rate": 4.66516079610383e-06,
      "loss": 1.3428,
      "step": 33950
    },
    {
      "epoch": 1.5692131953338642,
      "grad_norm": 1.6168560981750488,
      "learning_rate": 4.653087474650826e-06,
      "loss": 1.3395,
      "step": 34000
    },
    {
      "epoch": 1.5692131953338642,
      "eval_loss": 1.3136907815933228,
      "eval_runtime": 177.9818,
      "eval_samples_per_second": 28.093,
      "eval_steps_per_second": 1.174,
      "step": 34000
    },
    {
      "epoch": 1.5715208787658508,
      "grad_norm": 1.827962875366211,
      "learning_rate": 4.641016185352426e-06,
      "loss": 1.3215,
      "step": 34050
    },
    {
      "epoch": 1.5738285621978378,
      "grad_norm": 1.6761964559555054,
      "learning_rate": 4.6289469989201915e-06,
      "loss": 1.3562,
      "step": 34100
    },
    {
      "epoch": 1.5761362456298245,
      "grad_norm": 1.6130446195602417,
      "learning_rate": 4.616879986053365e-06,
      "loss": 1.3474,
      "step": 34150
    },
    {
      "epoch": 1.5784439290618113,
      "grad_norm": 1.7368495464324951,
      "learning_rate": 4.604815217438454e-06,
      "loss": 1.3272,
      "step": 34200
    },
    {
      "epoch": 1.5807516124937981,
      "grad_norm": 1.6203514337539673,
      "learning_rate": 4.592752763748825e-06,
      "loss": 1.295,
      "step": 34250
    },
    {
      "epoch": 1.5830592959257848,
      "grad_norm": 1.9444739818572998,
      "learning_rate": 4.5809338731706754e-06,
      "loss": 1.3131,
      "step": 34300
    },
    {
      "epoch": 1.5853669793577718,
      "grad_norm": 1.875009536743164,
      "learning_rate": 4.5688762114801895e-06,
      "loss": 1.3574,
      "step": 34350
    },
    {
      "epoch": 1.5876746627897584,
      "grad_norm": 2.1850054264068604,
      "learning_rate": 4.556821075239571e-06,
      "loss": 1.336,
      "step": 34400
    },
    {
      "epoch": 1.5899823462217453,
      "grad_norm": 1.7041040658950806,
      "learning_rate": 4.545009559971107e-06,
      "loss": 1.3489,
      "step": 34450
    },
    {
      "epoch": 1.5922900296537321,
      "grad_norm": 1.976761817932129,
      "learning_rate": 4.532959632440669e-06,
      "loss": 1.3308,
      "step": 34500
    },
    {
      "epoch": 1.5945977130857187,
      "grad_norm": 1.777321457862854,
      "learning_rate": 4.520912440753315e-06,
      "loss": 1.3482,
      "step": 34550
    },
    {
      "epoch": 1.5969053965177058,
      "grad_norm": 1.6076898574829102,
      "learning_rate": 4.508868055479447e-06,
      "loss": 1.3351,
      "step": 34600
    },
    {
      "epoch": 1.5992130799496924,
      "grad_norm": 1.628836989402771,
      "learning_rate": 4.496826547173025e-06,
      "loss": 1.356,
      "step": 34650
    },
    {
      "epoch": 1.6015207633816793,
      "grad_norm": 1.7384283542633057,
      "learning_rate": 4.484787986371158e-06,
      "loss": 1.3203,
      "step": 34700
    },
    {
      "epoch": 1.603828446813666,
      "grad_norm": 1.6173510551452637,
      "learning_rate": 4.47275244359369e-06,
      "loss": 1.3063,
      "step": 34750
    },
    {
      "epoch": 1.606136130245653,
      "grad_norm": 1.7229722738265991,
      "learning_rate": 4.4607199893427814e-06,
      "loss": 1.3364,
      "step": 34800
    },
    {
      "epoch": 1.6084438136776398,
      "grad_norm": 1.8235052824020386,
      "learning_rate": 4.4486906941025085e-06,
      "loss": 1.3147,
      "step": 34850
    },
    {
      "epoch": 1.6107514971096264,
      "grad_norm": 1.8003023862838745,
      "learning_rate": 4.436664628338435e-06,
      "loss": 1.3091,
      "step": 34900
    },
    {
      "epoch": 1.6130591805416135,
      "grad_norm": 1.7423425912857056,
      "learning_rate": 4.424641862497211e-06,
      "loss": 1.3425,
      "step": 34950
    },
    {
      "epoch": 1.6153668639736,
      "grad_norm": 1.6243937015533447,
      "learning_rate": 4.412622467006156e-06,
      "loss": 1.3594,
      "step": 35000
    },
    {
      "epoch": 1.6153668639736,
      "eval_loss": 1.3146607875823975,
      "eval_runtime": 178.0383,
      "eval_samples_per_second": 28.084,
      "eval_steps_per_second": 1.174,
      "step": 35000
    },
    {
      "epoch": 1.617674547405587,
      "grad_norm": 1.7786065340042114,
      "learning_rate": 4.400606512272841e-06,
      "loss": 1.324,
      "step": 35050
    },
    {
      "epoch": 1.6199822308375738,
      "grad_norm": 1.6956725120544434,
      "learning_rate": 4.388594068684692e-06,
      "loss": 1.3439,
      "step": 35100
    },
    {
      "epoch": 1.6222899142695604,
      "grad_norm": 1.8332089185714722,
      "learning_rate": 4.37658520660856e-06,
      "loss": 1.3254,
      "step": 35150
    },
    {
      "epoch": 1.6245975977015474,
      "grad_norm": 1.9757860898971558,
      "learning_rate": 4.3645799963903166e-06,
      "loss": 1.3485,
      "step": 35200
    },
    {
      "epoch": 1.626905281133534,
      "grad_norm": 1.4898041486740112,
      "learning_rate": 4.3525785083544435e-06,
      "loss": 1.3377,
      "step": 35250
    },
    {
      "epoch": 1.629212964565521,
      "grad_norm": 1.6884372234344482,
      "learning_rate": 4.3405808128036164e-06,
      "loss": 1.307,
      "step": 35300
    },
    {
      "epoch": 1.6315206479975077,
      "grad_norm": 1.6236059665679932,
      "learning_rate": 4.328586980018298e-06,
      "loss": 1.337,
      "step": 35350
    },
    {
      "epoch": 1.6338283314294944,
      "grad_norm": 1.6417412757873535,
      "learning_rate": 4.316597080256321e-06,
      "loss": 1.3181,
      "step": 35400
    },
    {
      "epoch": 1.6361360148614814,
      "grad_norm": 1.6679621934890747,
      "learning_rate": 4.304611183752481e-06,
      "loss": 1.3144,
      "step": 35450
    },
    {
      "epoch": 1.638443698293468,
      "grad_norm": 1.6182360649108887,
      "learning_rate": 4.2926293607181204e-06,
      "loss": 1.3204,
      "step": 35500
    },
    {
      "epoch": 1.6407513817254549,
      "grad_norm": 1.7049013376235962,
      "learning_rate": 4.280651681340724e-06,
      "loss": 1.3519,
      "step": 35550
    },
    {
      "epoch": 1.6430590651574417,
      "grad_norm": 1.938466191291809,
      "learning_rate": 4.2686782157834984e-06,
      "loss": 1.3002,
      "step": 35600
    },
    {
      "epoch": 1.6453667485894286,
      "grad_norm": 1.7099848985671997,
      "learning_rate": 4.256709034184974e-06,
      "loss": 1.323,
      "step": 35650
    },
    {
      "epoch": 1.6476744320214154,
      "grad_norm": 1.8792611360549927,
      "learning_rate": 4.244744206658579e-06,
      "loss": 1.3086,
      "step": 35700
    },
    {
      "epoch": 1.649982115453402,
      "grad_norm": 1.7552564144134521,
      "learning_rate": 4.23278380329224e-06,
      "loss": 1.314,
      "step": 35750
    },
    {
      "epoch": 1.6522897988853888,
      "grad_norm": 1.76216721534729,
      "learning_rate": 4.2208278941479666e-06,
      "loss": 1.2868,
      "step": 35800
    },
    {
      "epoch": 1.6545974823173757,
      "grad_norm": 1.726831316947937,
      "learning_rate": 4.2088765492614435e-06,
      "loss": 1.3199,
      "step": 35850
    },
    {
      "epoch": 1.6569051657493625,
      "grad_norm": 1.7423863410949707,
      "learning_rate": 4.196929838641617e-06,
      "loss": 1.3182,
      "step": 35900
    },
    {
      "epoch": 1.6592128491813494,
      "grad_norm": 1.4764485359191895,
      "learning_rate": 4.184987832270286e-06,
      "loss": 1.2922,
      "step": 35950
    },
    {
      "epoch": 1.661520532613336,
      "grad_norm": 1.6078914403915405,
      "learning_rate": 4.173050600101694e-06,
      "loss": 1.3325,
      "step": 36000
    },
    {
      "epoch": 1.661520532613336,
      "eval_loss": 1.313714861869812,
      "eval_runtime": 177.8845,
      "eval_samples_per_second": 28.108,
      "eval_steps_per_second": 1.175,
      "step": 36000
    },
    {
      "epoch": 1.663828216045323,
      "grad_norm": 1.5051835775375366,
      "learning_rate": 4.16111821206212e-06,
      "loss": 1.3452,
      "step": 36050
    },
    {
      "epoch": 1.6661358994773097,
      "grad_norm": 1.6766620874404907,
      "learning_rate": 4.149190738049461e-06,
      "loss": 1.347,
      "step": 36100
    },
    {
      "epoch": 1.6684435829092965,
      "grad_norm": 1.5415503978729248,
      "learning_rate": 4.137268247932835e-06,
      "loss": 1.3091,
      "step": 36150
    },
    {
      "epoch": 1.6707512663412833,
      "grad_norm": 1.6696401834487915,
      "learning_rate": 4.125350811552162e-06,
      "loss": 1.3117,
      "step": 36200
    },
    {
      "epoch": 1.67305894977327,
      "grad_norm": 1.5988136529922485,
      "learning_rate": 4.11343849871776e-06,
      "loss": 1.3186,
      "step": 36250
    },
    {
      "epoch": 1.675366633205257,
      "grad_norm": 1.7254589796066284,
      "learning_rate": 4.10153137920993e-06,
      "loss": 1.3292,
      "step": 36300
    },
    {
      "epoch": 1.6776743166372436,
      "grad_norm": 2.213719367980957,
      "learning_rate": 4.089629522778556e-06,
      "loss": 1.3492,
      "step": 36350
    },
    {
      "epoch": 1.6799820000692305,
      "grad_norm": 1.9578920602798462,
      "learning_rate": 4.077732999142689e-06,
      "loss": 1.3394,
      "step": 36400
    },
    {
      "epoch": 1.6822896835012173,
      "grad_norm": 1.5145059823989868,
      "learning_rate": 4.065841877990144e-06,
      "loss": 1.3613,
      "step": 36450
    },
    {
      "epoch": 1.684597366933204,
      "grad_norm": 1.543886423110962,
      "learning_rate": 4.053956228977084e-06,
      "loss": 1.3247,
      "step": 36500
    },
    {
      "epoch": 1.686905050365191,
      "grad_norm": 1.760035514831543,
      "learning_rate": 4.042076121727622e-06,
      "loss": 1.3041,
      "step": 36550
    },
    {
      "epoch": 1.6892127337971776,
      "grad_norm": 1.623464822769165,
      "learning_rate": 4.030201625833409e-06,
      "loss": 1.3179,
      "step": 36600
    },
    {
      "epoch": 1.6915204172291645,
      "grad_norm": 1.6033416986465454,
      "learning_rate": 4.018332810853221e-06,
      "loss": 1.3227,
      "step": 36650
    },
    {
      "epoch": 1.6938281006611513,
      "grad_norm": 1.8292874097824097,
      "learning_rate": 4.006469746312559e-06,
      "loss": 1.3023,
      "step": 36700
    },
    {
      "epoch": 1.6961357840931381,
      "grad_norm": 2.0747454166412354,
      "learning_rate": 3.994612501703237e-06,
      "loss": 1.3051,
      "step": 36750
    },
    {
      "epoch": 1.698443467525125,
      "grad_norm": 1.5300101041793823,
      "learning_rate": 3.982761146482982e-06,
      "loss": 1.311,
      "step": 36800
    },
    {
      "epoch": 1.7007511509571116,
      "grad_norm": 1.5678298473358154,
      "learning_rate": 3.970915750075018e-06,
      "loss": 1.2875,
      "step": 36850
    },
    {
      "epoch": 1.7030588343890987,
      "grad_norm": 1.7061638832092285,
      "learning_rate": 3.9590763818676604e-06,
      "loss": 1.3193,
      "step": 36900
    },
    {
      "epoch": 1.7053665178210853,
      "grad_norm": 1.4456874132156372,
      "learning_rate": 3.9472431112139185e-06,
      "loss": 1.3405,
      "step": 36950
    },
    {
      "epoch": 1.7076742012530721,
      "grad_norm": 1.7705572843551636,
      "learning_rate": 3.9354160074310786e-06,
      "loss": 1.2969,
      "step": 37000
    },
    {
      "epoch": 1.7076742012530721,
      "eval_loss": 1.3121625185012817,
      "eval_runtime": 178.1676,
      "eval_samples_per_second": 28.063,
      "eval_steps_per_second": 1.173,
      "step": 37000
    },
    {
      "epoch": 1.709981884685059,
      "grad_norm": 1.7048048973083496,
      "learning_rate": 3.923595139800305e-06,
      "loss": 1.3802,
      "step": 37050
    },
    {
      "epoch": 1.7122895681170456,
      "grad_norm": 1.5279881954193115,
      "learning_rate": 3.911780577566232e-06,
      "loss": 1.3097,
      "step": 37100
    },
    {
      "epoch": 1.7145972515490326,
      "grad_norm": 1.6184333562850952,
      "learning_rate": 3.899972389936555e-06,
      "loss": 1.3216,
      "step": 37150
    },
    {
      "epoch": 1.7169049349810193,
      "grad_norm": 1.759874939918518,
      "learning_rate": 3.888170646081631e-06,
      "loss": 1.2922,
      "step": 37200
    },
    {
      "epoch": 1.719212618413006,
      "grad_norm": 1.7050981521606445,
      "learning_rate": 3.8763754151340685e-06,
      "loss": 1.3658,
      "step": 37250
    },
    {
      "epoch": 1.721520301844993,
      "grad_norm": 1.9183934926986694,
      "learning_rate": 3.864586766188325e-06,
      "loss": 1.3136,
      "step": 37300
    },
    {
      "epoch": 1.7238279852769796,
      "grad_norm": 2.050564765930176,
      "learning_rate": 3.852804768300305e-06,
      "loss": 1.3698,
      "step": 37350
    },
    {
      "epoch": 1.7261356687089666,
      "grad_norm": 1.7646623849868774,
      "learning_rate": 3.841029490486947e-06,
      "loss": 1.3707,
      "step": 37400
    },
    {
      "epoch": 1.7284433521409532,
      "grad_norm": 1.555133581161499,
      "learning_rate": 3.829261001725826e-06,
      "loss": 1.3072,
      "step": 37450
    },
    {
      "epoch": 1.73075103557294,
      "grad_norm": 1.5695538520812988,
      "learning_rate": 3.817499370954751e-06,
      "loss": 1.376,
      "step": 37500
    },
    {
      "epoch": 1.733058719004927,
      "grad_norm": 1.7964667081832886,
      "learning_rate": 3.805744667071356e-06,
      "loss": 1.346,
      "step": 37550
    },
    {
      "epoch": 1.7353664024369138,
      "grad_norm": 1.6851634979248047,
      "learning_rate": 3.7939969589326966e-06,
      "loss": 1.3158,
      "step": 37600
    },
    {
      "epoch": 1.7376740858689006,
      "grad_norm": 2.0204436779022217,
      "learning_rate": 3.78225631535485e-06,
      "loss": 1.3765,
      "step": 37650
    },
    {
      "epoch": 1.7399817693008872,
      "grad_norm": 1.597397804260254,
      "learning_rate": 3.7705228051125116e-06,
      "loss": 1.3324,
      "step": 37700
    },
    {
      "epoch": 1.742289452732874,
      "grad_norm": 1.571825385093689,
      "learning_rate": 3.7587964969385895e-06,
      "loss": 1.3058,
      "step": 37750
    },
    {
      "epoch": 1.744597136164861,
      "grad_norm": 1.6894190311431885,
      "learning_rate": 3.7470774595238024e-06,
      "loss": 1.3061,
      "step": 37800
    },
    {
      "epoch": 1.7469048195968477,
      "grad_norm": 1.8905094861984253,
      "learning_rate": 3.73536576151628e-06,
      "loss": 1.3435,
      "step": 37850
    },
    {
      "epoch": 1.7492125030288346,
      "grad_norm": 1.6521592140197754,
      "learning_rate": 3.7236614715211613e-06,
      "loss": 1.3417,
      "step": 37900
    },
    {
      "epoch": 1.7515201864608212,
      "grad_norm": 1.770266056060791,
      "learning_rate": 3.7119646581001834e-06,
      "loss": 1.3334,
      "step": 37950
    },
    {
      "epoch": 1.7538278698928083,
      "grad_norm": 1.7462780475616455,
      "learning_rate": 3.700275389771295e-06,
      "loss": 1.3038,
      "step": 38000
    },
    {
      "epoch": 1.7538278698928083,
      "eval_loss": 1.3121023178100586,
      "eval_runtime": 178.131,
      "eval_samples_per_second": 28.069,
      "eval_steps_per_second": 1.173,
      "step": 38000
    },
    {
      "epoch": 1.7561355533247949,
      "grad_norm": 1.5437802076339722,
      "learning_rate": 3.6885937350082403e-06,
      "loss": 1.3531,
      "step": 38050
    },
    {
      "epoch": 1.7584432367567817,
      "grad_norm": 1.7639644145965576,
      "learning_rate": 3.676919762240168e-06,
      "loss": 1.3221,
      "step": 38100
    },
    {
      "epoch": 1.7607509201887686,
      "grad_norm": 1.7766462564468384,
      "learning_rate": 3.665253539851226e-06,
      "loss": 1.3256,
      "step": 38150
    },
    {
      "epoch": 1.7630586036207552,
      "grad_norm": 1.7870949506759644,
      "learning_rate": 3.6535951361801624e-06,
      "loss": 1.2997,
      "step": 38200
    },
    {
      "epoch": 1.7653662870527422,
      "grad_norm": 1.7294039726257324,
      "learning_rate": 3.6419446195199228e-06,
      "loss": 1.2959,
      "step": 38250
    },
    {
      "epoch": 1.7676739704847289,
      "grad_norm": 1.7306606769561768,
      "learning_rate": 3.630302058117255e-06,
      "loss": 1.2931,
      "step": 38300
    },
    {
      "epoch": 1.7699816539167157,
      "grad_norm": 1.7012319564819336,
      "learning_rate": 3.6186675201723044e-06,
      "loss": 1.298,
      "step": 38350
    },
    {
      "epoch": 1.7722893373487025,
      "grad_norm": 1.5448837280273438,
      "learning_rate": 3.607041073838214e-06,
      "loss": 1.3233,
      "step": 38400
    },
    {
      "epoch": 1.7745970207806891,
      "grad_norm": 1.8770692348480225,
      "learning_rate": 3.5954227872207348e-06,
      "loss": 1.3172,
      "step": 38450
    },
    {
      "epoch": 1.7769047042126762,
      "grad_norm": 1.6974108219146729,
      "learning_rate": 3.5838127283778117e-06,
      "loss": 1.3565,
      "step": 38500
    },
    {
      "epoch": 1.7792123876446628,
      "grad_norm": 1.7480173110961914,
      "learning_rate": 3.5722109653191973e-06,
      "loss": 1.3031,
      "step": 38550
    },
    {
      "epoch": 1.7815200710766497,
      "grad_norm": 1.5455751419067383,
      "learning_rate": 3.5606175660060464e-06,
      "loss": 1.3422,
      "step": 38600
    },
    {
      "epoch": 1.7838277545086365,
      "grad_norm": 1.5931490659713745,
      "learning_rate": 3.5490325983505227e-06,
      "loss": 1.3462,
      "step": 38650
    },
    {
      "epoch": 1.7861354379406233,
      "grad_norm": 1.877476692199707,
      "learning_rate": 3.5374561302153953e-06,
      "loss": 1.2945,
      "step": 38700
    },
    {
      "epoch": 1.7884431213726102,
      "grad_norm": 1.5592645406723022,
      "learning_rate": 3.525888229413649e-06,
      "loss": 1.3129,
      "step": 38750
    },
    {
      "epoch": 1.7907508048045968,
      "grad_norm": 1.607991337776184,
      "learning_rate": 3.514328963708079e-06,
      "loss": 1.3132,
      "step": 38800
    },
    {
      "epoch": 1.7930584882365839,
      "grad_norm": 2.103024482727051,
      "learning_rate": 3.5027784008108995e-06,
      "loss": 1.3156,
      "step": 38850
    },
    {
      "epoch": 1.7953661716685705,
      "grad_norm": 1.5889198780059814,
      "learning_rate": 3.491236608383345e-06,
      "loss": 1.3222,
      "step": 38900
    },
    {
      "epoch": 1.7976738551005573,
      "grad_norm": 1.470710039138794,
      "learning_rate": 3.4797036540352724e-06,
      "loss": 1.3134,
      "step": 38950
    },
    {
      "epoch": 1.7999815385325442,
      "grad_norm": 1.7223540544509888,
      "learning_rate": 3.468179605324766e-06,
      "loss": 1.2911,
      "step": 39000
    },
    {
      "epoch": 1.7999815385325442,
      "eval_loss": 1.3102220296859741,
      "eval_runtime": 178.2097,
      "eval_samples_per_second": 28.057,
      "eval_steps_per_second": 1.173,
      "step": 39000
    },
    {
      "epoch": 1.8022892219645308,
      "grad_norm": 1.6227473020553589,
      "learning_rate": 3.4566645297577496e-06,
      "loss": 1.3256,
      "step": 39050
    },
    {
      "epoch": 1.8045969053965178,
      "grad_norm": 1.699055790901184,
      "learning_rate": 3.4451584947875755e-06,
      "loss": 1.2953,
      "step": 39100
    },
    {
      "epoch": 1.8069045888285045,
      "grad_norm": 1.7872408628463745,
      "learning_rate": 3.43366156781464e-06,
      "loss": 1.3241,
      "step": 39150
    },
    {
      "epoch": 1.8092122722604913,
      "grad_norm": 1.6456633806228638,
      "learning_rate": 3.422173816185988e-06,
      "loss": 1.3292,
      "step": 39200
    },
    {
      "epoch": 1.8115199556924781,
      "grad_norm": 1.546207070350647,
      "learning_rate": 3.410695307194916e-06,
      "loss": 1.321,
      "step": 39250
    },
    {
      "epoch": 1.8138276391244648,
      "grad_norm": 1.5593242645263672,
      "learning_rate": 3.3994554003914336e-06,
      "loss": 1.3134,
      "step": 39300
    },
    {
      "epoch": 1.8161353225564518,
      "grad_norm": 1.8099740743637085,
      "learning_rate": 3.387995390139165e-06,
      "loss": 1.3222,
      "step": 39350
    },
    {
      "epoch": 1.8184430059884384,
      "grad_norm": 1.7837198972702026,
      "learning_rate": 3.3765448227358878e-06,
      "loss": 1.3211,
      "step": 39400
    },
    {
      "epoch": 1.8207506894204253,
      "grad_norm": 1.5695326328277588,
      "learning_rate": 3.3651037652570785e-06,
      "loss": 1.3245,
      "step": 39450
    },
    {
      "epoch": 1.8230583728524121,
      "grad_norm": 1.7654271125793457,
      "learning_rate": 3.3536722847225056e-06,
      "loss": 1.3724,
      "step": 39500
    },
    {
      "epoch": 1.8253660562843987,
      "grad_norm": 1.5866557359695435,
      "learning_rate": 3.3422504480958397e-06,
      "loss": 1.3491,
      "step": 39550
    },
    {
      "epoch": 1.8276737397163858,
      "grad_norm": 1.8638267517089844,
      "learning_rate": 3.3308383222842565e-06,
      "loss": 1.3364,
      "step": 39600
    },
    {
      "epoch": 1.8299814231483724,
      "grad_norm": 1.8841599225997925,
      "learning_rate": 3.319435974138052e-06,
      "loss": 1.3007,
      "step": 39650
    },
    {
      "epoch": 1.8322891065803593,
      "grad_norm": 1.6237698793411255,
      "learning_rate": 3.3080434704502428e-06,
      "loss": 1.3421,
      "step": 39700
    },
    {
      "epoch": 1.834596790012346,
      "grad_norm": 1.4605414867401123,
      "learning_rate": 3.296660877956177e-06,
      "loss": 1.3302,
      "step": 39750
    },
    {
      "epoch": 1.836904473444333,
      "grad_norm": 1.6937367916107178,
      "learning_rate": 3.2852882633331482e-06,
      "loss": 1.3201,
      "step": 39800
    },
    {
      "epoch": 1.8392121568763198,
      "grad_norm": 1.5520931482315063,
      "learning_rate": 3.2739256931999998e-06,
      "loss": 1.3425,
      "step": 39850
    },
    {
      "epoch": 1.8415198403083064,
      "grad_norm": 1.7997045516967773,
      "learning_rate": 3.262573234116734e-06,
      "loss": 1.3495,
      "step": 39900
    },
    {
      "epoch": 1.8438275237402935,
      "grad_norm": 1.85385262966156,
      "learning_rate": 3.251230952584129e-06,
      "loss": 1.3467,
      "step": 39950
    },
    {
      "epoch": 1.84613520717228,
      "grad_norm": 1.8183047771453857,
      "learning_rate": 3.2398989150433415e-06,
      "loss": 1.2949,
      "step": 40000
    },
    {
      "epoch": 1.84613520717228,
      "eval_loss": 1.3096990585327148,
      "eval_runtime": 177.7324,
      "eval_samples_per_second": 28.132,
      "eval_steps_per_second": 1.176,
      "step": 40000
    },
    {
      "epoch": 1.848442890604267,
      "grad_norm": 1.5638989210128784,
      "learning_rate": 3.22857718787552e-06,
      "loss": 1.3016,
      "step": 40050
    },
    {
      "epoch": 1.8507505740362538,
      "grad_norm": 1.9518738985061646,
      "learning_rate": 3.217265837401419e-06,
      "loss": 1.3304,
      "step": 40100
    },
    {
      "epoch": 1.8530582574682404,
      "grad_norm": 1.4816621541976929,
      "learning_rate": 3.2059649298810058e-06,
      "loss": 1.3259,
      "step": 40150
    },
    {
      "epoch": 1.8553659409002274,
      "grad_norm": 1.5341145992279053,
      "learning_rate": 3.194674531513077e-06,
      "loss": 1.2838,
      "step": 40200
    },
    {
      "epoch": 1.857673624332214,
      "grad_norm": 1.871945858001709,
      "learning_rate": 3.183394708434866e-06,
      "loss": 1.3445,
      "step": 40250
    },
    {
      "epoch": 1.859981307764201,
      "grad_norm": 1.5728551149368286,
      "learning_rate": 3.1721255267216587e-06,
      "loss": 1.3297,
      "step": 40300
    },
    {
      "epoch": 1.8622889911961877,
      "grad_norm": 1.7610692977905273,
      "learning_rate": 3.1608670523864075e-06,
      "loss": 1.3307,
      "step": 40350
    },
    {
      "epoch": 1.8645966746281744,
      "grad_norm": 1.4566779136657715,
      "learning_rate": 3.149619351379339e-06,
      "loss": 1.2799,
      "step": 40400
    },
    {
      "epoch": 1.8669043580601614,
      "grad_norm": 2.0139949321746826,
      "learning_rate": 3.1383824895875747e-06,
      "loss": 1.3326,
      "step": 40450
    },
    {
      "epoch": 1.869212041492148,
      "grad_norm": 1.7789418697357178,
      "learning_rate": 3.1271565328347427e-06,
      "loss": 1.3192,
      "step": 40500
    },
    {
      "epoch": 1.8715197249241349,
      "grad_norm": 1.8967105150222778,
      "learning_rate": 3.1159415468805863e-06,
      "loss": 1.3797,
      "step": 40550
    },
    {
      "epoch": 1.8738274083561217,
      "grad_norm": 1.8625853061676025,
      "learning_rate": 3.104737597420591e-06,
      "loss": 1.305,
      "step": 40600
    },
    {
      "epoch": 1.8761350917881086,
      "grad_norm": 1.4885984659194946,
      "learning_rate": 3.0935447500855842e-06,
      "loss": 1.3448,
      "step": 40650
    },
    {
      "epoch": 1.8784427752200954,
      "grad_norm": 2.2789201736450195,
      "learning_rate": 3.0823630704413656e-06,
      "loss": 1.3295,
      "step": 40700
    },
    {
      "epoch": 1.880750458652082,
      "grad_norm": 2.056306838989258,
      "learning_rate": 3.071192623988312e-06,
      "loss": 1.3251,
      "step": 40750
    },
    {
      "epoch": 1.8830581420840689,
      "grad_norm": 1.5865662097930908,
      "learning_rate": 3.0600334761610017e-06,
      "loss": 1.3183,
      "step": 40800
    },
    {
      "epoch": 1.8853658255160557,
      "grad_norm": 1.9740089178085327,
      "learning_rate": 3.0488856923278233e-06,
      "loss": 1.3257,
      "step": 40850
    },
    {
      "epoch": 1.8876735089480425,
      "grad_norm": 1.8166850805282593,
      "learning_rate": 3.037749337790602e-06,
      "loss": 1.2868,
      "step": 40900
    },
    {
      "epoch": 1.8899811923800294,
      "grad_norm": 1.7118302583694458,
      "learning_rate": 3.026624477784209e-06,
      "loss": 1.345,
      "step": 40950
    },
    {
      "epoch": 1.892288875812016,
      "grad_norm": 1.5696334838867188,
      "learning_rate": 3.0155111774761807e-06,
      "loss": 1.3371,
      "step": 41000
    },
    {
      "epoch": 1.892288875812016,
      "eval_loss": 1.3111032247543335,
      "eval_runtime": 178.3364,
      "eval_samples_per_second": 28.037,
      "eval_steps_per_second": 1.172,
      "step": 41000
    },
    {
      "epoch": 1.894596559244003,
      "grad_norm": 1.580844521522522,
      "learning_rate": 3.0044095019663456e-06,
      "loss": 1.3122,
      "step": 41050
    },
    {
      "epoch": 1.8969042426759897,
      "grad_norm": 1.723081111907959,
      "learning_rate": 2.99331951628643e-06,
      "loss": 1.3359,
      "step": 41100
    },
    {
      "epoch": 1.8992119261079765,
      "grad_norm": 2.1113967895507812,
      "learning_rate": 2.982241285399684e-06,
      "loss": 1.3378,
      "step": 41150
    },
    {
      "epoch": 1.9015196095399634,
      "grad_norm": 1.6543880701065063,
      "learning_rate": 2.9711748742005013e-06,
      "loss": 1.3016,
      "step": 41200
    },
    {
      "epoch": 1.90382729297195,
      "grad_norm": 1.7859046459197998,
      "learning_rate": 2.9601203475140385e-06,
      "loss": 1.3184,
      "step": 41250
    },
    {
      "epoch": 1.906134976403937,
      "grad_norm": 1.6288639307022095,
      "learning_rate": 2.9490777700958328e-06,
      "loss": 1.3329,
      "step": 41300
    },
    {
      "epoch": 1.9084426598359236,
      "grad_norm": 1.8062567710876465,
      "learning_rate": 2.9380472066314245e-06,
      "loss": 1.3026,
      "step": 41350
    },
    {
      "epoch": 1.9107503432679105,
      "grad_norm": 1.4977490901947021,
      "learning_rate": 2.9270287217359827e-06,
      "loss": 1.3246,
      "step": 41400
    },
    {
      "epoch": 1.9130580266998973,
      "grad_norm": 1.8693230152130127,
      "learning_rate": 2.9160223799539176e-06,
      "loss": 1.3275,
      "step": 41450
    },
    {
      "epoch": 1.915365710131884,
      "grad_norm": 1.7358753681182861,
      "learning_rate": 2.9050282457585053e-06,
      "loss": 1.3403,
      "step": 41500
    },
    {
      "epoch": 1.917673393563871,
      "grad_norm": 1.6288572549819946,
      "learning_rate": 2.8942659001139682e-06,
      "loss": 1.3191,
      "step": 41550
    },
    {
      "epoch": 1.9199810769958576,
      "grad_norm": 1.8133299350738525,
      "learning_rate": 2.883296126868955e-06,
      "loss": 1.3208,
      "step": 41600
    },
    {
      "epoch": 1.9222887604278445,
      "grad_norm": 1.583654522895813,
      "learning_rate": 2.8723387529154274e-06,
      "loss": 1.2958,
      "step": 41650
    },
    {
      "epoch": 1.9245964438598313,
      "grad_norm": 1.8868424892425537,
      "learning_rate": 2.8613938424398165e-06,
      "loss": 1.333,
      "step": 41700
    },
    {
      "epoch": 1.9269041272918181,
      "grad_norm": 1.793145775794983,
      "learning_rate": 2.850461459555548e-06,
      "loss": 1.3116,
      "step": 41750
    },
    {
      "epoch": 1.929211810723805,
      "grad_norm": 1.5690076351165771,
      "learning_rate": 2.8395416683026623e-06,
      "loss": 1.3608,
      "step": 41800
    },
    {
      "epoch": 1.9315194941557916,
      "grad_norm": 1.7385149002075195,
      "learning_rate": 2.8286345326474396e-06,
      "loss": 1.3183,
      "step": 41850
    },
    {
      "epoch": 1.9338271775877787,
      "grad_norm": 1.6355522871017456,
      "learning_rate": 2.8177401164820282e-06,
      "loss": 1.3345,
      "step": 41900
    },
    {
      "epoch": 1.9361348610197653,
      "grad_norm": 1.9548909664154053,
      "learning_rate": 2.806858483624063e-06,
      "loss": 1.3525,
      "step": 41950
    },
    {
      "epoch": 1.9384425444517521,
      "grad_norm": 1.751119613647461,
      "learning_rate": 2.7959896978163036e-06,
      "loss": 1.2962,
      "step": 42000
    },
    {
      "epoch": 1.9384425444517521,
      "eval_loss": 1.3107078075408936,
      "eval_runtime": 178.2813,
      "eval_samples_per_second": 28.046,
      "eval_steps_per_second": 1.172,
      "step": 42000
    },
    {
      "epoch": 1.940750227883739,
      "grad_norm": 1.458788275718689,
      "learning_rate": 2.785133822726248e-06,
      "loss": 1.3373,
      "step": 42050
    },
    {
      "epoch": 1.9430579113157256,
      "grad_norm": 1.5375162363052368,
      "learning_rate": 2.774290921945768e-06,
      "loss": 1.334,
      "step": 42100
    },
    {
      "epoch": 1.9453655947477126,
      "grad_norm": 1.8215081691741943,
      "learning_rate": 2.763461058990732e-06,
      "loss": 1.337,
      "step": 42150
    },
    {
      "epoch": 1.9476732781796993,
      "grad_norm": 1.9520739316940308,
      "learning_rate": 2.7526442973006363e-06,
      "loss": 1.3363,
      "step": 42200
    },
    {
      "epoch": 1.949980961611686,
      "grad_norm": 1.9988151788711548,
      "learning_rate": 2.741840700238233e-06,
      "loss": 1.3421,
      "step": 42250
    },
    {
      "epoch": 1.952288645043673,
      "grad_norm": 2.005469560623169,
      "learning_rate": 2.731050331089156e-06,
      "loss": 1.324,
      "step": 42300
    },
    {
      "epoch": 1.9545963284756596,
      "grad_norm": 1.7645676136016846,
      "learning_rate": 2.720273253061555e-06,
      "loss": 1.343,
      "step": 42350
    },
    {
      "epoch": 1.9569040119076466,
      "grad_norm": 1.9527348279953003,
      "learning_rate": 2.709509529285719e-06,
      "loss": 1.3239,
      "step": 42400
    },
    {
      "epoch": 1.9592116953396332,
      "grad_norm": 1.7859512567520142,
      "learning_rate": 2.698759222813715e-06,
      "loss": 1.3206,
      "step": 42450
    },
    {
      "epoch": 1.96151937877162,
      "grad_norm": 2.0980470180511475,
      "learning_rate": 2.68802239661901e-06,
      "loss": 1.3408,
      "step": 42500
    },
    {
      "epoch": 1.963827062203607,
      "grad_norm": 1.755637288093567,
      "learning_rate": 2.6772991135961048e-06,
      "loss": 1.3124,
      "step": 42550
    },
    {
      "epoch": 1.9661347456355938,
      "grad_norm": 1.4782601594924927,
      "learning_rate": 2.666589436560172e-06,
      "loss": 1.3264,
      "step": 42600
    },
    {
      "epoch": 1.9684424290675806,
      "grad_norm": 1.693686604499817,
      "learning_rate": 2.6558934282466773e-06,
      "loss": 1.3246,
      "step": 42650
    },
    {
      "epoch": 1.9707501124995672,
      "grad_norm": 1.9199126958847046,
      "learning_rate": 2.6452111513110203e-06,
      "loss": 1.299,
      "step": 42700
    },
    {
      "epoch": 1.973057795931554,
      "grad_norm": 1.5121387243270874,
      "learning_rate": 2.6345426683281614e-06,
      "loss": 1.3048,
      "step": 42750
    },
    {
      "epoch": 1.975365479363541,
      "grad_norm": 1.7017707824707031,
      "learning_rate": 2.6238880417922622e-06,
      "loss": 1.3458,
      "step": 42800
    },
    {
      "epoch": 1.9776731627955277,
      "grad_norm": 1.686287760734558,
      "learning_rate": 2.6132473341163135e-06,
      "loss": 1.3333,
      "step": 42850
    },
    {
      "epoch": 1.9799808462275146,
      "grad_norm": 1.8714399337768555,
      "learning_rate": 2.6026206076317716e-06,
      "loss": 1.3059,
      "step": 42900
    },
    {
      "epoch": 1.9822885296595012,
      "grad_norm": 1.6652939319610596,
      "learning_rate": 2.5920079245881935e-06,
      "loss": 1.3152,
      "step": 42950
    },
    {
      "epoch": 1.9845962130914883,
      "grad_norm": 1.5766205787658691,
      "learning_rate": 2.581409347152874e-06,
      "loss": 1.3305,
      "step": 43000
    },
    {
      "epoch": 1.9845962130914883,
      "eval_loss": 1.309522032737732,
      "eval_runtime": 178.3096,
      "eval_samples_per_second": 28.041,
      "eval_steps_per_second": 1.172,
      "step": 43000
    },
    {
      "epoch": 1.9869038965234749,
      "grad_norm": 1.8085830211639404,
      "learning_rate": 2.5708249374104753e-06,
      "loss": 1.2819,
      "step": 43050
    },
    {
      "epoch": 1.9892115799554617,
      "grad_norm": 1.9419037103652954,
      "learning_rate": 2.5602547573626736e-06,
      "loss": 1.3509,
      "step": 43100
    },
    {
      "epoch": 1.9915192633874486,
      "grad_norm": 1.706491470336914,
      "learning_rate": 2.549698868927787e-06,
      "loss": 1.3398,
      "step": 43150
    },
    {
      "epoch": 1.9938269468194352,
      "grad_norm": 1.968571424484253,
      "learning_rate": 2.539157333940413e-06,
      "loss": 1.3241,
      "step": 43200
    },
    {
      "epoch": 1.9961346302514222,
      "grad_norm": 2.0951192378997803,
      "learning_rate": 2.5286302141510733e-06,
      "loss": 1.3581,
      "step": 43250
    },
    {
      "epoch": 1.9984423136834089,
      "grad_norm": 1.6143267154693604,
      "learning_rate": 2.5181175712258444e-06,
      "loss": 1.316,
      "step": 43300
    },
    {
      "epoch": 2.000738458698236,
      "grad_norm": 1.6074994802474976,
      "learning_rate": 2.507619466746005e-06,
      "loss": 1.2908,
      "step": 43350
    },
    {
      "epoch": 2.0030461421302226,
      "grad_norm": 1.656273365020752,
      "learning_rate": 2.497135962207664e-06,
      "loss": 1.3151,
      "step": 43400
    },
    {
      "epoch": 2.005353825562209,
      "grad_norm": 1.8851573467254639,
      "learning_rate": 2.48666711902141e-06,
      "loss": 1.3254,
      "step": 43450
    },
    {
      "epoch": 2.0076615089941963,
      "grad_norm": 2.191622257232666,
      "learning_rate": 2.4762129985119463e-06,
      "loss": 1.3273,
      "step": 43500
    },
    {
      "epoch": 2.009969192426183,
      "grad_norm": 1.688758134841919,
      "learning_rate": 2.4657736619177346e-06,
      "loss": 1.3068,
      "step": 43550
    },
    {
      "epoch": 2.01227687585817,
      "grad_norm": 1.8560036420822144,
      "learning_rate": 2.455349170390631e-06,
      "loss": 1.338,
      "step": 43600
    },
    {
      "epoch": 2.0145845592901566,
      "grad_norm": 1.5176292657852173,
      "learning_rate": 2.44493958499554e-06,
      "loss": 1.3639,
      "step": 43650
    },
    {
      "epoch": 2.016892242722143,
      "grad_norm": 1.5260246992111206,
      "learning_rate": 2.43454496671004e-06,
      "loss": 1.3566,
      "step": 43700
    },
    {
      "epoch": 2.0191999261541302,
      "grad_norm": 1.8630095720291138,
      "learning_rate": 2.4241653764240393e-06,
      "loss": 1.3102,
      "step": 43750
    },
    {
      "epoch": 2.021507609586117,
      "grad_norm": 1.5174914598464966,
      "learning_rate": 2.413800874939413e-06,
      "loss": 1.3021,
      "step": 43800
    },
    {
      "epoch": 2.023815293018104,
      "grad_norm": 2.122260570526123,
      "learning_rate": 2.4034515229696486e-06,
      "loss": 1.2841,
      "step": 43850
    },
    {
      "epoch": 2.0261229764500905,
      "grad_norm": 1.8655019998550415,
      "learning_rate": 2.3931173811394914e-06,
      "loss": 1.2827,
      "step": 43900
    },
    {
      "epoch": 2.028430659882077,
      "grad_norm": 2.0015451908111572,
      "learning_rate": 2.3827985099845867e-06,
      "loss": 1.3352,
      "step": 43950
    },
    {
      "epoch": 2.030738343314064,
      "grad_norm": 1.8789390325546265,
      "learning_rate": 2.3724949699511286e-06,
      "loss": 1.3343,
      "step": 44000
    },
    {
      "epoch": 2.030738343314064,
      "eval_loss": 1.3091788291931152,
      "eval_runtime": 178.2718,
      "eval_samples_per_second": 28.047,
      "eval_steps_per_second": 1.172,
      "step": 44000
    },
    {
      "epoch": 2.033046026746051,
      "grad_norm": 1.7724474668502808,
      "learning_rate": 2.362206821395503e-06,
      "loss": 1.3151,
      "step": 44050
    },
    {
      "epoch": 2.035353710178038,
      "grad_norm": 1.7161715030670166,
      "learning_rate": 2.3519341245839327e-06,
      "loss": 1.3615,
      "step": 44100
    },
    {
      "epoch": 2.0376613936100245,
      "grad_norm": 1.7316744327545166,
      "learning_rate": 2.341676939692134e-06,
      "loss": 1.3384,
      "step": 44150
    },
    {
      "epoch": 2.0399690770420116,
      "grad_norm": 1.855431079864502,
      "learning_rate": 2.3314353268049505e-06,
      "loss": 1.2898,
      "step": 44200
    },
    {
      "epoch": 2.042276760473998,
      "grad_norm": 1.9687840938568115,
      "learning_rate": 2.3212093459160075e-06,
      "loss": 1.3197,
      "step": 44250
    },
    {
      "epoch": 2.044584443905985,
      "grad_norm": 1.7959717512130737,
      "learning_rate": 2.310999056927366e-06,
      "loss": 1.3131,
      "step": 44300
    },
    {
      "epoch": 2.046892127337972,
      "grad_norm": 1.8517550230026245,
      "learning_rate": 2.3008045196491623e-06,
      "loss": 1.2769,
      "step": 44350
    },
    {
      "epoch": 2.0491998107699585,
      "grad_norm": 1.7246819734573364,
      "learning_rate": 2.2906257937992633e-06,
      "loss": 1.3349,
      "step": 44400
    },
    {
      "epoch": 2.0515074942019456,
      "grad_norm": 1.9459547996520996,
      "learning_rate": 2.2804629390029133e-06,
      "loss": 1.3451,
      "step": 44450
    },
    {
      "epoch": 2.053815177633932,
      "grad_norm": 1.5155407190322876,
      "learning_rate": 2.2703160147923887e-06,
      "loss": 1.334,
      "step": 44500
    },
    {
      "epoch": 2.056122861065919,
      "grad_norm": 1.657374382019043,
      "learning_rate": 2.260185080606647e-06,
      "loss": 1.3114,
      "step": 44550
    },
    {
      "epoch": 2.058430544497906,
      "grad_norm": 1.6836763620376587,
      "learning_rate": 2.250070195790979e-06,
      "loss": 1.3029,
      "step": 44600
    },
    {
      "epoch": 2.0607382279298925,
      "grad_norm": 1.7383543252944946,
      "learning_rate": 2.2401732368732732e-06,
      "loss": 1.2759,
      "step": 44650
    },
    {
      "epoch": 2.0630459113618795,
      "grad_norm": 1.8973486423492432,
      "learning_rate": 2.2300903045225266e-06,
      "loss": 1.3125,
      "step": 44700
    },
    {
      "epoch": 2.065353594793866,
      "grad_norm": 1.9418798685073853,
      "learning_rate": 2.2200235978319353e-06,
      "loss": 1.3099,
      "step": 44750
    },
    {
      "epoch": 2.0676612782258528,
      "grad_norm": 1.7225894927978516,
      "learning_rate": 2.2099731757705567e-06,
      "loss": 1.2834,
      "step": 44800
    },
    {
      "epoch": 2.06996896165784,
      "grad_norm": 2.0170934200286865,
      "learning_rate": 2.199939097212055e-06,
      "loss": 1.325,
      "step": 44850
    },
    {
      "epoch": 2.0722766450898265,
      "grad_norm": 1.6677547693252563,
      "learning_rate": 2.1899214209343563e-06,
      "loss": 1.3098,
      "step": 44900
    },
    {
      "epoch": 2.0745843285218135,
      "grad_norm": 1.6770029067993164,
      "learning_rate": 2.179920205619305e-06,
      "loss": 1.3293,
      "step": 44950
    },
    {
      "epoch": 2.0768920119538,
      "grad_norm": 1.786490559577942,
      "learning_rate": 2.1699355098523194e-06,
      "loss": 1.3261,
      "step": 45000
    },
    {
      "epoch": 2.0768920119538,
      "eval_loss": 1.3093161582946777,
      "eval_runtime": 178.3472,
      "eval_samples_per_second": 28.035,
      "eval_steps_per_second": 1.172,
      "step": 45000
    },
    {
      "epoch": 2.079199695385787,
      "grad_norm": 1.9922429323196411,
      "learning_rate": 2.1599673921220536e-06,
      "loss": 1.3305,
      "step": 45050
    },
    {
      "epoch": 2.081507378817774,
      "grad_norm": 1.7963550090789795,
      "learning_rate": 2.150015910820044e-06,
      "loss": 1.3379,
      "step": 45100
    },
    {
      "epoch": 2.0838150622497604,
      "grad_norm": 1.7196784019470215,
      "learning_rate": 2.1400811242403763e-06,
      "loss": 1.3067,
      "step": 45150
    },
    {
      "epoch": 2.0861227456817475,
      "grad_norm": 1.5983953475952148,
      "learning_rate": 2.1301630905793435e-06,
      "loss": 1.3285,
      "step": 45200
    },
    {
      "epoch": 2.088430429113734,
      "grad_norm": 1.2744295597076416,
      "learning_rate": 2.1202618679351008e-06,
      "loss": 1.3021,
      "step": 45250
    },
    {
      "epoch": 2.090738112545721,
      "grad_norm": 1.9573581218719482,
      "learning_rate": 2.1103775143073253e-06,
      "loss": 1.3059,
      "step": 45300
    },
    {
      "epoch": 2.093045795977708,
      "grad_norm": 1.904871940612793,
      "learning_rate": 2.100510087596882e-06,
      "loss": 1.3207,
      "step": 45350
    },
    {
      "epoch": 2.0953534794096944,
      "grad_norm": 1.9074246883392334,
      "learning_rate": 2.090659645605479e-06,
      "loss": 1.2998,
      "step": 45400
    },
    {
      "epoch": 2.0976611628416815,
      "grad_norm": 1.8653606176376343,
      "learning_rate": 2.0808262460353308e-06,
      "loss": 1.3069,
      "step": 45450
    },
    {
      "epoch": 2.099968846273668,
      "grad_norm": 2.030738115310669,
      "learning_rate": 2.07100994648882e-06,
      "loss": 1.3351,
      "step": 45500
    },
    {
      "epoch": 2.102276529705655,
      "grad_norm": 2.0850954055786133,
      "learning_rate": 2.0612108044681615e-06,
      "loss": 1.31,
      "step": 45550
    },
    {
      "epoch": 2.1045842131376418,
      "grad_norm": 2.0207948684692383,
      "learning_rate": 2.051428877375064e-06,
      "loss": 1.3231,
      "step": 45600
    },
    {
      "epoch": 2.1068918965696284,
      "grad_norm": 1.6231135129928589,
      "learning_rate": 2.041664222510391e-06,
      "loss": 1.3232,
      "step": 45650
    },
    {
      "epoch": 2.1091995800016154,
      "grad_norm": 1.615283489227295,
      "learning_rate": 2.0319168970738343e-06,
      "loss": 1.3013,
      "step": 45700
    },
    {
      "epoch": 2.111507263433602,
      "grad_norm": 1.6406854391098022,
      "learning_rate": 2.022186958163568e-06,
      "loss": 1.3294,
      "step": 45750
    },
    {
      "epoch": 2.113814946865589,
      "grad_norm": 2.297595977783203,
      "learning_rate": 2.012474462775921e-06,
      "loss": 1.3424,
      "step": 45800
    },
    {
      "epoch": 2.1161226302975757,
      "grad_norm": 1.567177653312683,
      "learning_rate": 2.0027794678050395e-06,
      "loss": 1.2714,
      "step": 45850
    },
    {
      "epoch": 2.1184303137295624,
      "grad_norm": 1.8737215995788574,
      "learning_rate": 1.9931020300425558e-06,
      "loss": 1.3128,
      "step": 45900
    },
    {
      "epoch": 2.1207379971615494,
      "grad_norm": 1.7918901443481445,
      "learning_rate": 1.9834422061772534e-06,
      "loss": 1.3164,
      "step": 45950
    },
    {
      "epoch": 2.123045680593536,
      "grad_norm": 1.7709137201309204,
      "learning_rate": 1.9738000527947433e-06,
      "loss": 1.2912,
      "step": 46000
    },
    {
      "epoch": 2.123045680593536,
      "eval_loss": 1.3084847927093506,
      "eval_runtime": 177.94,
      "eval_samples_per_second": 28.099,
      "eval_steps_per_second": 1.175,
      "step": 46000
    },
    {
      "epoch": 2.125353364025523,
      "grad_norm": 1.8604027032852173,
      "learning_rate": 1.964175626377118e-06,
      "loss": 1.3073,
      "step": 46050
    },
    {
      "epoch": 2.1276610474575097,
      "grad_norm": 1.8167610168457031,
      "learning_rate": 1.9545689833026327e-06,
      "loss": 1.3057,
      "step": 46100
    },
    {
      "epoch": 2.129968730889497,
      "grad_norm": 1.6488789319992065,
      "learning_rate": 1.9449801798453683e-06,
      "loss": 1.3278,
      "step": 46150
    },
    {
      "epoch": 2.1322764143214834,
      "grad_norm": 1.7517502307891846,
      "learning_rate": 1.935409272174904e-06,
      "loss": 1.3203,
      "step": 46200
    },
    {
      "epoch": 2.13458409775347,
      "grad_norm": 1.9732120037078857,
      "learning_rate": 1.925856316355994e-06,
      "loss": 1.3057,
      "step": 46250
    },
    {
      "epoch": 2.136891781185457,
      "grad_norm": 1.8592860698699951,
      "learning_rate": 1.9163213683482277e-06,
      "loss": 1.3172,
      "step": 46300
    },
    {
      "epoch": 2.1391994646174437,
      "grad_norm": 1.7281098365783691,
      "learning_rate": 1.90680448400571e-06,
      "loss": 1.3087,
      "step": 46350
    },
    {
      "epoch": 2.1415071480494308,
      "grad_norm": 1.8770638704299927,
      "learning_rate": 1.8973057190767307e-06,
      "loss": 1.3305,
      "step": 46400
    },
    {
      "epoch": 2.1438148314814174,
      "grad_norm": 2.069977045059204,
      "learning_rate": 1.8878251292034412e-06,
      "loss": 1.3172,
      "step": 46450
    },
    {
      "epoch": 2.146122514913404,
      "grad_norm": 1.9453210830688477,
      "learning_rate": 1.8783627699215247e-06,
      "loss": 1.3224,
      "step": 46500
    },
    {
      "epoch": 2.148430198345391,
      "grad_norm": 1.7262790203094482,
      "learning_rate": 1.8689186966598739e-06,
      "loss": 1.3023,
      "step": 46550
    },
    {
      "epoch": 2.1507378817773777,
      "grad_norm": 1.807546854019165,
      "learning_rate": 1.8594929647402643e-06,
      "loss": 1.2625,
      "step": 46600
    },
    {
      "epoch": 2.1530455652093647,
      "grad_norm": 2.2275657653808594,
      "learning_rate": 1.8500856293770319e-06,
      "loss": 1.3383,
      "step": 46650
    },
    {
      "epoch": 2.1553532486413514,
      "grad_norm": 1.5732272863388062,
      "learning_rate": 1.8406967456767454e-06,
      "loss": 1.2999,
      "step": 46700
    },
    {
      "epoch": 2.157660932073338,
      "grad_norm": 1.7676637172698975,
      "learning_rate": 1.831326368637894e-06,
      "loss": 1.3162,
      "step": 46750
    },
    {
      "epoch": 2.159968615505325,
      "grad_norm": 1.8939709663391113,
      "learning_rate": 1.8219745531505512e-06,
      "loss": 1.3133,
      "step": 46800
    },
    {
      "epoch": 2.1622762989373117,
      "grad_norm": 1.8724194765090942,
      "learning_rate": 1.8126413539960608e-06,
      "loss": 1.2824,
      "step": 46850
    },
    {
      "epoch": 2.1645839823692987,
      "grad_norm": 2.0901317596435547,
      "learning_rate": 1.8035129330807644e-06,
      "loss": 1.3036,
      "step": 46900
    },
    {
      "epoch": 2.1668916658012853,
      "grad_norm": 1.6506595611572266,
      "learning_rate": 1.7942167554541261e-06,
      "loss": 1.3156,
      "step": 46950
    },
    {
      "epoch": 2.1691993492332724,
      "grad_norm": 1.7171826362609863,
      "learning_rate": 1.7849393567608025e-06,
      "loss": 1.34,
      "step": 47000
    },
    {
      "epoch": 2.1691993492332724,
      "eval_loss": 1.3085044622421265,
      "eval_runtime": 177.9491,
      "eval_samples_per_second": 28.098,
      "eval_steps_per_second": 1.174,
      "step": 47000
    },
    {
      "epoch": 2.171507032665259,
      "grad_norm": 1.4712589979171753,
      "learning_rate": 1.7756807913462187e-06,
      "loss": 1.315,
      "step": 47050
    },
    {
      "epoch": 2.1738147160972456,
      "grad_norm": 1.5496412515640259,
      "learning_rate": 1.7664411134454768e-06,
      "loss": 1.2831,
      "step": 47100
    },
    {
      "epoch": 2.1761223995292327,
      "grad_norm": 1.8524281978607178,
      "learning_rate": 1.757220377183037e-06,
      "loss": 1.3405,
      "step": 47150
    },
    {
      "epoch": 2.1784300829612193,
      "grad_norm": 1.5334879159927368,
      "learning_rate": 1.7480186365724089e-06,
      "loss": 1.3027,
      "step": 47200
    },
    {
      "epoch": 2.1807377663932064,
      "grad_norm": 1.807295799255371,
      "learning_rate": 1.7388359455158232e-06,
      "loss": 1.3091,
      "step": 47250
    },
    {
      "epoch": 2.183045449825193,
      "grad_norm": 1.669442892074585,
      "learning_rate": 1.7296723578039227e-06,
      "loss": 1.3016,
      "step": 47300
    },
    {
      "epoch": 2.1853531332571796,
      "grad_norm": 1.7576414346694946,
      "learning_rate": 1.7205279271154473e-06,
      "loss": 1.3074,
      "step": 47350
    },
    {
      "epoch": 2.1876608166891667,
      "grad_norm": 1.8865749835968018,
      "learning_rate": 1.711402707016917e-06,
      "loss": 1.3316,
      "step": 47400
    },
    {
      "epoch": 2.1899685001211533,
      "grad_norm": 1.7838853597640991,
      "learning_rate": 1.7022967509623205e-06,
      "loss": 1.3355,
      "step": 47450
    },
    {
      "epoch": 2.1922761835531404,
      "grad_norm": 1.755965232849121,
      "learning_rate": 1.6932101122928002e-06,
      "loss": 1.3016,
      "step": 47500
    },
    {
      "epoch": 2.194583866985127,
      "grad_norm": 1.814431071281433,
      "learning_rate": 1.6841428442363405e-06,
      "loss": 1.3004,
      "step": 47550
    },
    {
      "epoch": 2.1968915504171136,
      "grad_norm": 2.0734734535217285,
      "learning_rate": 1.675094999907455e-06,
      "loss": 1.301,
      "step": 47600
    },
    {
      "epoch": 2.1991992338491007,
      "grad_norm": 1.751970648765564,
      "learning_rate": 1.6660666323068814e-06,
      "loss": 1.3064,
      "step": 47650
    },
    {
      "epoch": 2.2015069172810873,
      "grad_norm": 1.6694269180297852,
      "learning_rate": 1.6570577943212607e-06,
      "loss": 1.3282,
      "step": 47700
    },
    {
      "epoch": 2.2038146007130743,
      "grad_norm": 1.9965431690216064,
      "learning_rate": 1.6480685387228322e-06,
      "loss": 1.2851,
      "step": 47750
    },
    {
      "epoch": 2.206122284145061,
      "grad_norm": 1.6966352462768555,
      "learning_rate": 1.6390989181691313e-06,
      "loss": 1.2819,
      "step": 47800
    },
    {
      "epoch": 2.2084299675770476,
      "grad_norm": 1.952278971672058,
      "learning_rate": 1.6301489852026687e-06,
      "loss": 1.3051,
      "step": 47850
    },
    {
      "epoch": 2.2107376510090346,
      "grad_norm": 1.7520264387130737,
      "learning_rate": 1.6212187922506294e-06,
      "loss": 1.3301,
      "step": 47900
    },
    {
      "epoch": 2.2130453344410213,
      "grad_norm": 1.8683267831802368,
      "learning_rate": 1.6123083916245668e-06,
      "loss": 1.3319,
      "step": 47950
    },
    {
      "epoch": 2.2153530178730083,
      "grad_norm": 1.9365154504776,
      "learning_rate": 1.603417835520093e-06,
      "loss": 1.3454,
      "step": 48000
    },
    {
      "epoch": 2.2153530178730083,
      "eval_loss": 1.307924509048462,
      "eval_runtime": 178.2617,
      "eval_samples_per_second": 28.049,
      "eval_steps_per_second": 1.172,
      "step": 48000
    },
    {
      "epoch": 2.217660701304995,
      "grad_norm": 1.8123517036437988,
      "learning_rate": 1.5945471760165743e-06,
      "loss": 1.294,
      "step": 48050
    },
    {
      "epoch": 2.2199683847369815,
      "grad_norm": 1.8868917226791382,
      "learning_rate": 1.5856964650768258e-06,
      "loss": 1.3056,
      "step": 48100
    },
    {
      "epoch": 2.2222760681689686,
      "grad_norm": 1.9684057235717773,
      "learning_rate": 1.576865754546808e-06,
      "loss": 1.2859,
      "step": 48150
    },
    {
      "epoch": 2.2245837516009552,
      "grad_norm": 1.5703781843185425,
      "learning_rate": 1.5680550961553226e-06,
      "loss": 1.3241,
      "step": 48200
    },
    {
      "epoch": 2.2268914350329423,
      "grad_norm": 1.6870149374008179,
      "learning_rate": 1.5592645415137065e-06,
      "loss": 1.3238,
      "step": 48250
    },
    {
      "epoch": 2.229199118464929,
      "grad_norm": 1.640179991722107,
      "learning_rate": 1.5504941421155378e-06,
      "loss": 1.3251,
      "step": 48300
    },
    {
      "epoch": 2.231506801896916,
      "grad_norm": 1.9452569484710693,
      "learning_rate": 1.541743949336324e-06,
      "loss": 1.3248,
      "step": 48350
    },
    {
      "epoch": 2.2338144853289026,
      "grad_norm": 1.8597095012664795,
      "learning_rate": 1.5330140144332067e-06,
      "loss": 1.3087,
      "step": 48400
    },
    {
      "epoch": 2.236122168760889,
      "grad_norm": 1.6189239025115967,
      "learning_rate": 1.5243043885446612e-06,
      "loss": 1.3428,
      "step": 48450
    },
    {
      "epoch": 2.2384298521928763,
      "grad_norm": 1.633048415184021,
      "learning_rate": 1.515615122690195e-06,
      "loss": 1.3315,
      "step": 48500
    },
    {
      "epoch": 2.240737535624863,
      "grad_norm": 1.850283145904541,
      "learning_rate": 1.5069462677700486e-06,
      "loss": 1.2987,
      "step": 48550
    },
    {
      "epoch": 2.24304521905685,
      "grad_norm": 1.6843498945236206,
      "learning_rate": 1.4982978745649045e-06,
      "loss": 1.3164,
      "step": 48600
    },
    {
      "epoch": 2.2453529024888366,
      "grad_norm": 1.979723334312439,
      "learning_rate": 1.489669993735578e-06,
      "loss": 1.3314,
      "step": 48650
    },
    {
      "epoch": 2.247660585920823,
      "grad_norm": 1.6341345310211182,
      "learning_rate": 1.481062675822728e-06,
      "loss": 1.2903,
      "step": 48700
    },
    {
      "epoch": 2.2499682693528102,
      "grad_norm": 2.1540160179138184,
      "learning_rate": 1.4724759712465608e-06,
      "loss": 1.3317,
      "step": 48750
    },
    {
      "epoch": 2.252275952784797,
      "grad_norm": 1.9197733402252197,
      "learning_rate": 1.463909930306529e-06,
      "loss": 1.3045,
      "step": 48800
    },
    {
      "epoch": 2.254583636216784,
      "grad_norm": 1.947241187095642,
      "learning_rate": 1.4553646031810492e-06,
      "loss": 1.3563,
      "step": 48850
    },
    {
      "epoch": 2.2568913196487705,
      "grad_norm": 1.6897047758102417,
      "learning_rate": 1.4468400399271925e-06,
      "loss": 1.2904,
      "step": 48900
    },
    {
      "epoch": 2.2591990030807576,
      "grad_norm": 2.003600597381592,
      "learning_rate": 1.4383362904804015e-06,
      "loss": 1.3091,
      "step": 48950
    },
    {
      "epoch": 2.2615066865127442,
      "grad_norm": 1.7217251062393188,
      "learning_rate": 1.4298534046541955e-06,
      "loss": 1.3356,
      "step": 49000
    },
    {
      "epoch": 2.2615066865127442,
      "eval_loss": 1.3077162504196167,
      "eval_runtime": 178.0523,
      "eval_samples_per_second": 28.082,
      "eval_steps_per_second": 1.174,
      "step": 49000
    },
    {
      "epoch": 2.263814369944731,
      "grad_norm": 1.7681176662445068,
      "learning_rate": 1.4213914321398774e-06,
      "loss": 1.3265,
      "step": 49050
    },
    {
      "epoch": 2.266122053376718,
      "grad_norm": 1.858188509941101,
      "learning_rate": 1.4129504225062434e-06,
      "loss": 1.3196,
      "step": 49100
    },
    {
      "epoch": 2.2684297368087045,
      "grad_norm": 1.8854033946990967,
      "learning_rate": 1.4045304251992935e-06,
      "loss": 1.2899,
      "step": 49150
    },
    {
      "epoch": 2.2707374202406916,
      "grad_norm": 1.7601220607757568,
      "learning_rate": 1.3961314895419408e-06,
      "loss": 1.3123,
      "step": 49200
    },
    {
      "epoch": 2.273045103672678,
      "grad_norm": 1.4930986166000366,
      "learning_rate": 1.3877536647337225e-06,
      "loss": 1.3045,
      "step": 49250
    },
    {
      "epoch": 2.275352787104665,
      "grad_norm": 1.6919960975646973,
      "learning_rate": 1.3793969998505124e-06,
      "loss": 1.3295,
      "step": 49300
    },
    {
      "epoch": 2.277660470536652,
      "grad_norm": 1.864040732383728,
      "learning_rate": 1.371061543844231e-06,
      "loss": 1.3035,
      "step": 49350
    },
    {
      "epoch": 2.2799681539686385,
      "grad_norm": 1.9133857488632202,
      "learning_rate": 1.3627473455425661e-06,
      "loss": 1.3383,
      "step": 49400
    },
    {
      "epoch": 2.2822758374006256,
      "grad_norm": 1.759255290031433,
      "learning_rate": 1.3544544536486747e-06,
      "loss": 1.3295,
      "step": 49450
    },
    {
      "epoch": 2.284583520832612,
      "grad_norm": 1.9213601350784302,
      "learning_rate": 1.3461829167409107e-06,
      "loss": 1.3078,
      "step": 49500
    },
    {
      "epoch": 2.286891204264599,
      "grad_norm": 1.5572059154510498,
      "learning_rate": 1.3379327832725309e-06,
      "loss": 1.298,
      "step": 49550
    },
    {
      "epoch": 2.289198887696586,
      "grad_norm": 1.6428648233413696,
      "learning_rate": 1.3297041015714134e-06,
      "loss": 1.3236,
      "step": 49600
    },
    {
      "epoch": 2.2915065711285725,
      "grad_norm": 1.6815602779388428,
      "learning_rate": 1.3214969198397776e-06,
      "loss": 1.3331,
      "step": 49650
    },
    {
      "epoch": 2.2938142545605595,
      "grad_norm": 1.9373184442520142,
      "learning_rate": 1.3133112861538987e-06,
      "loss": 1.3188,
      "step": 49700
    },
    {
      "epoch": 2.296121937992546,
      "grad_norm": 2.0660011768341064,
      "learning_rate": 1.3051472484638283e-06,
      "loss": 1.3224,
      "step": 49750
    },
    {
      "epoch": 2.2984296214245328,
      "grad_norm": 1.7987703084945679,
      "learning_rate": 1.2970048545931097e-06,
      "loss": 1.3559,
      "step": 49800
    },
    {
      "epoch": 2.30073730485652,
      "grad_norm": 2.052624225616455,
      "learning_rate": 1.2888841522385037e-06,
      "loss": 1.2982,
      "step": 49850
    },
    {
      "epoch": 2.3030449882885065,
      "grad_norm": 2.0200345516204834,
      "learning_rate": 1.2807851889697038e-06,
      "loss": 1.3344,
      "step": 49900
    },
    {
      "epoch": 2.3053526717204935,
      "grad_norm": 1.8716644048690796,
      "learning_rate": 1.272708012229058e-06,
      "loss": 1.2982,
      "step": 49950
    },
    {
      "epoch": 2.30766035515248,
      "grad_norm": 1.3586779832839966,
      "learning_rate": 1.2646526693312982e-06,
      "loss": 1.3127,
      "step": 50000
    },
    {
      "epoch": 2.30766035515248,
      "eval_loss": 1.3072818517684937,
      "eval_runtime": 177.8542,
      "eval_samples_per_second": 28.113,
      "eval_steps_per_second": 1.175,
      "step": 50000
    },
    {
      "epoch": 2.3099680385844668,
      "grad_norm": 1.828352451324463,
      "learning_rate": 1.2566192074632528e-06,
      "loss": 1.3533,
      "step": 50050
    },
    {
      "epoch": 2.312275722016454,
      "grad_norm": 1.8117685317993164,
      "learning_rate": 1.248607673683575e-06,
      "loss": 1.3274,
      "step": 50100
    },
    {
      "epoch": 2.3145834054484404,
      "grad_norm": 1.554702877998352,
      "learning_rate": 1.240618114922469e-06,
      "loss": 1.3304,
      "step": 50150
    },
    {
      "epoch": 2.3168910888804275,
      "grad_norm": 1.7630152702331543,
      "learning_rate": 1.2326505779814101e-06,
      "loss": 1.3426,
      "step": 50200
    },
    {
      "epoch": 2.319198772312414,
      "grad_norm": 1.713046669960022,
      "learning_rate": 1.2247051095328755e-06,
      "loss": 1.3148,
      "step": 50250
    },
    {
      "epoch": 2.321506455744401,
      "grad_norm": 1.6514822244644165,
      "learning_rate": 1.2167817561200706e-06,
      "loss": 1.296,
      "step": 50300
    },
    {
      "epoch": 2.323814139176388,
      "grad_norm": 1.7894914150238037,
      "learning_rate": 1.2088805641566526e-06,
      "loss": 1.3466,
      "step": 50350
    },
    {
      "epoch": 2.3261218226083744,
      "grad_norm": 1.7537192106246948,
      "learning_rate": 1.2010015799264602e-06,
      "loss": 1.3353,
      "step": 50400
    },
    {
      "epoch": 2.3284295060403615,
      "grad_norm": 1.8388116359710693,
      "learning_rate": 1.1931448495832432e-06,
      "loss": 1.319,
      "step": 50450
    },
    {
      "epoch": 2.330737189472348,
      "grad_norm": 1.5563762187957764,
      "learning_rate": 1.1853104191503923e-06,
      "loss": 1.3342,
      "step": 50500
    },
    {
      "epoch": 2.333044872904335,
      "grad_norm": 1.9345179796218872,
      "learning_rate": 1.1774983345206708e-06,
      "loss": 1.3259,
      "step": 50550
    },
    {
      "epoch": 2.3353525563363218,
      "grad_norm": 2.0162265300750732,
      "learning_rate": 1.1697086414559416e-06,
      "loss": 1.3099,
      "step": 50600
    },
    {
      "epoch": 2.3376602397683084,
      "grad_norm": 1.8738266229629517,
      "learning_rate": 1.1619413855869033e-06,
      "loss": 1.2981,
      "step": 50650
    },
    {
      "epoch": 2.3399679232002955,
      "grad_norm": 1.7840931415557861,
      "learning_rate": 1.1541966124128196e-06,
      "loss": 1.3219,
      "step": 50700
    },
    {
      "epoch": 2.342275606632282,
      "grad_norm": 1.838120460510254,
      "learning_rate": 1.1464743673012551e-06,
      "loss": 1.3017,
      "step": 50750
    },
    {
      "epoch": 2.344583290064269,
      "grad_norm": 1.9029929637908936,
      "learning_rate": 1.1387746954878099e-06,
      "loss": 1.3427,
      "step": 50800
    },
    {
      "epoch": 2.3468909734962558,
      "grad_norm": 2.1055960655212402,
      "learning_rate": 1.1312509611926652e-06,
      "loss": 1.3474,
      "step": 50850
    },
    {
      "epoch": 2.349198656928243,
      "grad_norm": 2.0366578102111816,
      "learning_rate": 1.123596117445765e-06,
      "loss": 1.3213,
      "step": 50900
    },
    {
      "epoch": 2.3515063403602294,
      "grad_norm": 1.9383810758590698,
      "learning_rate": 1.1159639810138823e-06,
      "loss": 1.3409,
      "step": 50950
    },
    {
      "epoch": 2.353814023792216,
      "grad_norm": 1.7615115642547607,
      "learning_rate": 1.1083545966047748e-06,
      "loss": 1.3074,
      "step": 51000
    },
    {
      "epoch": 2.353814023792216,
      "eval_loss": 1.3075134754180908,
      "eval_runtime": 177.8484,
      "eval_samples_per_second": 28.114,
      "eval_steps_per_second": 1.175,
      "step": 51000
    },
    {
      "epoch": 2.356121707224203,
      "grad_norm": 1.9786862134933472,
      "learning_rate": 1.1007680087929235e-06,
      "loss": 1.3075,
      "step": 51050
    },
    {
      "epoch": 2.3584293906561897,
      "grad_norm": 1.799913763999939,
      "learning_rate": 1.0932042620192695e-06,
      "loss": 1.3397,
      "step": 51100
    },
    {
      "epoch": 2.360737074088177,
      "grad_norm": 1.859423279762268,
      "learning_rate": 1.0856634005909544e-06,
      "loss": 1.3228,
      "step": 51150
    },
    {
      "epoch": 2.3630447575201634,
      "grad_norm": 1.9722471237182617,
      "learning_rate": 1.078145468681066e-06,
      "loss": 1.3143,
      "step": 51200
    },
    {
      "epoch": 2.36535244095215,
      "grad_norm": 1.7533224821090698,
      "learning_rate": 1.0706505103283693e-06,
      "loss": 1.2991,
      "step": 51250
    },
    {
      "epoch": 2.367660124384137,
      "grad_norm": 1.7140398025512695,
      "learning_rate": 1.0631785694370573e-06,
      "loss": 1.3051,
      "step": 51300
    },
    {
      "epoch": 2.3699678078161237,
      "grad_norm": 1.8017995357513428,
      "learning_rate": 1.0557296897764886e-06,
      "loss": 1.3165,
      "step": 51350
    },
    {
      "epoch": 2.3722754912481108,
      "grad_norm": 1.6036700010299683,
      "learning_rate": 1.0483039149809332e-06,
      "loss": 1.334,
      "step": 51400
    },
    {
      "epoch": 2.3745831746800974,
      "grad_norm": 2.003791570663452,
      "learning_rate": 1.0409012885493202e-06,
      "loss": 1.317,
      "step": 51450
    },
    {
      "epoch": 2.376890858112084,
      "grad_norm": 2.152661085128784,
      "learning_rate": 1.0335218538449754e-06,
      "loss": 1.2993,
      "step": 51500
    },
    {
      "epoch": 2.379198541544071,
      "grad_norm": 1.9905102252960205,
      "learning_rate": 1.0261656540953735e-06,
      "loss": 1.325,
      "step": 51550
    },
    {
      "epoch": 2.3815062249760577,
      "grad_norm": 1.6783488988876343,
      "learning_rate": 1.018832732391881e-06,
      "loss": 1.3256,
      "step": 51600
    },
    {
      "epoch": 2.3838139084080447,
      "grad_norm": 1.7747458219528198,
      "learning_rate": 1.0115231316895085e-06,
      "loss": 1.3109,
      "step": 51650
    },
    {
      "epoch": 2.3861215918400314,
      "grad_norm": 2.061556577682495,
      "learning_rate": 1.0042368948066533e-06,
      "loss": 1.2923,
      "step": 51700
    },
    {
      "epoch": 2.388429275272018,
      "grad_norm": 1.7279233932495117,
      "learning_rate": 9.969740644248521e-07,
      "loss": 1.3045,
      "step": 51750
    },
    {
      "epoch": 2.390736958704005,
      "grad_norm": 1.7543630599975586,
      "learning_rate": 9.897346830885318e-07,
      "loss": 1.3006,
      "step": 51800
    },
    {
      "epoch": 2.3930446421359917,
      "grad_norm": 1.8748875856399536,
      "learning_rate": 9.825187932047569e-07,
      "loss": 1.3367,
      "step": 51850
    },
    {
      "epoch": 2.3953523255679787,
      "grad_norm": 1.8157479763031006,
      "learning_rate": 9.753264370429843e-07,
      "loss": 1.3551,
      "step": 51900
    },
    {
      "epoch": 2.3976600089999653,
      "grad_norm": 1.7810968160629272,
      "learning_rate": 9.681576567348121e-07,
      "loss": 1.3135,
      "step": 51950
    },
    {
      "epoch": 2.399967692431952,
      "grad_norm": 1.8265315294265747,
      "learning_rate": 9.610124942737392e-07,
      "loss": 1.3071,
      "step": 52000
    },
    {
      "epoch": 2.399967692431952,
      "eval_loss": 1.3074828386306763,
      "eval_runtime": 178.1172,
      "eval_samples_per_second": 28.071,
      "eval_steps_per_second": 1.173,
      "step": 52000
    },
    {
      "epoch": 2.402275375863939,
      "grad_norm": 1.962327003479004,
      "learning_rate": 9.538909915149125e-07,
      "loss": 1.3565,
      "step": 52050
    },
    {
      "epoch": 2.4045830592959256,
      "grad_norm": 2.1115732192993164,
      "learning_rate": 9.467931901748817e-07,
      "loss": 1.3054,
      "step": 52100
    },
    {
      "epoch": 2.4068907427279127,
      "grad_norm": 1.9126423597335815,
      "learning_rate": 9.397191318313648e-07,
      "loss": 1.2936,
      "step": 52150
    },
    {
      "epoch": 2.4091984261598993,
      "grad_norm": 1.9018313884735107,
      "learning_rate": 9.326688579229903e-07,
      "loss": 1.3143,
      "step": 52200
    },
    {
      "epoch": 2.411506109591886,
      "grad_norm": 1.8683565855026245,
      "learning_rate": 9.256424097490652e-07,
      "loss": 1.3102,
      "step": 52250
    },
    {
      "epoch": 2.413813793023873,
      "grad_norm": 1.5655274391174316,
      "learning_rate": 9.186398284693287e-07,
      "loss": 1.3337,
      "step": 52300
    },
    {
      "epoch": 2.4161214764558596,
      "grad_norm": 1.959568738937378,
      "learning_rate": 9.116611551037108e-07,
      "loss": 1.311,
      "step": 52350
    },
    {
      "epoch": 2.4184291598878467,
      "grad_norm": 1.7241084575653076,
      "learning_rate": 9.047064305320946e-07,
      "loss": 1.3113,
      "step": 52400
    },
    {
      "epoch": 2.4207368433198333,
      "grad_norm": 1.9405986070632935,
      "learning_rate": 8.977756954940736e-07,
      "loss": 1.3161,
      "step": 52450
    },
    {
      "epoch": 2.4230445267518204,
      "grad_norm": 1.8497122526168823,
      "learning_rate": 8.908689905887164e-07,
      "loss": 1.2774,
      "step": 52500
    },
    {
      "epoch": 2.425352210183807,
      "grad_norm": 1.836500883102417,
      "learning_rate": 8.83986356274325e-07,
      "loss": 1.3304,
      "step": 52550
    },
    {
      "epoch": 2.4276598936157936,
      "grad_norm": 2.0706005096435547,
      "learning_rate": 8.771278328682031e-07,
      "loss": 1.3376,
      "step": 52600
    },
    {
      "epoch": 2.4299675770477807,
      "grad_norm": 1.6175284385681152,
      "learning_rate": 8.702934605464141e-07,
      "loss": 1.3059,
      "step": 52650
    },
    {
      "epoch": 2.4322752604797673,
      "grad_norm": 1.7031190395355225,
      "learning_rate": 8.634832793435493e-07,
      "loss": 1.3112,
      "step": 52700
    },
    {
      "epoch": 2.4345829439117543,
      "grad_norm": 1.7872169017791748,
      "learning_rate": 8.566973291524928e-07,
      "loss": 1.3061,
      "step": 52750
    },
    {
      "epoch": 2.436890627343741,
      "grad_norm": 1.698996901512146,
      "learning_rate": 8.499356497241873e-07,
      "loss": 1.3103,
      "step": 52800
    },
    {
      "epoch": 2.439198310775728,
      "grad_norm": 1.957985520362854,
      "learning_rate": 8.43198280667401e-07,
      "loss": 1.3179,
      "step": 52850
    },
    {
      "epoch": 2.4415059942077146,
      "grad_norm": 1.8924274444580078,
      "learning_rate": 8.364852614484959e-07,
      "loss": 1.3236,
      "step": 52900
    },
    {
      "epoch": 2.4438136776397013,
      "grad_norm": 1.8104225397109985,
      "learning_rate": 8.297966313911992e-07,
      "loss": 1.3114,
      "step": 52950
    },
    {
      "epoch": 2.4461213610716883,
      "grad_norm": 1.7485264539718628,
      "learning_rate": 8.231324296763687e-07,
      "loss": 1.3171,
      "step": 53000
    },
    {
      "epoch": 2.4461213610716883,
      "eval_loss": 1.3071246147155762,
      "eval_runtime": 177.9233,
      "eval_samples_per_second": 28.102,
      "eval_steps_per_second": 1.175,
      "step": 53000
    },
    {
      "epoch": 2.448429044503675,
      "grad_norm": 1.6938550472259521,
      "learning_rate": 8.164926953417646e-07,
      "loss": 1.3145,
      "step": 53050
    },
    {
      "epoch": 2.450736727935662,
      "grad_norm": 1.830926775932312,
      "learning_rate": 8.098774672818205e-07,
      "loss": 1.3153,
      "step": 53100
    },
    {
      "epoch": 2.4530444113676486,
      "grad_norm": 2.0438530445098877,
      "learning_rate": 8.032867842474207e-07,
      "loss": 1.3389,
      "step": 53150
    },
    {
      "epoch": 2.4553520947996352,
      "grad_norm": 1.909956455230713,
      "learning_rate": 7.967206848456649e-07,
      "loss": 1.3077,
      "step": 53200
    },
    {
      "epoch": 2.4576597782316223,
      "grad_norm": 1.9078608751296997,
      "learning_rate": 7.901792075396475e-07,
      "loss": 1.3382,
      "step": 53250
    },
    {
      "epoch": 2.459967461663609,
      "grad_norm": 2.1567680835723877,
      "learning_rate": 7.836623906482299e-07,
      "loss": 1.2943,
      "step": 53300
    },
    {
      "epoch": 2.462275145095596,
      "grad_norm": 1.9017746448516846,
      "learning_rate": 7.77170272345818e-07,
      "loss": 1.32,
      "step": 53350
    },
    {
      "epoch": 2.4645828285275826,
      "grad_norm": 1.788863182067871,
      "learning_rate": 7.707028906621378e-07,
      "loss": 1.3173,
      "step": 53400
    },
    {
      "epoch": 2.466890511959569,
      "grad_norm": 1.7383356094360352,
      "learning_rate": 7.642602834820111e-07,
      "loss": 1.3248,
      "step": 53450
    },
    {
      "epoch": 2.4691981953915563,
      "grad_norm": 1.6762373447418213,
      "learning_rate": 7.578424885451364e-07,
      "loss": 1.3091,
      "step": 53500
    },
    {
      "epoch": 2.471505878823543,
      "grad_norm": 1.8861042261123657,
      "learning_rate": 7.514495434458646e-07,
      "loss": 1.3136,
      "step": 53550
    },
    {
      "epoch": 2.47381356225553,
      "grad_norm": 1.8054375648498535,
      "learning_rate": 7.450814856329818e-07,
      "loss": 1.2911,
      "step": 53600
    },
    {
      "epoch": 2.4761212456875166,
      "grad_norm": 2.107259750366211,
      "learning_rate": 7.387383524094871e-07,
      "loss": 1.2973,
      "step": 53650
    },
    {
      "epoch": 2.478428929119503,
      "grad_norm": 2.0193026065826416,
      "learning_rate": 7.324201809323795e-07,
      "loss": 1.3461,
      "step": 53700
    },
    {
      "epoch": 2.4807366125514902,
      "grad_norm": 1.6571000814437866,
      "learning_rate": 7.26127008212431e-07,
      "loss": 1.351,
      "step": 53750
    },
    {
      "epoch": 2.483044295983477,
      "grad_norm": 1.8367539644241333,
      "learning_rate": 7.198588711139781e-07,
      "loss": 1.3249,
      "step": 53800
    },
    {
      "epoch": 2.485351979415464,
      "grad_norm": 1.9050387144088745,
      "learning_rate": 7.136158063547038e-07,
      "loss": 1.3131,
      "step": 53850
    },
    {
      "epoch": 2.4876596628474505,
      "grad_norm": 1.8336670398712158,
      "learning_rate": 7.073978505054196e-07,
      "loss": 1.3401,
      "step": 53900
    },
    {
      "epoch": 2.489967346279437,
      "grad_norm": 2.4283316135406494,
      "learning_rate": 7.012050399898529e-07,
      "loss": 1.3283,
      "step": 53950
    },
    {
      "epoch": 2.4922750297114242,
      "grad_norm": 1.639256238937378,
      "learning_rate": 6.950374110844366e-07,
      "loss": 1.2706,
      "step": 54000
    },
    {
      "epoch": 2.4922750297114242,
      "eval_loss": 1.3072446584701538,
      "eval_runtime": 178.0755,
      "eval_samples_per_second": 28.078,
      "eval_steps_per_second": 1.174,
      "step": 54000
    },
    {
      "epoch": 2.494582713143411,
      "grad_norm": 1.7951769828796387,
      "learning_rate": 6.88894999918091e-07,
      "loss": 1.2892,
      "step": 54050
    },
    {
      "epoch": 2.496890396575398,
      "grad_norm": 2.110180616378784,
      "learning_rate": 6.827778424720172e-07,
      "loss": 1.3144,
      "step": 54100
    },
    {
      "epoch": 2.4991980800073845,
      "grad_norm": 1.9822404384613037,
      "learning_rate": 6.766859745794835e-07,
      "loss": 1.3214,
      "step": 54150
    },
    {
      "epoch": 2.501505763439371,
      "grad_norm": 1.9803930521011353,
      "learning_rate": 6.70619431925617e-07,
      "loss": 1.3054,
      "step": 54200
    },
    {
      "epoch": 2.503813446871358,
      "grad_norm": 1.9245285987854004,
      "learning_rate": 6.645782500471921e-07,
      "loss": 1.3004,
      "step": 54250
    },
    {
      "epoch": 2.506121130303345,
      "grad_norm": 1.7276283502578735,
      "learning_rate": 6.585624643324268e-07,
      "loss": 1.3109,
      "step": 54300
    },
    {
      "epoch": 2.508428813735332,
      "grad_norm": 1.8546894788742065,
      "learning_rate": 6.52572110020771e-07,
      "loss": 1.3004,
      "step": 54350
    },
    {
      "epoch": 2.5107364971673185,
      "grad_norm": 2.1203901767730713,
      "learning_rate": 6.466072222027015e-07,
      "loss": 1.3358,
      "step": 54400
    },
    {
      "epoch": 2.513044180599305,
      "grad_norm": 1.9406849145889282,
      "learning_rate": 6.406678358195173e-07,
      "loss": 1.3141,
      "step": 54450
    },
    {
      "epoch": 2.515351864031292,
      "grad_norm": 1.8607726097106934,
      "learning_rate": 6.347539856631346e-07,
      "loss": 1.3223,
      "step": 54500
    },
    {
      "epoch": 2.5176595474632792,
      "grad_norm": 1.784797191619873,
      "learning_rate": 6.288657063758818e-07,
      "loss": 1.3232,
      "step": 54550
    },
    {
      "epoch": 2.519967230895266,
      "grad_norm": 1.5717681646347046,
      "learning_rate": 6.230030324502978e-07,
      "loss": 1.2859,
      "step": 54600
    },
    {
      "epoch": 2.5222749143272525,
      "grad_norm": 2.1850101947784424,
      "learning_rate": 6.171659982289308e-07,
      "loss": 1.3192,
      "step": 54650
    },
    {
      "epoch": 2.5245825977592395,
      "grad_norm": 1.7604453563690186,
      "learning_rate": 6.113546379041352e-07,
      "loss": 1.2812,
      "step": 54700
    },
    {
      "epoch": 2.526890281191226,
      "grad_norm": 2.446686267852783,
      "learning_rate": 6.055689855178709e-07,
      "loss": 1.3174,
      "step": 54750
    },
    {
      "epoch": 2.5291979646232132,
      "grad_norm": 2.384460926055908,
      "learning_rate": 5.99809074961506e-07,
      "loss": 1.3269,
      "step": 54800
    },
    {
      "epoch": 2.5315056480552,
      "grad_norm": 1.9690098762512207,
      "learning_rate": 5.94074939975619e-07,
      "loss": 1.3268,
      "step": 54850
    },
    {
      "epoch": 2.5338133314871865,
      "grad_norm": 1.6853041648864746,
      "learning_rate": 5.884805275200161e-07,
      "loss": 1.3112,
      "step": 54900
    },
    {
      "epoch": 2.5361210149191735,
      "grad_norm": 1.9527335166931152,
      "learning_rate": 5.827975271139746e-07,
      "loss": 1.3278,
      "step": 54950
    },
    {
      "epoch": 2.53842869835116,
      "grad_norm": 1.7782621383666992,
      "learning_rate": 5.771404019291655e-07,
      "loss": 1.341,
      "step": 55000
    },
    {
      "epoch": 2.53842869835116,
      "eval_loss": 1.3068640232086182,
      "eval_runtime": 178.125,
      "eval_samples_per_second": 28.07,
      "eval_steps_per_second": 1.173,
      "step": 55000
    },
    {
      "epoch": 2.540736381783147,
      "grad_norm": 1.7991583347320557,
      "learning_rate": 5.715091851040671e-07,
      "loss": 1.3387,
      "step": 55050
    },
    {
      "epoch": 2.543044065215134,
      "grad_norm": 1.707184076309204,
      "learning_rate": 5.659039096253899e-07,
      "loss": 1.2983,
      "step": 55100
    },
    {
      "epoch": 2.5453517486471204,
      "grad_norm": 1.790588140487671,
      "learning_rate": 5.603246083278835e-07,
      "loss": 1.3714,
      "step": 55150
    },
    {
      "epoch": 2.5476594320791075,
      "grad_norm": 1.9872910976409912,
      "learning_rate": 5.54771313894149e-07,
      "loss": 1.3366,
      "step": 55200
    },
    {
      "epoch": 2.549967115511094,
      "grad_norm": 2.0171163082122803,
      "learning_rate": 5.492440588544401e-07,
      "loss": 1.2787,
      "step": 55250
    },
    {
      "epoch": 2.552274798943081,
      "grad_norm": 1.7658827304840088,
      "learning_rate": 5.437428755864776e-07,
      "loss": 1.3154,
      "step": 55300
    },
    {
      "epoch": 2.554582482375068,
      "grad_norm": 1.8168197870254517,
      "learning_rate": 5.382677963152577e-07,
      "loss": 1.3015,
      "step": 55350
    },
    {
      "epoch": 2.5568901658070544,
      "grad_norm": 2.020490884780884,
      "learning_rate": 5.328188531128636e-07,
      "loss": 1.3305,
      "step": 55400
    },
    {
      "epoch": 2.5591978492390415,
      "grad_norm": 1.834259271621704,
      "learning_rate": 5.27396077898279e-07,
      "loss": 1.3359,
      "step": 55450
    },
    {
      "epoch": 2.561505532671028,
      "grad_norm": 1.7105354070663452,
      "learning_rate": 5.219995024371982e-07,
      "loss": 1.2707,
      "step": 55500
    },
    {
      "epoch": 2.563813216103015,
      "grad_norm": 1.567327857017517,
      "learning_rate": 5.166291583418448e-07,
      "loss": 1.2693,
      "step": 55550
    },
    {
      "epoch": 2.5661208995350018,
      "grad_norm": 2.052874803543091,
      "learning_rate": 5.112850770707806e-07,
      "loss": 1.2985,
      "step": 55600
    },
    {
      "epoch": 2.5684285829669884,
      "grad_norm": 2.0051448345184326,
      "learning_rate": 5.059672899287255e-07,
      "loss": 1.3026,
      "step": 55650
    },
    {
      "epoch": 2.5707362663989755,
      "grad_norm": 2.12873911857605,
      "learning_rate": 5.006758280663715e-07,
      "loss": 1.3292,
      "step": 55700
    },
    {
      "epoch": 2.573043949830962,
      "grad_norm": 1.942803978919983,
      "learning_rate": 4.954107224802052e-07,
      "loss": 1.3335,
      "step": 55750
    },
    {
      "epoch": 2.575351633262949,
      "grad_norm": 1.624422311782837,
      "learning_rate": 4.901720040123182e-07,
      "loss": 1.3313,
      "step": 55800
    },
    {
      "epoch": 2.5776593166949358,
      "grad_norm": 1.7847707271575928,
      "learning_rate": 4.849597033502329e-07,
      "loss": 1.2847,
      "step": 55850
    },
    {
      "epoch": 2.5799670001269224,
      "grad_norm": 1.9148322343826294,
      "learning_rate": 4.797738510267214e-07,
      "loss": 1.3002,
      "step": 55900
    },
    {
      "epoch": 2.5822746835589094,
      "grad_norm": 1.7572835683822632,
      "learning_rate": 4.746144774196243e-07,
      "loss": 1.3374,
      "step": 55950
    },
    {
      "epoch": 2.584582366990896,
      "grad_norm": 1.7436892986297607,
      "learning_rate": 4.69481612751676e-07,
      "loss": 1.316,
      "step": 56000
    },
    {
      "epoch": 2.584582366990896,
      "eval_loss": 1.3063772916793823,
      "eval_runtime": 178.1775,
      "eval_samples_per_second": 28.062,
      "eval_steps_per_second": 1.173,
      "step": 56000
    },
    {
      "epoch": 2.586890050422883,
      "grad_norm": 1.986126184463501,
      "learning_rate": 4.6437528709032456e-07,
      "loss": 1.3085,
      "step": 56050
    },
    {
      "epoch": 2.5891977338548697,
      "grad_norm": 1.8780035972595215,
      "learning_rate": 4.592955303475577e-07,
      "loss": 1.3048,
      "step": 56100
    },
    {
      "epoch": 2.5915054172868563,
      "grad_norm": 1.5462607145309448,
      "learning_rate": 4.542423722797268e-07,
      "loss": 1.3193,
      "step": 56150
    },
    {
      "epoch": 2.5938131007188434,
      "grad_norm": 1.7938910722732544,
      "learning_rate": 4.492158424873738e-07,
      "loss": 1.3007,
      "step": 56200
    },
    {
      "epoch": 2.59612078415083,
      "grad_norm": 1.6621687412261963,
      "learning_rate": 4.442159704150539e-07,
      "loss": 1.3003,
      "step": 56250
    },
    {
      "epoch": 2.598428467582817,
      "grad_norm": 1.7297366857528687,
      "learning_rate": 4.392427853511705e-07,
      "loss": 1.2952,
      "step": 56300
    },
    {
      "epoch": 2.6007361510148037,
      "grad_norm": 1.7597566843032837,
      "learning_rate": 4.3429631642779414e-07,
      "loss": 1.3105,
      "step": 56350
    },
    {
      "epoch": 2.6030438344467903,
      "grad_norm": 1.6019341945648193,
      "learning_rate": 4.2937659262049957e-07,
      "loss": 1.3017,
      "step": 56400
    },
    {
      "epoch": 2.6053515178787774,
      "grad_norm": 1.8073811531066895,
      "learning_rate": 4.2448364274819297e-07,
      "loss": 1.2986,
      "step": 56450
    },
    {
      "epoch": 2.6076592013107645,
      "grad_norm": 1.8412712812423706,
      "learning_rate": 4.196174954729432e-07,
      "loss": 1.3058,
      "step": 56500
    },
    {
      "epoch": 2.609966884742751,
      "grad_norm": 2.170440435409546,
      "learning_rate": 4.147781792998135e-07,
      "loss": 1.3225,
      "step": 56550
    },
    {
      "epoch": 2.6122745681747377,
      "grad_norm": 1.8993839025497437,
      "learning_rate": 4.099657225766951e-07,
      "loss": 1.3123,
      "step": 56600
    },
    {
      "epoch": 2.6145822516067247,
      "grad_norm": 1.7730835676193237,
      "learning_rate": 4.051801534941413e-07,
      "loss": 1.3172,
      "step": 56650
    },
    {
      "epoch": 2.6168899350387114,
      "grad_norm": 1.5931732654571533,
      "learning_rate": 4.0042150008520296e-07,
      "loss": 1.3327,
      "step": 56700
    },
    {
      "epoch": 2.6191976184706984,
      "grad_norm": 1.7438362836837769,
      "learning_rate": 3.9568979022526264e-07,
      "loss": 1.3385,
      "step": 56750
    },
    {
      "epoch": 2.621505301902685,
      "grad_norm": 1.9364771842956543,
      "learning_rate": 3.9098505163187194e-07,
      "loss": 1.3268,
      "step": 56800
    },
    {
      "epoch": 2.6238129853346717,
      "grad_norm": 1.7055528163909912,
      "learning_rate": 3.8630731186458994e-07,
      "loss": 1.2987,
      "step": 56850
    },
    {
      "epoch": 2.6261206687666587,
      "grad_norm": 1.8541767597198486,
      "learning_rate": 3.816565983248216e-07,
      "loss": 1.3408,
      "step": 56900
    },
    {
      "epoch": 2.6284283521986453,
      "grad_norm": 1.6875929832458496,
      "learning_rate": 3.770329382556559e-07,
      "loss": 1.3449,
      "step": 56950
    },
    {
      "epoch": 2.6307360356306324,
      "grad_norm": 1.9264196157455444,
      "learning_rate": 3.7243635874170794e-07,
      "loss": 1.3183,
      "step": 57000
    },
    {
      "epoch": 2.6307360356306324,
      "eval_loss": 1.3063852787017822,
      "eval_runtime": 178.09,
      "eval_samples_per_second": 28.076,
      "eval_steps_per_second": 1.174,
      "step": 57000
    }
  ],
  "logging_steps": 50,
  "max_steps": 65001,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0950580197425938e+19,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
