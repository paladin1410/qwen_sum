2025-08-26 06:47:41,315 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 06:48:18,213 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 06:49:41,404 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 06:50:27,932 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 06:59:23,003 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:00:15,777 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:20:32,925 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:22:32,436 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:39:36,345 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:42:55,165 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:51:39,305 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 07:54:21,028 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 08:57:06,824 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 08:58:56,005 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 08:59:07,784 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 08:59:08,839 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:01:20,777 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:01:32,799 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:01:34,567 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:06:35,759 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:06:47,745 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:06:50,192 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:09:27,131 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:09:38,926 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:09:40,895 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:14:22,579 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:14:34,477 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:14:36,288 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:29:03,020 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:29:16,701 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:29:20,587 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:33:16,069 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:33:29,355 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=3,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_09-33-29_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 09:33:29,360 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:33:32,113 - root - INFO - ðŸš€ Starting training...
2025-08-26 09:36:36,804 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 09:36:48,590 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_09-36-48_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 09:36:48,595 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 09:36:51,235 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:02:55,524 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:02:55,530 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:02:55,758 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:14:08,555 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-14-08_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:14:11,341 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:14:11,982 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-14-11_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:14:15,381 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-14-15_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:14:15,387 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 10:14:15,890 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:14:18,098 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:15:02,452 - root - INFO - TRAINER_LOGS - loss: 2.7138 grad_norm: 3.1705806255340576 learning_rate: 4.7e-06 epoch: 0.0023076834319868
2025-08-26 10:17:04,109 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:17:25,674 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=3,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-17-25_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:17:25,680 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 10:17:29,831 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:18:41,623 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:18:41,908 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:18:41,943 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:18:56,857 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-18-56_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:18:56,947 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-18-56_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:18:57,570 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-18-57_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:18:57,574 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 10:18:58,561 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:18:58,577 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:19:00,505 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:19:44,366 - root - INFO - TRAINER_LOGS - loss: 2.7133 grad_norm: 3.2187986373901367 learning_rate: 4.7e-06 epoch: 0.0023076834319868
2025-08-26 10:20:27,778 - root - INFO - TRAINER_LOGS - loss: 1.9952 grad_norm: 1.7938612699508667 learning_rate: 9.7e-06 epoch: 0.0046153668639736
2025-08-26 10:20:27,832 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:21:10,002 - root - INFO - TRAINER_LOGS - loss: 1.5175 grad_norm: 1.1498531103134155 learning_rate: 9.999987060052761e-06 epoch: 0.0069230502959604
2025-08-26 10:21:52,614 - root - INFO - TRAINER_LOGS - loss: 1.5308 grad_norm: 1.165283203125 learning_rate: 9.999944883751735e-06 epoch: 0.0092307337279472
2025-08-26 10:31:30,454 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=3,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-31-30_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:31:30,460 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 10:31:33,904 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:32:38,788 - root - INFO - TRAINER_LOGS - loss: 0.9049 grad_norm: 82282.0 learning_rate: 4.9000000000000005e-06 epoch: 0.0023076834319868
2025-08-26 10:33:43,633 - root - INFO - TRAINER_LOGS - loss: 0.6969 grad_norm: 61123.8984375 learning_rate: 9.9e-06 epoch: 0.0046153668639736
2025-08-26 10:34:47,236 - root - INFO - TRAINER_LOGS - loss: 0.5116 grad_norm: 44011.10546875 learning_rate: 9.99998593534986e-06 epoch: 0.0069230502959604
2025-08-26 10:35:52,389 - root - INFO - TRAINER_LOGS - loss: 0.5135 grad_norm: 61317.0546875 learning_rate: 9.999942587489862e-06 epoch: 0.0092307337279472
2025-08-26 10:36:57,898 - root - INFO - TRAINER_LOGS - loss: 0.5193 grad_norm: 38346.50390625 learning_rate: 9.999869950816095e-06 epoch: 0.011538417159934
2025-08-26 10:38:02,646 - root - INFO - TRAINER_LOGS - loss: 0.5098 grad_norm: 36856.4453125 learning_rate: 9.999768025754053e-06 epoch: 0.0138461005919208
2025-08-26 10:39:06,308 - root - INFO - TRAINER_LOGS - loss: 0.4952 grad_norm: 39696.96875 learning_rate: 9.999636812900798e-06 epoch: 0.0161537840239076
2025-08-26 10:40:10,774 - root - INFO - TRAINER_LOGS - loss: 0.4844 grad_norm: 31555.89453125 learning_rate: 9.99947631302495e-06 epoch: 0.0184614674558944
2025-08-26 10:41:13,858 - root - INFO - TRAINER_LOGS - loss: 0.512 grad_norm: 38514.66796875 learning_rate: 9.999286527066691e-06 epoch: 0.0207691508878812
2025-08-26 10:42:17,959 - root - INFO - TRAINER_LOGS - loss: 0.4973 grad_norm: 34827.1953125 learning_rate: 9.999067456137756e-06 epoch: 0.023076834319868
2025-08-26 10:42:45,354 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:42:45,358 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:42:45,364 - root - INFO - ðŸ”§ Configuration loaded successfully.
2025-08-26 10:43:10,108 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-43-10_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:43:10,113 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-08-26 10:43:10,257 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-43-10_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:43:11,061 - root - INFO - EFFECTIVE TrainingArguments: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=1000,
eval_strategy=steps,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./results/output/runs/Aug26_10-43-11_9568fd5a3cce,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3,
optim=paged_adamw_8bit,
optim_args=None,
optim_target_modules=None,
output_dir=./results/output,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=10,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
)
2025-08-26 10:43:13,556 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:43:14,623 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:43:14,737 - root - INFO - ðŸš€ Starting training...
2025-08-26 10:43:58,441 - root - INFO - TRAINER_LOGS - loss: 2.7128 grad_norm: 3.234070301055908 learning_rate: 4.7e-06 epoch: 0.0023076834319868
2025-08-26 10:44:41,701 - root - INFO - TRAINER_LOGS - loss: 1.9984 grad_norm: 1.803808569908142 learning_rate: 9.7e-06 epoch: 0.0046153668639736
2025-08-26 10:45:24,265 - root - INFO - TRAINER_LOGS - loss: 1.5177 grad_norm: 1.185814380645752 learning_rate: 9.999987060052761e-06 epoch: 0.0069230502959604
2025-08-26 10:46:06,966 - root - INFO - TRAINER_LOGS - loss: 1.5309 grad_norm: 1.1732913255691528 learning_rate: 9.999944883751735e-06 epoch: 0.0092307337279472
2025-08-26 10:46:50,169 - root - INFO - TRAINER_LOGS - loss: 1.5033 grad_norm: 1.0128954648971558 learning_rate: 9.999873418623491e-06 epoch: 0.011538417159934
2025-08-26 10:47:32,825 - root - INFO - TRAINER_LOGS - loss: 1.4592 grad_norm: 0.9635249376296997 learning_rate: 9.99977266508666e-06 epoch: 0.0138461005919208
2025-08-26 10:48:15,387 - root - INFO - TRAINER_LOGS - loss: 1.4804 grad_norm: 1.2935932874679565 learning_rate: 9.999642623731437e-06 epoch: 0.0161537840239076
2025-08-26 10:48:58,314 - root - INFO - TRAINER_LOGS - loss: 1.4481 grad_norm: 0.9319048523902893 learning_rate: 9.999483295319584e-06 epoch: 0.0184614674558944
2025-08-26 10:49:40,453 - root - INFO - TRAINER_LOGS - loss: 1.4476 grad_norm: 1.2098811864852905 learning_rate: 9.99929468078442e-06 epoch: 0.0207691508878812
2025-08-26 10:50:23,342 - root - INFO - TRAINER_LOGS - loss: 1.464 grad_norm: 0.9458542466163635 learning_rate: 9.999076781230813e-06 epoch: 0.023076834319868
2025-08-26 10:51:05,938 - root - INFO - TRAINER_LOGS - loss: 1.4152 grad_norm: 1.1508913040161133 learning_rate: 9.998829597935187e-06 epoch: 0.0253845177518548
2025-08-26 10:51:48,455 - root - INFO - TRAINER_LOGS - loss: 1.4352 grad_norm: 1.1195052862167358 learning_rate: 9.998553132345496e-06 epoch: 0.0276922011838416
2025-08-26 10:52:31,325 - root - INFO - TRAINER_LOGS - loss: 1.4686 grad_norm: 1.4136531352996826 learning_rate: 9.99824738608123e-06 epoch: 0.0299998846158284
2025-08-26 10:53:14,477 - root - INFO - TRAINER_LOGS - loss: 1.4112 grad_norm: 1.3209282159805298 learning_rate: 9.997912360933398e-06 epoch: 0.0323075680478152
2025-08-26 10:53:56,748 - root - INFO - TRAINER_LOGS - loss: 1.4074 grad_norm: 1.325654149055481 learning_rate: 9.99754805886452e-06 epoch: 0.034615251479802
2025-08-26 10:54:40,330 - root - INFO - TRAINER_LOGS - loss: 1.4206 grad_norm: 0.9531615972518921 learning_rate: 9.997154482008617e-06 epoch: 0.0369229349117888
2025-08-26 10:55:22,883 - root - INFO - TRAINER_LOGS - loss: 1.4087 grad_norm: 1.0985593795776367 learning_rate: 9.996731632671196e-06 epoch: 0.0392306183437756
2025-08-26 10:56:05,445 - root - INFO - TRAINER_LOGS - loss: 1.433 grad_norm: 0.97088623046875 learning_rate: 9.996279513329232e-06 epoch: 0.0415383017757624
2025-08-26 10:56:47,596 - root - INFO - TRAINER_LOGS - loss: 1.4161 grad_norm: 1.0757375955581665 learning_rate: 9.995798126631166e-06 epoch: 0.043845985207749204
2025-08-26 10:57:30,618 - root - INFO - TRAINER_LOGS - loss: 1.3952 grad_norm: 1.1121803522109985 learning_rate: 9.995287475396883e-06 epoch: 0.046153668639736
2025-08-26 11:00:34,211 - root - INFO - TRAINER_LOGS - eval_loss: 1.4266554117202759 eval_runtime: 183.5883 eval_samples_per_second: 27.235 eval_steps_per_second: 1.138 epoch: 0.046153668639736
2025-08-26 11:01:17,361 - root - INFO - TRAINER_LOGS - loss: 1.364 grad_norm: 1.230531096458435 learning_rate: 9.994747562617686e-06 epoch: 0.0484613520717228
2025-08-26 11:02:00,447 - root - INFO - TRAINER_LOGS - loss: 1.4094 grad_norm: 1.0545494556427002 learning_rate: 9.994178391456295e-06 epoch: 0.0507690355037096
2025-08-26 11:02:43,204 - root - INFO - TRAINER_LOGS - loss: 1.4264 grad_norm: 1.0936639308929443 learning_rate: 9.993579965246816e-06 epoch: 0.053076718935696404
2025-08-26 11:03:25,919 - root - INFO - TRAINER_LOGS - loss: 1.4113 grad_norm: 1.2801318168640137 learning_rate: 9.99295228749473e-06 epoch: 0.0553844023676832
2025-08-26 11:04:08,047 - root - INFO - TRAINER_LOGS - loss: 1.4042 grad_norm: 1.0804117918014526 learning_rate: 9.992295361876865e-06 epoch: 0.05769208579967
2025-08-26 11:04:50,996 - root - INFO - TRAINER_LOGS - loss: 1.4135 grad_norm: 0.9686274528503418 learning_rate: 9.99160919224138e-06 epoch: 0.0599997692316568
2025-08-26 11:05:34,265 - root - INFO - TRAINER_LOGS - loss: 1.4013 grad_norm: 1.0597426891326904 learning_rate: 9.990893782607742e-06 epoch: 0.062307452663643605
2025-08-26 11:06:16,928 - root - INFO - TRAINER_LOGS - loss: 1.4446 grad_norm: 1.1714166402816772 learning_rate: 9.990149137166696e-06 epoch: 0.0646151360956304
2025-08-26 11:06:59,541 - root - INFO - TRAINER_LOGS - loss: 1.4196 grad_norm: 0.9853427410125732 learning_rate: 9.989375260280251e-06 epoch: 0.06692281952761721
2025-08-26 11:07:42,952 - root - INFO - TRAINER_LOGS - loss: 1.4196 grad_norm: 1.3195018768310547 learning_rate: 9.988572156481644e-06 epoch: 0.069230502959604
2025-08-26 11:08:25,666 - root - INFO - TRAINER_LOGS - loss: 1.3807 grad_norm: 1.314433217048645 learning_rate: 9.987739830475323e-06 epoch: 0.0715381863915908
2025-08-26 11:09:09,352 - root - INFO - TRAINER_LOGS - loss: 1.4288 grad_norm: 1.0599256753921509 learning_rate: 9.986878287136909e-06 epoch: 0.0738458698235776
2025-08-26 11:09:51,400 - root - INFO - TRAINER_LOGS - loss: 1.372 grad_norm: 1.3608887195587158 learning_rate: 9.98598753151318e-06 epoch: 0.0761535532555644
2025-08-26 11:10:34,503 - root - INFO - TRAINER_LOGS - loss: 1.4289 grad_norm: 1.1401894092559814 learning_rate: 9.985067568822028e-06 epoch: 0.0784612366875512
2025-08-26 11:11:17,165 - root - INFO - TRAINER_LOGS - loss: 1.4145 grad_norm: 1.1807911396026611 learning_rate: 9.98411840445244e-06 epoch: 0.080768920119538
2025-08-26 11:11:59,531 - root - INFO - TRAINER_LOGS - loss: 1.3852 grad_norm: 1.1952358484268188 learning_rate: 9.98314004396446e-06 epoch: 0.0830766035515248
2025-08-26 11:12:41,737 - root - INFO - TRAINER_LOGS - loss: 1.4089 grad_norm: 1.017669439315796 learning_rate: 9.982132493089152e-06 epoch: 0.0853842869835116
2025-08-26 11:13:24,580 - root - INFO - TRAINER_LOGS - loss: 1.4239 grad_norm: 1.3019542694091797 learning_rate: 9.981095757728586e-06 epoch: 0.08769197041549841
2025-08-26 11:14:07,414 - root - INFO - TRAINER_LOGS - loss: 1.4363 grad_norm: 1.105987787246704 learning_rate: 9.980029843955777e-06 epoch: 0.0899996538474852
2025-08-26 11:14:50,949 - root - INFO - TRAINER_LOGS - loss: 1.4083 grad_norm: 1.2253038883209229 learning_rate: 9.978934758014667e-06 epoch: 0.092307337279472
2025-08-26 11:17:49,355 - root - INFO - TRAINER_LOGS - eval_loss: 1.3999137878417969 eval_runtime: 178.4021 eval_samples_per_second: 28.027 eval_steps_per_second: 1.172 epoch: 0.092307337279472
2025-08-26 11:18:32,199 - root - INFO - TRAINER_LOGS - loss: 1.4233 grad_norm: 1.37126624584198 learning_rate: 9.977810506320084e-06 epoch: 0.0946150207114588
2025-08-26 11:19:14,538 - root - INFO - TRAINER_LOGS - loss: 1.4098 grad_norm: 1.2563042640686035 learning_rate: 9.976657095457702e-06 epoch: 0.0969227041434456
2025-08-26 11:19:56,540 - root - INFO - TRAINER_LOGS - loss: 1.4131 grad_norm: 1.2131456136703491 learning_rate: 9.975474532184008e-06 epoch: 0.0992303875754324
2025-08-26 11:20:38,334 - root - INFO - TRAINER_LOGS - loss: 1.3923 grad_norm: 0.9997296333312988 learning_rate: 9.974262823426256e-06 epoch: 0.1015380710074192
2025-08-26 11:21:20,134 - root - INFO - TRAINER_LOGS - loss: 1.3666 grad_norm: 1.4654428958892822 learning_rate: 9.973021976282426e-06 epoch: 0.103845754439406
2025-08-26 11:22:03,479 - root - INFO - TRAINER_LOGS - loss: 1.4195 grad_norm: 1.2952613830566406 learning_rate: 9.971751998021196e-06 epoch: 0.10615343787139281
2025-08-26 11:22:46,384 - root - INFO - TRAINER_LOGS - loss: 1.4043 grad_norm: 1.2366816997528076 learning_rate: 9.970452896081878e-06 epoch: 0.1084611213033796
2025-08-26 11:23:28,445 - root - INFO - TRAINER_LOGS - loss: 1.4059 grad_norm: 1.4446766376495361 learning_rate: 9.969124678074394e-06 epoch: 0.1107688047353664
2025-08-26 11:24:11,645 - root - INFO - TRAINER_LOGS - loss: 1.3928 grad_norm: 1.1339999437332153 learning_rate: 9.967767351779215e-06 epoch: 0.1130764881673532
2025-08-26 11:24:54,173 - root - INFO - TRAINER_LOGS - loss: 1.4294 grad_norm: 1.231937050819397 learning_rate: 9.96638092514733e-06 epoch: 0.11538417159934
2025-08-26 11:25:37,176 - root - INFO - TRAINER_LOGS - loss: 1.3899 grad_norm: 0.9418694376945496 learning_rate: 9.964965406300191e-06 epoch: 0.1176918550313268
2025-08-26 11:26:20,251 - root - INFO - TRAINER_LOGS - loss: 1.3939 grad_norm: 1.3084807395935059 learning_rate: 9.963520803529669e-06 epoch: 0.1199995384633136
2025-08-26 11:27:02,214 - root - INFO - TRAINER_LOGS - loss: 1.3726 grad_norm: 1.187669038772583 learning_rate: 9.962047125297995e-06 epoch: 0.1223072218953004
2025-08-26 11:27:46,279 - root - INFO - TRAINER_LOGS - loss: 1.4191 grad_norm: 1.2251622676849365 learning_rate: 9.960544380237733e-06 epoch: 0.12461490532728721
2025-08-26 11:28:29,652 - root - INFO - TRAINER_LOGS - loss: 1.3833 grad_norm: 1.2395092248916626 learning_rate: 9.959043497924318e-06 epoch: 0.126922588759274
2025-08-26 11:29:12,258 - root - INFO - TRAINER_LOGS - loss: 1.3938 grad_norm: 1.1666330099105835 learning_rate: 9.957483226677583e-06 epoch: 0.1292302721912608
2025-08-26 11:29:55,034 - root - INFO - TRAINER_LOGS - loss: 1.3768 grad_norm: 1.6935616731643677 learning_rate: 9.955893915336796e-06 epoch: 0.1315379556232476
2025-08-26 11:30:38,216 - root - INFO - TRAINER_LOGS - loss: 1.4052 grad_norm: 1.2206794023513794 learning_rate: 9.954275573211878e-06 epoch: 0.13384563905523442
2025-08-26 11:31:20,074 - root - INFO - TRAINER_LOGS - loss: 1.3868 grad_norm: 1.1947776079177856 learning_rate: 9.952628209782797e-06 epoch: 0.1361533224872212
2025-08-26 11:32:02,075 - root - INFO - TRAINER_LOGS - loss: 1.3989 grad_norm: 1.5884712934494019 learning_rate: 9.950951834699532e-06 epoch: 0.138461005919208
2025-08-26 11:35:00,555 - root - INFO - TRAINER_LOGS - eval_loss: 1.3870929479599 eval_runtime: 178.4755 eval_samples_per_second: 28.015 eval_steps_per_second: 1.171 epoch: 0.138461005919208
2025-08-26 11:35:43,302 - root - INFO - TRAINER_LOGS - loss: 1.4001 grad_norm: 1.354844093322754 learning_rate: 9.949246457782003e-06 epoch: 0.1407686893511948
2025-08-26 11:36:26,208 - root - INFO - TRAINER_LOGS - loss: 1.3649 grad_norm: 1.1765773296356201 learning_rate: 9.947512089020014e-06 epoch: 0.1430763727831816
2025-08-26 11:37:09,129 - root - INFO - TRAINER_LOGS - loss: 1.3866 grad_norm: 1.1801015138626099 learning_rate: 9.945748738573206e-06 epoch: 0.1453840562151684
2025-08-26 11:37:51,706 - root - INFO - TRAINER_LOGS - loss: 1.377 grad_norm: 1.680984616279602 learning_rate: 9.943956416770987e-06 epoch: 0.1476917396471552
2025-08-26 11:38:34,446 - root - INFO - TRAINER_LOGS - loss: 1.3594 grad_norm: 1.4463222026824951 learning_rate: 9.94213513411247e-06 epoch: 0.149999423079142
2025-08-26 11:39:17,170 - root - INFO - TRAINER_LOGS - loss: 1.3786 grad_norm: 1.2378607988357544 learning_rate: 9.940284901266422e-06 epoch: 0.1523071065111288
2025-08-26 11:39:59,011 - root - INFO - TRAINER_LOGS - loss: 1.3976 grad_norm: 1.2128461599349976 learning_rate: 9.938405729071192e-06 epoch: 0.15461478994311562
2025-08-26 11:40:41,576 - root - INFO - TRAINER_LOGS - loss: 1.4038 grad_norm: 1.3348947763442993 learning_rate: 9.93649762853465e-06 epoch: 0.1569224733751024
2025-08-26 11:41:24,121 - root - INFO - TRAINER_LOGS - loss: 1.4103 grad_norm: 1.1455196142196655 learning_rate: 9.934560610834126e-06 epoch: 0.1592301568070892
2025-08-26 11:42:07,489 - root - INFO - TRAINER_LOGS - loss: 1.3464 grad_norm: 1.3384920358657837 learning_rate: 9.93259468731634e-06 epoch: 0.161537840239076
2025-08-26 11:42:49,475 - root - INFO - TRAINER_LOGS - loss: 1.3428 grad_norm: 1.3076852560043335 learning_rate: 9.930599869497337e-06 epoch: 0.1638455236710628
2025-08-26 11:43:32,373 - root - INFO - TRAINER_LOGS - loss: 1.3962 grad_norm: 1.3590813875198364 learning_rate: 9.928576169062422e-06 epoch: 0.1661532071030496
2025-08-26 11:44:15,181 - root - INFO - TRAINER_LOGS - loss: 1.3988 grad_norm: 1.1356443166732788 learning_rate: 9.926523597866088e-06 epoch: 0.1684608905350364
2025-08-26 11:44:57,668 - root - INFO - TRAINER_LOGS - loss: 1.3752 grad_norm: 1.2136253118515015 learning_rate: 9.924442167931947e-06 epoch: 0.1707685739670232
2025-08-26 11:45:40,671 - root - INFO - TRAINER_LOGS - loss: 1.4051 grad_norm: 1.24173903465271 learning_rate: 9.922331891452662e-06 epoch: 0.17307625739901
2025-08-26 11:46:22,563 - root - INFO - TRAINER_LOGS - loss: 1.4034 grad_norm: 1.1268192529678345 learning_rate: 9.920192780789875e-06 epoch: 0.17538394083099682
2025-08-26 11:47:05,385 - root - INFO - TRAINER_LOGS - loss: 1.3583 grad_norm: 1.4889854192733765 learning_rate: 9.918024848474133e-06 epoch: 0.1776916242629836
2025-08-26 11:47:47,463 - root - INFO - TRAINER_LOGS - loss: 1.3918 grad_norm: 1.4490572214126587 learning_rate: 9.915828107204812e-06 epoch: 0.1799993076949704
2025-08-26 11:48:30,143 - root - INFO - TRAINER_LOGS - loss: 1.3809 grad_norm: 1.299573540687561 learning_rate: 9.913602569850052e-06 epoch: 0.1823069911269572
2025-08-26 11:49:12,266 - root - INFO - TRAINER_LOGS - loss: 1.4005 grad_norm: 1.1006134748458862 learning_rate: 9.91134824944667e-06 epoch: 0.184614674558944
2025-08-26 11:52:10,513 - root - INFO - TRAINER_LOGS - eval_loss: 1.3781589269638062 eval_runtime: 178.243 eval_samples_per_second: 28.052 eval_steps_per_second: 1.173 epoch: 0.184614674558944
2025-08-26 11:52:53,888 - root - INFO - TRAINER_LOGS - loss: 1.3297 grad_norm: 1.521079659461975 learning_rate: 9.909065159200095e-06 epoch: 0.1869223579909308
2025-08-26 11:53:36,655 - root - INFO - TRAINER_LOGS - loss: 1.4013 grad_norm: 1.354052186012268 learning_rate: 9.90675331248428e-06 epoch: 0.1892300414229176
2025-08-26 11:54:19,531 - root - INFO - TRAINER_LOGS - loss: 1.3962 grad_norm: 1.0919792652130127 learning_rate: 9.90441272284163e-06 epoch: 0.19153772485490442
2025-08-26 11:55:03,009 - root - INFO - TRAINER_LOGS - loss: 1.3906 grad_norm: 1.2446045875549316 learning_rate: 9.90204340398292e-06 epoch: 0.1938454082868912
2025-08-26 11:55:45,240 - root - INFO - TRAINER_LOGS - loss: 1.3781 grad_norm: 1.2204394340515137 learning_rate: 9.899645369787218e-06 epoch: 0.19615309171887801
2025-08-26 11:56:27,658 - root - INFO - TRAINER_LOGS - loss: 1.362 grad_norm: 1.2081555128097534 learning_rate: 9.897218634301802e-06 epoch: 0.1984607751508648
2025-08-26 11:57:10,107 - root - INFO - TRAINER_LOGS - loss: 1.3705 grad_norm: 1.366284728050232 learning_rate: 9.894763211742073e-06 epoch: 0.2007684585828516
2025-08-26 11:57:53,499 - root - INFO - TRAINER_LOGS - loss: 1.378 grad_norm: 1.4689913988113403 learning_rate: 9.892279116491483e-06 epoch: 0.2030761420148384
2025-08-26 11:58:36,350 - root - INFO - TRAINER_LOGS - loss: 1.3889 grad_norm: 1.130577564239502 learning_rate: 9.889766363101435e-06 epoch: 0.2053838254468252
2025-08-26 11:59:18,379 - root - INFO - TRAINER_LOGS - loss: 1.3782 grad_norm: 1.274696946144104 learning_rate: 9.887224966291217e-06 epoch: 0.207691508878812
2025-08-26 12:00:01,531 - root - INFO - TRAINER_LOGS - loss: 1.3854 grad_norm: 1.26731276512146 learning_rate: 9.884654940947896e-06 epoch: 0.2099991923107988
2025-08-26 12:00:44,316 - root - INFO - TRAINER_LOGS - loss: 1.3524 grad_norm: 1.329776644706726 learning_rate: 9.882056302126242e-06 epoch: 0.21230687574278562
2025-08-26 12:01:26,416 - root - INFO - TRAINER_LOGS - loss: 1.3673 grad_norm: 1.4293302297592163 learning_rate: 9.879429065048642e-06 epoch: 0.2146145591747724
2025-08-26 12:02:08,886 - root - INFO - TRAINER_LOGS - loss: 1.3608 grad_norm: 1.2220356464385986 learning_rate: 9.876773245105004e-06 epoch: 0.2169222426067592
2025-08-26 12:02:51,167 - root - INFO - TRAINER_LOGS - loss: 1.3813 grad_norm: 1.3201549053192139 learning_rate: 9.874088857852668e-06 epoch: 0.219229926038746
2025-08-26 12:03:34,221 - root - INFO - TRAINER_LOGS - loss: 1.3924 grad_norm: 1.3053706884384155 learning_rate: 9.871375919016321e-06 epoch: 0.2215376094707328
2025-08-26 12:04:18,185 - root - INFO - TRAINER_LOGS - loss: 1.3255 grad_norm: 1.4297142028808594 learning_rate: 9.868634444487897e-06 epoch: 0.2238452929027196
2025-08-26 12:05:00,563 - root - INFO - TRAINER_LOGS - loss: 1.3542 grad_norm: 1.3589943647384644 learning_rate: 9.865864450326486e-06 epoch: 0.2261529763347064
2025-08-26 12:05:43,155 - root - INFO - TRAINER_LOGS - loss: 1.3465 grad_norm: 1.2394944429397583 learning_rate: 9.863065952758244e-06 epoch: 0.2284606597666932
2025-08-26 12:06:25,338 - root - INFO - TRAINER_LOGS - loss: 1.3988 grad_norm: 1.2589763402938843 learning_rate: 9.860238968176294e-06 epoch: 0.23076834319868
2025-08-26 12:09:23,847 - root - INFO - TRAINER_LOGS - eval_loss: 1.3694864511489868 eval_runtime: 178.5036 eval_samples_per_second: 28.011 eval_steps_per_second: 1.171 epoch: 0.23076834319868
2025-08-26 12:10:06,904 - root - INFO - TRAINER_LOGS - loss: 1.366 grad_norm: 1.3532823324203491 learning_rate: 9.85738351314063e-06 epoch: 0.23307602663066682
2025-08-26 12:10:49,000 - root - INFO - TRAINER_LOGS - loss: 1.3993 grad_norm: 1.283898949623108 learning_rate: 9.854499604378026e-06 epoch: 0.2353837100626536
2025-08-26 12:11:31,959 - root - INFO - TRAINER_LOGS - loss: 1.3527 grad_norm: 1.2848609685897827 learning_rate: 9.851587258781925e-06 epoch: 0.2376913934946404
2025-08-26 12:12:13,879 - root - INFO - TRAINER_LOGS - loss: 1.3894 grad_norm: 1.5865778923034668 learning_rate: 9.848646493412353e-06 epoch: 0.2399990769266272
2025-08-26 12:12:56,911 - root - INFO - TRAINER_LOGS - loss: 1.3928 grad_norm: 1.4455169439315796 learning_rate: 9.845677325495817e-06 epoch: 0.242306760358614
2025-08-26 12:13:39,277 - root - INFO - TRAINER_LOGS - loss: 1.3702 grad_norm: 1.4260966777801514 learning_rate: 9.842679772425195e-06 epoch: 0.2446144437906008
2025-08-26 12:14:22,307 - root - INFO - TRAINER_LOGS - loss: 1.3692 grad_norm: 1.4814893007278442 learning_rate: 9.839653851759643e-06 epoch: 0.2469221272225876
2025-08-26 12:15:04,868 - root - INFO - TRAINER_LOGS - loss: 1.3882 grad_norm: 1.3308700323104858 learning_rate: 9.836660944348468e-06 epoch: 0.24922981065457442
2025-08-26 12:15:47,511 - root - INFO - TRAINER_LOGS - loss: 1.3738 grad_norm: 1.29794180393219 learning_rate: 9.83357890829827e-06 epoch: 0.25153749408656123
2025-08-26 12:16:30,626 - root - INFO - TRAINER_LOGS - loss: 1.4094 grad_norm: 1.4045895338058472 learning_rate: 9.830468557964456e-06 epoch: 0.253845177518548
2025-08-26 12:17:13,010 - root - INFO - TRAINER_LOGS - loss: 1.3872 grad_norm: 1.7498154640197754 learning_rate: 9.827329911566933e-06 epoch: 0.2561528609505348
2025-08-26 12:17:55,872 - root - INFO - TRAINER_LOGS - loss: 1.3707 grad_norm: 1.1452780961990356 learning_rate: 9.824162987491357e-06 epoch: 0.2584605443825216
2025-08-26 12:18:38,196 - root - INFO - TRAINER_LOGS - loss: 1.3751 grad_norm: 1.6340456008911133 learning_rate: 9.820967804289028e-06 epoch: 0.2607682278145084
2025-08-26 12:19:21,503 - root - INFO - TRAINER_LOGS - loss: 1.362 grad_norm: 1.6047037839889526 learning_rate: 9.817744380676791e-06 epoch: 0.2630759112464952
2025-08-26 12:20:04,309 - root - INFO - TRAINER_LOGS - loss: 1.3356 grad_norm: 1.2555086612701416 learning_rate: 9.814492735536912e-06 epoch: 0.265383594678482
2025-08-26 12:20:46,911 - root - INFO - TRAINER_LOGS - loss: 1.353 grad_norm: 1.6483103036880493 learning_rate: 9.811212887916972e-06 epoch: 0.26769127811046883
2025-08-26 12:21:29,997 - root - INFO - TRAINER_LOGS - loss: 1.4009 grad_norm: 1.5018279552459717 learning_rate: 9.807904857029766e-06 epoch: 0.2699989615424556
2025-08-26 12:22:12,217 - root - INFO - TRAINER_LOGS - loss: 1.3332 grad_norm: 1.3301727771759033 learning_rate: 9.804568662253174e-06 epoch: 0.2723066449744424
2025-08-26 12:22:54,939 - root - INFO - TRAINER_LOGS - loss: 1.3539 grad_norm: 1.4625303745269775 learning_rate: 9.801204323130058e-06 epoch: 0.2746143284064292
2025-08-26 12:23:38,305 - root - INFO - TRAINER_LOGS - loss: 1.3484 grad_norm: 1.6215753555297852 learning_rate: 9.797811859368144e-06 epoch: 0.276922011838416
2025-08-26 12:26:36,694 - root - INFO - TRAINER_LOGS - eval_loss: 1.3653181791305542 eval_runtime: 178.3849 eval_samples_per_second: 28.029 eval_steps_per_second: 1.172 epoch: 0.276922011838416
2025-08-26 12:27:19,860 - root - INFO - TRAINER_LOGS - loss: 1.3474 grad_norm: 1.5025418996810913 learning_rate: 9.794391290839909e-06 epoch: 0.2792296952704028
2025-08-26 12:28:03,025 - root - INFO - TRAINER_LOGS - loss: 1.3727 grad_norm: 1.3979206085205078 learning_rate: 9.790942637582463e-06 epoch: 0.2815373787023896
2025-08-26 12:28:44,898 - root - INFO - TRAINER_LOGS - loss: 1.3827 grad_norm: 1.3955585956573486 learning_rate: 9.787465919797428e-06 epoch: 0.2838450621343764
2025-08-26 12:29:27,726 - root - INFO - TRAINER_LOGS - loss: 1.3455 grad_norm: 1.208298683166504 learning_rate: 9.783961157850827e-06 epoch: 0.2861527455663632
2025-08-26 12:30:11,029 - root - INFO - TRAINER_LOGS - loss: 1.3849 grad_norm: 1.371996521949768 learning_rate: 9.780428372272963e-06 epoch: 0.28846042899835
2025-08-26 12:30:53,420 - root - INFO - TRAINER_LOGS - loss: 1.3522 grad_norm: 1.1958187818527222 learning_rate: 9.776867583758288e-06 epoch: 0.2907681124303368
2025-08-26 12:31:36,154 - root - INFO - TRAINER_LOGS - loss: 1.3854 grad_norm: 1.290692687034607 learning_rate: 9.773278813165297e-06 epoch: 0.29307579586232363
2025-08-26 12:32:19,843 - root - INFO - TRAINER_LOGS - loss: 1.3683 grad_norm: 1.248901128768921 learning_rate: 9.769662081516403e-06 epoch: 0.2953834792943104
2025-08-26 12:33:03,406 - root - INFO - TRAINER_LOGS - loss: 1.3962 grad_norm: 1.3705945014953613 learning_rate: 9.766017409997798e-06 epoch: 0.2976911627262972
2025-08-26 12:33:46,175 - root - INFO - TRAINER_LOGS - loss: 1.3933 grad_norm: 1.7356164455413818 learning_rate: 9.762344819959353e-06 epoch: 0.299998846158284
2025-08-26 12:34:29,760 - root - INFO - TRAINER_LOGS - loss: 1.3677 grad_norm: 1.2354319095611572 learning_rate: 9.758644332914476e-06 epoch: 0.3023065295902708
2025-08-26 12:35:12,215 - root - INFO - TRAINER_LOGS - loss: 1.3249 grad_norm: 1.3022233247756958 learning_rate: 9.754915970539988e-06 epoch: 0.3046142130222576
2025-08-26 12:35:55,892 - root - INFO - TRAINER_LOGS - loss: 1.3635 grad_norm: 1.2888805866241455 learning_rate: 9.751159754676005e-06 epoch: 0.3069218964542444
2025-08-26 12:36:38,670 - root - INFO - TRAINER_LOGS - loss: 1.3738 grad_norm: 1.5069547891616821 learning_rate: 9.747375707325802e-06 epoch: 0.30922957988623123
2025-08-26 12:37:21,446 - root - INFO - TRAINER_LOGS - loss: 1.3843 grad_norm: 1.3925191164016724 learning_rate: 9.74356385065568e-06 epoch: 0.311537263318218
2025-08-26 12:38:05,438 - root - INFO - TRAINER_LOGS - loss: 1.3964 grad_norm: 1.4308773279190063 learning_rate: 9.739724206994852e-06 epoch: 0.3138449467502048
2025-08-26 12:38:47,597 - root - INFO - TRAINER_LOGS - loss: 1.3931 grad_norm: 1.3309776782989502 learning_rate: 9.735856798835298e-06 epoch: 0.3161526301821916
2025-08-26 12:39:30,644 - root - INFO - TRAINER_LOGS - loss: 1.3549 grad_norm: 1.4930305480957031 learning_rate: 9.731961648831633e-06 epoch: 0.3184603136141784
2025-08-26 12:40:13,850 - root - INFO - TRAINER_LOGS - loss: 1.359 grad_norm: 1.4148837327957153 learning_rate: 9.72803877980099e-06 epoch: 0.3207679970461652
2025-08-26 12:40:56,997 - root - INFO - TRAINER_LOGS - loss: 1.3907 grad_norm: 1.4344557523727417 learning_rate: 9.724088214722865e-06 epoch: 0.323075680478152
2025-08-26 12:43:55,204 - root - INFO - TRAINER_LOGS - eval_loss: 1.359694004058838 eval_runtime: 178.2029 eval_samples_per_second: 28.058 eval_steps_per_second: 1.173 epoch: 0.323075680478152
2025-08-26 12:44:38,646 - root - INFO - TRAINER_LOGS - loss: 1.3905 grad_norm: 1.8040902614593506 learning_rate: 9.720109976738996e-06 epoch: 0.32538336391013883
2025-08-26 12:45:22,513 - root - INFO - TRAINER_LOGS - loss: 1.3578 grad_norm: 1.456432819366455 learning_rate: 9.716104089153227e-06 epoch: 0.3276910473421256
2025-08-26 12:46:05,482 - root - INFO - TRAINER_LOGS - loss: 1.3808 grad_norm: 1.3788949251174927 learning_rate: 9.712070575431364e-06 epoch: 0.3299987307741124
2025-08-26 12:46:48,897 - root - INFO - TRAINER_LOGS - loss: 1.3642 grad_norm: 1.2134976387023926 learning_rate: 9.70800945920105e-06 epoch: 0.3323064142060992
2025-08-26 12:47:32,572 - root - INFO - TRAINER_LOGS - loss: 1.3558 grad_norm: 1.3637040853500366 learning_rate: 9.70392076425161e-06 epoch: 0.334614097638086
2025-08-26 12:48:15,650 - root - INFO - TRAINER_LOGS - loss: 1.3519 grad_norm: 1.5762923955917358 learning_rate: 9.69980451453392e-06 epoch: 0.3369217810700728
2025-08-26 12:48:59,014 - root - INFO - TRAINER_LOGS - loss: 1.3572 grad_norm: 1.3395864963531494 learning_rate: 9.695660734160278e-06 epoch: 0.3392294645020596
2025-08-26 12:49:42,072 - root - INFO - TRAINER_LOGS - loss: 1.3549 grad_norm: 1.251217007637024 learning_rate: 9.691489447404243e-06 epoch: 0.3415371479340464
2025-08-26 12:50:25,486 - root - INFO - TRAINER_LOGS - loss: 1.3796 grad_norm: 1.5076048374176025 learning_rate: 9.687374923238843e-06 epoch: 0.3438448313660332
2025-08-26 12:51:08,851 - root - INFO - TRAINER_LOGS - loss: 1.3657 grad_norm: 1.688606858253479 learning_rate: 9.683149246088034e-06 epoch: 0.34615251479802
2025-08-26 12:51:51,557 - root - INFO - TRAINER_LOGS - loss: 1.3846 grad_norm: 1.6821999549865723 learning_rate: 9.678896135845002e-06 epoch: 0.3484601982300068
2025-08-26 12:52:34,909 - root - INFO - TRAINER_LOGS - loss: 1.3494 grad_norm: 1.3190609216690063 learning_rate: 9.674615617423742e-06 epoch: 0.35076788166199363
2025-08-26 12:53:17,599 - root - INFO - TRAINER_LOGS - loss: 1.3549 grad_norm: 1.5519264936447144 learning_rate: 9.670307715898805e-06 epoch: 0.3530755650939804
2025-08-26 12:54:01,120 - root - INFO - TRAINER_LOGS - loss: 1.3914 grad_norm: 1.4892072677612305 learning_rate: 9.665972456505145e-06 epoch: 0.3553832485259672
2025-08-26 12:54:44,276 - root - INFO - TRAINER_LOGS - loss: 1.3622 grad_norm: 1.4824330806732178 learning_rate: 9.661609864637977e-06 epoch: 0.357690931957954
2025-08-26 12:55:27,958 - root - INFO - TRAINER_LOGS - loss: 1.3643 grad_norm: 1.4167470932006836 learning_rate: 9.657219965852618e-06 epoch: 0.3599986153899408
2025-08-26 12:56:10,766 - root - INFO - TRAINER_LOGS - loss: 1.3542 grad_norm: 1.3888047933578491 learning_rate: 9.652802785864355e-06 epoch: 0.3623062988219276
2025-08-26 12:56:53,883 - root - INFO - TRAINER_LOGS - loss: 1.3771 grad_norm: 1.3904517889022827 learning_rate: 9.648358350548272e-06 epoch: 0.3646139822539144
2025-08-26 12:57:37,054 - root - INFO - TRAINER_LOGS - loss: 1.3588 grad_norm: 1.47262704372406 learning_rate: 9.643886685939118e-06 epoch: 0.36692166568590123
2025-08-26 12:58:20,085 - root - INFO - TRAINER_LOGS - loss: 1.3621 grad_norm: 1.4519085884094238 learning_rate: 9.639387818231146e-06 epoch: 0.369229349117888
2025-08-26 13:01:18,022 - root - INFO - TRAINER_LOGS - eval_loss: 1.3545523881912231 eval_runtime: 177.9328 eval_samples_per_second: 28.1 eval_steps_per_second: 1.175 epoch: 0.369229349117888
2025-08-26 13:02:00,463 - root - INFO - TRAINER_LOGS - loss: 1.3809 grad_norm: 1.5121536254882812 learning_rate: 9.634861773777955e-06 epoch: 0.3715370325498748
2025-08-26 13:02:43,336 - root - INFO - TRAINER_LOGS - loss: 1.3356 grad_norm: 1.3477240800857544 learning_rate: 9.630308579092345e-06 epoch: 0.3738447159818616
2025-08-26 13:03:25,966 - root - INFO - TRAINER_LOGS - loss: 1.3533 grad_norm: 1.442193865776062 learning_rate: 9.62572826084616e-06 epoch: 0.3761523994138484
2025-08-26 13:04:09,663 - root - INFO - TRAINER_LOGS - loss: 1.3531 grad_norm: 1.2611267566680908 learning_rate: 9.621120845870118e-06 epoch: 0.3784600828458352
2025-08-26 13:04:53,040 - root - INFO - TRAINER_LOGS - loss: 1.3867 grad_norm: 1.3847886323928833 learning_rate: 9.61648636115368e-06 epoch: 0.380767766277822
2025-08-26 13:05:35,485 - root - INFO - TRAINER_LOGS - loss: 1.3421 grad_norm: 1.456662654876709 learning_rate: 9.611824833844867e-06 epoch: 0.38307544970980884
2025-08-26 13:06:19,906 - root - INFO - TRAINER_LOGS - loss: 1.3445 grad_norm: 1.6888097524642944 learning_rate: 9.607136291250112e-06 epoch: 0.3853831331417956
2025-08-26 13:07:02,516 - root - INFO - TRAINER_LOGS - loss: 1.3955 grad_norm: 1.6469125747680664 learning_rate: 9.602420760834104e-06 epoch: 0.3876908165737824
2025-08-26 13:07:44,912 - root - INFO - TRAINER_LOGS - loss: 1.3801 grad_norm: 1.3542736768722534 learning_rate: 9.597678270219615e-06 epoch: 0.3899985000057692
2025-08-26 13:08:27,847 - root - INFO - TRAINER_LOGS - loss: 1.3491 grad_norm: 1.4657344818115234 learning_rate: 9.59290884718735e-06 epoch: 0.39230618343775603
2025-08-26 13:09:11,417 - root - INFO - TRAINER_LOGS - loss: 1.3544 grad_norm: 1.368537187576294 learning_rate: 9.588112519675782e-06 epoch: 0.3946138668697428
2025-08-26 13:09:54,419 - root - INFO - TRAINER_LOGS - loss: 1.3648 grad_norm: 1.546828269958496 learning_rate: 9.583289315780978e-06 epoch: 0.3969215503017296
2025-08-26 13:10:37,864 - root - INFO - TRAINER_LOGS - loss: 1.3543 grad_norm: 1.4719271659851074 learning_rate: 9.578439263756447e-06 epoch: 0.3992292337337164
2025-08-26 13:11:20,666 - root - INFO - TRAINER_LOGS - loss: 1.3714 grad_norm: 1.4975672960281372 learning_rate: 9.573562392012972e-06 epoch: 0.4015369171657032
2025-08-26 13:12:04,373 - root - INFO - TRAINER_LOGS - loss: 1.3617 grad_norm: 1.3723787069320679 learning_rate: 9.568658729118435e-06 epoch: 0.40384460059769
2025-08-26 13:12:45,689 - root - INFO - TRAINER_LOGS - loss: 1.3722 grad_norm: 1.436517596244812 learning_rate: 9.563728303797661e-06 epoch: 0.4061522840296768
2025-08-26 13:13:28,240 - root - INFO - TRAINER_LOGS - loss: 1.3656 grad_norm: 1.4031198024749756 learning_rate: 9.558771144932246e-06 epoch: 0.40845996746166363
2025-08-26 13:14:11,467 - root - INFO - TRAINER_LOGS - loss: 1.3665 grad_norm: 1.3483961820602417 learning_rate: 9.55378728156038e-06 epoch: 0.4107676508936504
2025-08-26 13:14:54,807 - root - INFO - TRAINER_LOGS - loss: 1.3638 grad_norm: 1.3667676448822021 learning_rate: 9.54877674287669e-06 epoch: 0.4130753343256372
2025-08-26 13:15:38,214 - root - INFO - TRAINER_LOGS - loss: 1.392 grad_norm: 1.4517261981964111 learning_rate: 9.543739558232061e-06 epoch: 0.415383017757624
2025-08-26 13:18:36,230 - root - INFO - TRAINER_LOGS - eval_loss: 1.3481671810150146 eval_runtime: 178.0117 eval_samples_per_second: 28.088 eval_steps_per_second: 1.174 epoch: 0.415383017757624
2025-08-26 13:19:20,143 - root - INFO - TRAINER_LOGS - loss: 1.3688 grad_norm: 1.2423149347305298 learning_rate: 9.538675757133462e-06 epoch: 0.4176907011896108
2025-08-26 13:20:02,976 - root - INFO - TRAINER_LOGS - loss: 1.3767 grad_norm: 1.3997743129730225 learning_rate: 9.53358536924378e-06 epoch: 0.4199983846215976
2025-08-26 13:20:46,104 - root - INFO - TRAINER_LOGS - loss: 1.3665 grad_norm: 1.3724242448806763 learning_rate: 9.528468424381641e-06 epoch: 0.4223060680535844
2025-08-26 13:21:28,735 - root - INFO - TRAINER_LOGS - loss: 1.3483 grad_norm: 1.3290592432022095 learning_rate: 9.52332495252124e-06 epoch: 0.42461375148557123
2025-08-26 13:22:11,668 - root - INFO - TRAINER_LOGS - loss: 1.3479 grad_norm: 1.2846637964248657 learning_rate: 9.518154983792158e-06 epoch: 0.426921434917558
2025-08-26 13:22:54,537 - root - INFO - TRAINER_LOGS - loss: 1.3537 grad_norm: 1.3611632585525513 learning_rate: 9.512958548479197e-06 epoch: 0.4292291183495448
2025-08-26 13:23:37,555 - root - INFO - TRAINER_LOGS - loss: 1.3743 grad_norm: 1.3824471235275269 learning_rate: 9.507735677022187e-06 epoch: 0.4315368017815316
2025-08-26 13:24:20,618 - root - INFO - TRAINER_LOGS - loss: 1.3415 grad_norm: 1.3227802515029907 learning_rate: 9.502486400015825e-06 epoch: 0.4338444852135184
2025-08-26 13:25:03,935 - root - INFO - TRAINER_LOGS - loss: 1.3652 grad_norm: 1.3371866941452026 learning_rate: 9.497210748209483e-06 epoch: 0.4361521686455052
2025-08-26 13:25:46,799 - root - INFO - TRAINER_LOGS - loss: 1.3399 grad_norm: 1.4511524438858032 learning_rate: 9.491908752507031e-06 epoch: 0.438459852077492
2025-08-26 13:26:29,695 - root - INFO - TRAINER_LOGS - loss: 1.3591 grad_norm: 1.4281114339828491 learning_rate: 9.48658044396666e-06 epoch: 0.44076753550947884
2025-08-26 13:27:12,560 - root - INFO - TRAINER_LOGS - loss: 1.3416 grad_norm: 1.2893288135528564 learning_rate: 9.481225853800695e-06 epoch: 0.4430752189414656
2025-08-26 13:27:55,357 - root - INFO - TRAINER_LOGS - loss: 1.3406 grad_norm: 1.2424618005752563 learning_rate: 9.475845013375414e-06 epoch: 0.4453829023734524
2025-08-26 13:28:37,942 - root - INFO - TRAINER_LOGS - loss: 1.3494 grad_norm: 1.462271809577942 learning_rate: 9.470437954210867e-06 epoch: 0.4476905858054392
2025-08-26 13:29:21,369 - root - INFO - TRAINER_LOGS - loss: 1.3238 grad_norm: 1.5905342102050781 learning_rate: 9.465113629332928e-06 epoch: 0.44999826923742603
2025-08-26 13:30:03,663 - root - INFO - TRAINER_LOGS - loss: 1.3939 grad_norm: 1.5316884517669678 learning_rate: 9.459654750656025e-06 epoch: 0.4523059526694128
2025-08-26 13:30:46,984 - root - INFO - TRAINER_LOGS - loss: 1.3844 grad_norm: 1.7744826078414917 learning_rate: 9.45416974807966e-06 epoch: 0.4546136361013996
2025-08-26 13:31:29,715 - root - INFO - TRAINER_LOGS - loss: 1.3542 grad_norm: 1.655947208404541 learning_rate: 9.448658653734049e-06 epoch: 0.4569213195333864
2025-08-26 13:32:13,229 - root - INFO - TRAINER_LOGS - loss: 1.3656 grad_norm: 1.4580295085906982 learning_rate: 9.443121499902246e-06 epoch: 0.4592290029653732
2025-08-26 13:32:56,613 - root - INFO - TRAINER_LOGS - loss: 1.3697 grad_norm: 1.4543321132659912 learning_rate: 9.437558319019955e-06 epoch: 0.46153668639736
2025-08-26 13:35:54,612 - root - INFO - TRAINER_LOGS - eval_loss: 1.3464746475219727 eval_runtime: 177.9944 eval_samples_per_second: 28.091 eval_steps_per_second: 1.174 epoch: 0.46153668639736
2025-08-26 13:36:37,113 - root - INFO - TRAINER_LOGS - loss: 1.3692 grad_norm: 1.535687804222107 learning_rate: 9.431969143675344e-06 epoch: 0.4638443698293468
2025-08-26 13:37:19,941 - root - INFO - TRAINER_LOGS - loss: 1.3286 grad_norm: 1.4299414157867432 learning_rate: 9.426354006608854e-06 epoch: 0.46615205326133363
2025-08-26 13:38:02,186 - root - INFO - TRAINER_LOGS - loss: 1.3508 grad_norm: 1.2419962882995605 learning_rate: 9.420712940713005e-06 epoch: 0.4684597366933204
2025-08-26 13:38:45,193 - root - INFO - TRAINER_LOGS - loss: 1.3471 grad_norm: 1.462646484375 learning_rate: 9.415045979032195e-06 epoch: 0.4707674201253072
2025-08-26 13:39:28,076 - root - INFO - TRAINER_LOGS - loss: 1.3624 grad_norm: 1.3636424541473389 learning_rate: 9.40935315476253e-06 epoch: 0.473075103557294
2025-08-26 13:40:10,325 - root - INFO - TRAINER_LOGS - loss: 1.3293 grad_norm: 1.422682762145996 learning_rate: 9.403634501251602e-06 epoch: 0.4753827869892808
2025-08-26 13:40:53,688 - root - INFO - TRAINER_LOGS - loss: 1.3475 grad_norm: 1.711004376411438 learning_rate: 9.397890051998314e-06 epoch: 0.4776904704212676
2025-08-26 13:41:36,157 - root - INFO - TRAINER_LOGS - loss: 1.356 grad_norm: 2.9169723987579346 learning_rate: 9.392119840652671e-06 epoch: 0.4799981538532544
2025-08-26 13:42:19,065 - root - INFO - TRAINER_LOGS - loss: 1.3458 grad_norm: 1.256858229637146 learning_rate: 9.386323901015593e-06 epoch: 0.48230583728524123
2025-08-26 13:43:02,263 - root - INFO - TRAINER_LOGS - loss: 1.3842 grad_norm: 1.8683758974075317 learning_rate: 9.380502267038707e-06 epoch: 0.484613520717228
2025-08-26 13:43:45,806 - root - INFO - TRAINER_LOGS - loss: 1.3601 grad_norm: 1.2782706022262573 learning_rate: 9.374654972824156e-06 epoch: 0.4869212041492148
2025-08-26 13:44:29,090 - root - INFO - TRAINER_LOGS - loss: 1.3434 grad_norm: 1.3258230686187744 learning_rate: 9.368782052624395e-06 epoch: 0.4892288875812016
2025-08-26 13:45:11,338 - root - INFO - TRAINER_LOGS - loss: 1.3461 grad_norm: 1.5476065874099731 learning_rate: 9.362883540841992e-06 epoch: 0.49153657101318843
2025-08-26 13:45:54,415 - root - INFO - TRAINER_LOGS - loss: 1.3506 grad_norm: 1.7180019617080688 learning_rate: 9.356959472029428e-06 epoch: 0.4938442544451752
2025-08-26 13:46:37,977 - root - INFO - TRAINER_LOGS - loss: 1.3525 grad_norm: 1.3189632892608643 learning_rate: 9.35100988088889e-06 epoch: 0.496151937877162
2025-08-26 13:47:20,752 - root - INFO - TRAINER_LOGS - loss: 1.3871 grad_norm: 1.5152833461761475 learning_rate: 9.34503480227207e-06 epoch: 0.49845962130914884
2025-08-26 13:48:04,635 - root - INFO - TRAINER_LOGS - loss: 1.3548 grad_norm: 1.3487995862960815 learning_rate: 9.339034271179968e-06 epoch: 0.5007673047411356
2025-08-26 13:48:48,038 - root - INFO - TRAINER_LOGS - loss: 1.3669 grad_norm: 1.6817939281463623 learning_rate: 9.333008322762669e-06 epoch: 0.5030749881731225
2025-08-26 13:49:31,387 - root - INFO - TRAINER_LOGS - loss: 1.3592 grad_norm: 1.573663592338562 learning_rate: 9.326956992319157e-06 epoch: 0.5053826716051092
2025-08-26 13:50:13,737 - root - INFO - TRAINER_LOGS - loss: 1.3333 grad_norm: 1.494926929473877 learning_rate: 9.3208803152971e-06 epoch: 0.507690355037096
2025-08-26 13:53:11,788 - root - INFO - TRAINER_LOGS - eval_loss: 1.341208577156067 eval_runtime: 178.0467 eval_samples_per_second: 28.083 eval_steps_per_second: 1.174 epoch: 0.507690355037096
2025-08-26 13:53:55,234 - root - INFO - TRAINER_LOGS - loss: 1.3695 grad_norm: 1.8129562139511108 learning_rate: 9.314778327292632e-06 epoch: 0.5099980384690828
2025-08-26 13:54:38,360 - root - INFO - TRAINER_LOGS - loss: 1.3466 grad_norm: 1.274186372756958 learning_rate: 9.308651064050169e-06 epoch: 0.5123057219010696
2025-08-26 13:55:21,654 - root - INFO - TRAINER_LOGS - loss: 1.3534 grad_norm: 1.3488510847091675 learning_rate: 9.302498561462173e-06 epoch: 0.5146134053330564
2025-08-26 13:56:04,982 - root - INFO - TRAINER_LOGS - loss: 1.3471 grad_norm: 1.7703368663787842 learning_rate: 9.296320855568962e-06 epoch: 0.5169210887650432
2025-08-26 13:56:47,193 - root - INFO - TRAINER_LOGS - loss: 1.309 grad_norm: 1.9980889558792114 learning_rate: 9.290117982558482e-06 epoch: 0.51922877219703
2025-08-26 13:57:31,193 - root - INFO - TRAINER_LOGS - loss: 1.3585 grad_norm: 1.403945803642273 learning_rate: 9.283889978766113e-06 epoch: 0.5215364556290168
2025-08-26 13:58:14,238 - root - INFO - TRAINER_LOGS - loss: 1.3724 grad_norm: 1.4045027494430542 learning_rate: 9.27763688067444e-06 epoch: 0.5238441390610036
2025-08-26 13:58:58,661 - root - INFO - TRAINER_LOGS - loss: 1.3512 grad_norm: 1.4969336986541748 learning_rate: 9.27135872491305e-06 epoch: 0.5261518224929904
2025-08-26 13:59:41,931 - root - INFO - TRAINER_LOGS - loss: 1.3572 grad_norm: 1.667027473449707 learning_rate: 9.265055548258313e-06 epoch: 0.5284595059249773
2025-08-26 14:00:24,287 - root - INFO - TRAINER_LOGS - loss: 1.3773 grad_norm: 1.2891933917999268 learning_rate: 9.258727387633163e-06 epoch: 0.530767189356964
2025-08-26 14:01:07,180 - root - INFO - TRAINER_LOGS - loss: 1.3428 grad_norm: 1.5664368867874146 learning_rate: 9.252374280106894e-06 epoch: 0.5330748727889508
2025-08-26 14:01:49,755 - root - INFO - TRAINER_LOGS - loss: 1.3695 grad_norm: 1.5353076457977295 learning_rate: 9.245996262894927e-06 epoch: 0.5353825562209377
2025-08-26 14:02:32,598 - root - INFO - TRAINER_LOGS - loss: 1.3402 grad_norm: 1.2636135816574097 learning_rate: 9.239593373358602e-06 epoch: 0.5376902396529244
2025-08-26 14:03:16,248 - root - INFO - TRAINER_LOGS - loss: 1.3442 grad_norm: 1.2685757875442505 learning_rate: 9.23316564900496e-06 epoch: 0.5399979230849112
2025-08-26 14:03:58,231 - root - INFO - TRAINER_LOGS - loss: 1.3363 grad_norm: 1.5822128057479858 learning_rate: 9.226713127486517e-06 epoch: 0.542305606516898
2025-08-26 14:04:40,700 - root - INFO - TRAINER_LOGS - loss: 1.3503 grad_norm: 1.482696533203125 learning_rate: 9.220235846601044e-06 epoch: 0.5446132899488848
2025-08-26 14:05:22,938 - root - INFO - TRAINER_LOGS - loss: 1.3426 grad_norm: 1.5130283832550049 learning_rate: 9.213733844291357e-06 epoch: 0.5469209733808716
2025-08-26 14:06:04,752 - root - INFO - TRAINER_LOGS - loss: 1.3706 grad_norm: 1.6295862197875977 learning_rate: 9.207207158645075e-06 epoch: 0.5492286568128584
2025-08-26 14:06:47,765 - root - INFO - TRAINER_LOGS - loss: 1.3427 grad_norm: 1.4432355165481567 learning_rate: 9.200655827894417e-06 epoch: 0.5515363402448452
2025-08-26 14:07:31,280 - root - INFO - TRAINER_LOGS - loss: 1.3815 grad_norm: 1.4398125410079956 learning_rate: 9.194079890415964e-06 epoch: 0.553844023676832
2025-08-26 14:10:29,291 - root - INFO - TRAINER_LOGS - eval_loss: 1.340593695640564 eval_runtime: 178.0064 eval_samples_per_second: 28.089 eval_steps_per_second: 1.174 epoch: 0.553844023676832
2025-08-26 14:11:11,587 - root - INFO - TRAINER_LOGS - loss: 1.3524 grad_norm: 1.3201764822006226 learning_rate: 9.187479384730437e-06 epoch: 0.5561517071088188
2025-08-26 14:11:54,057 - root - INFO - TRAINER_LOGS - loss: 1.3361 grad_norm: 1.5014488697052002 learning_rate: 9.180854349502479e-06 epoch: 0.5584593905408056
2025-08-26 14:12:36,237 - root - INFO - TRAINER_LOGS - loss: 1.3546 grad_norm: 1.5211293697357178 learning_rate: 9.174204823540421e-06 epoch: 0.5607670739727925
2025-08-26 14:13:19,452 - root - INFO - TRAINER_LOGS - loss: 1.3712 grad_norm: 1.6825107336044312 learning_rate: 9.167530845796052e-06 epoch: 0.5630747574047792
2025-08-26 14:14:02,151 - root - INFO - TRAINER_LOGS - loss: 1.3443 grad_norm: 2.0130507946014404 learning_rate: 9.160832455364406e-06 epoch: 0.565382440836766
2025-08-26 14:14:44,788 - root - INFO - TRAINER_LOGS - loss: 1.3664 grad_norm: 1.5414998531341553 learning_rate: 9.154109691483507e-06 epoch: 0.5676901242687528
2025-08-26 14:15:27,341 - root - INFO - TRAINER_LOGS - loss: 1.3683 grad_norm: 1.3753067255020142 learning_rate: 9.14736259353417e-06 epoch: 0.5699978077007396
2025-08-26 14:16:10,558 - root - INFO - TRAINER_LOGS - loss: 1.3163 grad_norm: 1.6157268285751343 learning_rate: 9.140591201039745e-06 epoch: 0.5723054911327264
2025-08-26 14:16:53,684 - root - INFO - TRAINER_LOGS - loss: 1.3457 grad_norm: 1.525922417640686 learning_rate: 9.133795553665898e-06 epoch: 0.5746131745647132
2025-08-26 14:17:37,030 - root - INFO - TRAINER_LOGS - loss: 1.3841 grad_norm: 1.5506274700164795 learning_rate: 9.126975691220377e-06 epoch: 0.5769208579967
2025-08-26 14:18:21,808 - root - INFO - TRAINER_LOGS - loss: 1.3629 grad_norm: 1.2893446683883667 learning_rate: 9.120131653652777e-06 epoch: 0.5792285414286868
2025-08-26 14:19:05,158 - root - INFO - TRAINER_LOGS - loss: 1.3318 grad_norm: 1.4902284145355225 learning_rate: 9.113263481054304e-06 epoch: 0.5815362248606736
2025-08-26 14:19:48,022 - root - INFO - TRAINER_LOGS - loss: 1.3682 grad_norm: 1.3008276224136353 learning_rate: 9.10637121365755e-06 epoch: 0.5838439082926604
2025-08-26 14:20:30,592 - root - INFO - TRAINER_LOGS - loss: 1.3639 grad_norm: 1.6307209730148315 learning_rate: 9.09945489183624e-06 epoch: 0.5861515917246473
2025-08-26 14:21:13,638 - root - INFO - TRAINER_LOGS - loss: 1.3377 grad_norm: 1.5027633905410767 learning_rate: 9.09251455610502e-06 epoch: 0.588459275156634
2025-08-26 14:21:55,988 - root - INFO - TRAINER_LOGS - loss: 1.3832 grad_norm: 1.6512293815612793 learning_rate: 9.08555024711919e-06 epoch: 0.5907669585886208
2025-08-26 14:22:39,292 - root - INFO - TRAINER_LOGS - loss: 1.3599 grad_norm: 1.3286153078079224 learning_rate: 9.07856200567449e-06 epoch: 0.5930746420206077
2025-08-26 14:23:23,184 - root - INFO - TRAINER_LOGS - loss: 1.3287 grad_norm: 1.4552720785140991 learning_rate: 9.071549872706851e-06 epoch: 0.5953823254525944
2025-08-26 14:24:05,395 - root - INFO - TRAINER_LOGS - loss: 1.3165 grad_norm: 1.525847315788269 learning_rate: 9.064513889292156e-06 epoch: 0.5976900088845812
2025-08-26 14:24:47,713 - root - INFO - TRAINER_LOGS - loss: 1.3423 grad_norm: 1.602961778640747 learning_rate: 9.057454096646002e-06 epoch: 0.599997692316568
2025-08-26 14:27:45,768 - root - INFO - TRAINER_LOGS - eval_loss: 1.338531255722046 eval_runtime: 178.0498 eval_samples_per_second: 28.082 eval_steps_per_second: 1.174 epoch: 0.599997692316568
2025-08-26 14:28:28,199 - root - INFO - TRAINER_LOGS - loss: 1.3653 grad_norm: 1.1471598148345947 learning_rate: 9.05037053612345e-06 epoch: 0.6023053757485548
2025-08-26 14:29:11,242 - root - INFO - TRAINER_LOGS - loss: 1.3471 grad_norm: 1.3355554342269897 learning_rate: 9.043263249218795e-06 epoch: 0.6046130591805416
2025-08-26 14:29:55,098 - root - INFO - TRAINER_LOGS - loss: 1.3624 grad_norm: 1.7779704332351685 learning_rate: 9.036132277565316e-06 epoch: 0.6069207426125284
2025-08-26 14:30:38,765 - root - INFO - TRAINER_LOGS - loss: 1.3465 grad_norm: 1.419787883758545 learning_rate: 9.028977662935032e-06 epoch: 0.6092284260445152
2025-08-26 14:31:21,603 - root - INFO - TRAINER_LOGS - loss: 1.3472 grad_norm: 1.3596655130386353 learning_rate: 9.021799447238463e-06 epoch: 0.611536109476502
2025-08-26 14:32:04,604 - root - INFO - TRAINER_LOGS - loss: 1.3297 grad_norm: 1.2903145551681519 learning_rate: 9.014597672524372e-06 epoch: 0.6138437929084888
2025-08-26 14:32:47,508 - root - INFO - TRAINER_LOGS - loss: 1.3592 grad_norm: 1.412043809890747 learning_rate: 9.00737238097953e-06 epoch: 0.6161514763404756
2025-08-26 14:33:30,440 - root - INFO - TRAINER_LOGS - loss: 1.3556 grad_norm: 1.5850248336791992 learning_rate: 9.000123614928473e-06 epoch: 0.6184591597724625
2025-08-26 14:34:13,124 - root - INFO - TRAINER_LOGS - loss: 1.3611 grad_norm: 1.6944992542266846 learning_rate: 8.992851416833235e-06 epoch: 0.6207668432044492
2025-08-26 14:34:56,663 - root - INFO - TRAINER_LOGS - loss: 1.3927 grad_norm: 1.4669299125671387 learning_rate: 8.985555829293117e-06 epoch: 0.623074526636436
2025-08-26 14:35:39,240 - root - INFO - TRAINER_LOGS - loss: 1.3539 grad_norm: 1.3399789333343506 learning_rate: 8.978236895044435e-06 epoch: 0.6253822100684228
2025-08-26 14:36:22,037 - root - INFO - TRAINER_LOGS - loss: 1.3035 grad_norm: 1.6167569160461426 learning_rate: 8.970894656960256e-06 epoch: 0.6276898935004096
2025-08-26 14:37:04,930 - root - INFO - TRAINER_LOGS - loss: 1.3276 grad_norm: 1.4771947860717773 learning_rate: 8.963529158050164e-06 epoch: 0.6299975769323964
2025-08-26 14:37:48,520 - root - INFO - TRAINER_LOGS - loss: 1.3488 grad_norm: 1.8537935018539429 learning_rate: 8.956140441460001e-06 epoch: 0.6323052603643832
2025-08-26 14:38:32,928 - root - INFO - TRAINER_LOGS - loss: 1.3653 grad_norm: 1.3998725414276123 learning_rate: 8.948728550471613e-06 epoch: 0.63461294379637
2025-08-26 14:39:16,764 - root - INFO - TRAINER_LOGS - loss: 1.3522 grad_norm: 1.3860598802566528 learning_rate: 8.941293528502597e-06 epoch: 0.6369206272283569
2025-08-26 14:39:59,756 - root - INFO - TRAINER_LOGS - loss: 1.3276 grad_norm: 1.6995534896850586 learning_rate: 8.933835419106047e-06 epoch: 0.6392283106603436
2025-08-26 14:40:42,447 - root - INFO - TRAINER_LOGS - loss: 1.39 grad_norm: 1.5709260702133179 learning_rate: 8.926504114578434e-06 epoch: 0.6415359940923304
2025-08-26 14:41:25,747 - root - INFO - TRAINER_LOGS - loss: 1.3504 grad_norm: 1.5842280387878418 learning_rate: 8.919000421094792e-06 epoch: 0.6438436775243173
2025-08-26 14:42:08,664 - root - INFO - TRAINER_LOGS - loss: 1.3112 grad_norm: 1.4734750986099243 learning_rate: 8.911473770772852e-06 epoch: 0.646151360956304
2025-08-26 14:45:06,814 - root - INFO - TRAINER_LOGS - eval_loss: 1.3382893800735474 eval_runtime: 178.1453 eval_samples_per_second: 28.067 eval_steps_per_second: 1.173 epoch: 0.646151360956304
2025-08-26 14:45:50,531 - root - INFO - TRAINER_LOGS - loss: 1.3713 grad_norm: 1.6101367473602295 learning_rate: 8.903924207702448e-06 epoch: 0.6484590443882908
2025-08-26 14:46:32,532 - root - INFO - TRAINER_LOGS - loss: 1.331 grad_norm: 1.4159103631973267 learning_rate: 8.89635177610764e-06 epoch: 0.6507667278202777
2025-08-26 14:47:15,496 - root - INFO - TRAINER_LOGS - loss: 1.3973 grad_norm: 1.466037631034851 learning_rate: 8.88875652034645e-06 epoch: 0.6530744112522644
2025-08-26 14:47:58,772 - root - INFO - TRAINER_LOGS - loss: 1.3564 grad_norm: 1.5703160762786865 learning_rate: 8.881138484910585e-06 epoch: 0.6553820946842512
2025-08-26 14:48:41,240 - root - INFO - TRAINER_LOGS - loss: 1.3467 grad_norm: 1.448097586631775 learning_rate: 8.873497714425207e-06 epoch: 0.657689778116238
2025-08-26 14:49:24,547 - root - INFO - TRAINER_LOGS - loss: 1.303 grad_norm: 1.468119740486145 learning_rate: 8.865834253648651e-06 epoch: 0.6599974615482248
2025-08-26 14:50:07,586 - root - INFO - TRAINER_LOGS - loss: 1.3244 grad_norm: 1.4920796155929565 learning_rate: 8.858148147472169e-06 epoch: 0.6623051449802116
2025-08-26 14:50:50,935 - root - INFO - TRAINER_LOGS - loss: 1.354 grad_norm: 1.4383323192596436 learning_rate: 8.850439440919661e-06 epoch: 0.6646128284121984
2025-08-26 14:51:33,215 - root - INFO - TRAINER_LOGS - loss: 1.3121 grad_norm: 1.750296711921692 learning_rate: 8.84270817914742e-06 epoch: 0.6669205118441852
2025-08-26 14:52:15,908 - root - INFO - TRAINER_LOGS - loss: 1.3678 grad_norm: 1.56887948513031 learning_rate: 8.834954407443866e-06 epoch: 0.669228195276172
2025-08-26 14:52:58,910 - root - INFO - TRAINER_LOGS - loss: 1.341 grad_norm: 1.5623135566711426 learning_rate: 8.827178171229271e-06 epoch: 0.6715358787081588
2025-08-26 14:53:42,119 - root - INFO - TRAINER_LOGS - loss: 1.3243 grad_norm: 1.3034453392028809 learning_rate: 8.81937951605551e-06 epoch: 0.6738435621401456
2025-08-26 14:54:24,220 - root - INFO - TRAINER_LOGS - loss: 1.3372 grad_norm: 1.7497217655181885 learning_rate: 8.811558487605779e-06 epoch: 0.6761512455721325
2025-08-26 14:55:06,036 - root - INFO - TRAINER_LOGS - loss: 1.346 grad_norm: 1.539458990097046 learning_rate: 8.803715131694327e-06 epoch: 0.6784589290041192
2025-08-26 14:55:48,490 - root - INFO - TRAINER_LOGS - loss: 1.3264 grad_norm: 1.3741787672042847 learning_rate: 8.795849494266209e-06 epoch: 0.680766612436106
2025-08-26 14:56:31,171 - root - INFO - TRAINER_LOGS - loss: 1.3236 grad_norm: 1.3552931547164917 learning_rate: 8.787961621396985e-06 epoch: 0.6830742958680928
2025-08-26 14:57:13,946 - root - INFO - TRAINER_LOGS - loss: 1.3505 grad_norm: 1.6060442924499512 learning_rate: 8.780051559292476e-06 epoch: 0.6853819793000796
2025-08-26 14:57:57,266 - root - INFO - TRAINER_LOGS - loss: 1.3459 grad_norm: 1.7316741943359375 learning_rate: 8.772119354288478e-06 epoch: 0.6876896627320664
2025-08-26 14:58:39,814 - root - INFO - TRAINER_LOGS - loss: 1.3565 grad_norm: 1.6779654026031494 learning_rate: 8.764165052850505e-06 epoch: 0.6899973461640532
2025-08-26 14:59:22,738 - root - INFO - TRAINER_LOGS - loss: 1.3297 grad_norm: 1.6175156831741333 learning_rate: 8.7561887015735e-06 epoch: 0.69230502959604
2025-08-26 15:02:21,109 - root - INFO - TRAINER_LOGS - eval_loss: 1.33516263961792 eval_runtime: 178.3673 eval_samples_per_second: 28.032 eval_steps_per_second: 1.172 epoch: 0.69230502959604
2025-08-26 15:03:04,386 - root - INFO - TRAINER_LOGS - loss: 1.3295 grad_norm: 1.3470591306686401 learning_rate: 8.748190347181573e-06 epoch: 0.6946127130280269
2025-08-26 15:03:47,373 - root - INFO - TRAINER_LOGS - loss: 1.3462 grad_norm: 1.5127140283584595 learning_rate: 8.740170036527724e-06 epoch: 0.6969203964600136
2025-08-26 15:04:30,096 - root - INFO - TRAINER_LOGS - loss: 1.3285 grad_norm: 1.6227591037750244 learning_rate: 8.73212781659357e-06 epoch: 0.6992280798920004
2025-08-26 15:05:13,281 - root - INFO - TRAINER_LOGS - loss: 1.3659 grad_norm: 1.3522510528564453 learning_rate: 8.72406373448907e-06 epoch: 0.7015357633239873
2025-08-26 15:05:56,230 - root - INFO - TRAINER_LOGS - loss: 1.3435 grad_norm: 1.5781714916229248 learning_rate: 8.71597783745224e-06 epoch: 0.703843446755974
2025-08-26 15:06:38,715 - root - INFO - TRAINER_LOGS - loss: 1.3477 grad_norm: 1.8387417793273926 learning_rate: 8.707870172848899e-06 epoch: 0.7061511301879608
2025-08-26 15:07:21,791 - root - INFO - TRAINER_LOGS - loss: 1.3425 grad_norm: 1.3478269577026367 learning_rate: 8.699740788172362e-06 epoch: 0.7084588136199477
2025-08-26 15:08:04,661 - root - INFO - TRAINER_LOGS - loss: 1.3533 grad_norm: 1.5211037397384644 learning_rate: 8.691589731043186e-06 epoch: 0.7107664970519344
2025-08-26 15:08:47,767 - root - INFO - TRAINER_LOGS - loss: 1.3283 grad_norm: 1.657016396522522 learning_rate: 8.683417049208876e-06 epoch: 0.7130741804839212
2025-08-26 15:09:30,571 - root - INFO - TRAINER_LOGS - loss: 1.347 grad_norm: 1.3118754625320435 learning_rate: 8.675222790543613e-06 epoch: 0.715381863915908
2025-08-26 15:10:13,303 - root - INFO - TRAINER_LOGS - loss: 1.3418 grad_norm: 1.5550662279129028 learning_rate: 8.667007003047971e-06 epoch: 0.7176895473478948
2025-08-26 15:10:56,041 - root - INFO - TRAINER_LOGS - loss: 1.3485 grad_norm: 1.380224347114563 learning_rate: 8.65876973484864e-06 epoch: 0.7199972307798816
2025-08-26 15:11:39,039 - root - INFO - TRAINER_LOGS - loss: 1.3571 grad_norm: 1.6031453609466553 learning_rate: 8.650511034198132e-06 epoch: 0.7223049142118684
2025-08-26 15:12:22,175 - root - INFO - TRAINER_LOGS - loss: 1.3765 grad_norm: 1.7599836587905884 learning_rate: 8.642230949474517e-06 epoch: 0.7246125976438552
2025-08-26 15:13:05,070 - root - INFO - TRAINER_LOGS - loss: 1.3542 grad_norm: 1.7591116428375244 learning_rate: 8.633929529181118e-06 epoch: 0.7269202810758421
2025-08-26 15:13:47,118 - root - INFO - TRAINER_LOGS - loss: 1.3669 grad_norm: 1.4726672172546387 learning_rate: 8.625606821946248e-06 epoch: 0.7292279645078288
2025-08-26 15:14:29,848 - root - INFO - TRAINER_LOGS - loss: 1.3514 grad_norm: 1.2454782724380493 learning_rate: 8.61726287652291e-06 epoch: 0.7315356479398156
2025-08-26 15:15:12,295 - root - INFO - TRAINER_LOGS - loss: 1.3363 grad_norm: 1.4706190824508667 learning_rate: 8.608897741788517e-06 epoch: 0.7338433313718025
2025-08-26 15:15:55,688 - root - INFO - TRAINER_LOGS - loss: 1.3957 grad_norm: 1.6180036067962646 learning_rate: 8.600511466744609e-06 epoch: 0.7361510148037892
2025-08-26 15:16:37,901 - root - INFO - TRAINER_LOGS - loss: 1.3449 grad_norm: 1.484878420829773 learning_rate: 8.592272454216384e-06 epoch: 0.738458698235776
2025-08-26 15:19:36,325 - root - INFO - TRAINER_LOGS - eval_loss: 1.3344852924346924 eval_runtime: 178.4196 eval_samples_per_second: 28.024 eval_steps_per_second: 1.171 epoch: 0.738458698235776
2025-08-26 15:20:19,739 - root - INFO - TRAINER_LOGS - loss: 1.3708 grad_norm: 1.4906708002090454 learning_rate: 8.583844466408378e-06 epoch: 0.7407663816677628
2025-08-26 15:21:03,067 - root - INFO - TRAINER_LOGS - loss: 1.3407 grad_norm: 1.4625091552734375 learning_rate: 8.575395485048685e-06 epoch: 0.7430740650997496
2025-08-26 15:21:47,257 - root - INFO - TRAINER_LOGS - loss: 1.3699 grad_norm: 1.8032640218734741 learning_rate: 8.56692555963e-06 epoch: 0.7453817485317364
2025-08-26 15:22:30,058 - root - INFO - TRAINER_LOGS - loss: 1.3192 grad_norm: 1.3891280889511108 learning_rate: 8.558434739767707e-06 epoch: 0.7476894319637232
2025-08-26 15:23:12,906 - root - INFO - TRAINER_LOGS - loss: 1.3317 grad_norm: 1.402127981185913 learning_rate: 8.549923075199587e-06 epoch: 0.74999711539571
2025-08-26 15:23:55,747 - root - INFO - TRAINER_LOGS - loss: 1.3629 grad_norm: 1.563159704208374 learning_rate: 8.54156146844021e-06 epoch: 0.7523047988276969
2025-08-26 15:24:37,692 - root - INFO - TRAINER_LOGS - loss: 1.2992 grad_norm: 1.3163034915924072 learning_rate: 8.533008678568575e-06 epoch: 0.7546124822596836
2025-08-26 15:25:20,165 - root - INFO - TRAINER_LOGS - loss: 1.3226 grad_norm: 1.4140312671661377 learning_rate: 8.524435192932653e-06 epoch: 0.7569201656916704
2025-08-26 15:26:03,265 - root - INFO - TRAINER_LOGS - loss: 1.3509 grad_norm: 1.5803618431091309 learning_rate: 8.515841061754471e-06 epoch: 0.7592278491236573
2025-08-26 15:26:47,036 - root - INFO - TRAINER_LOGS - loss: 1.3469 grad_norm: 1.6125673055648804 learning_rate: 8.507226335376983e-06 epoch: 0.761535532555644
2025-08-26 15:27:30,248 - root - INFO - TRAINER_LOGS - loss: 1.3635 grad_norm: 1.7636903524398804 learning_rate: 8.498591064263797e-06 epoch: 0.7638432159876308
2025-08-26 15:28:13,288 - root - INFO - TRAINER_LOGS - loss: 1.3474 grad_norm: 1.4397954940795898 learning_rate: 8.489935298998862e-06 epoch: 0.7661508994196177
2025-08-26 15:28:56,061 - root - INFO - TRAINER_LOGS - loss: 1.335 grad_norm: 1.3513367176055908 learning_rate: 8.481259090286176e-06 epoch: 0.7684585828516044
2025-08-26 15:29:39,089 - root - INFO - TRAINER_LOGS - loss: 1.3265 grad_norm: 1.3669722080230713 learning_rate: 8.472562488949498e-06 epoch: 0.7707662662835912
2025-08-26 15:30:22,366 - root - INFO - TRAINER_LOGS - loss: 1.3434 grad_norm: 1.6688573360443115 learning_rate: 8.463845545932038e-06 epoch: 0.773073949715578
2025-08-26 15:31:04,528 - root - INFO - TRAINER_LOGS - loss: 1.366 grad_norm: 1.4472894668579102 learning_rate: 8.455108312296172e-06 epoch: 0.7753816331475648
2025-08-26 15:31:47,335 - root - INFO - TRAINER_LOGS - loss: 1.3463 grad_norm: 1.6176066398620605 learning_rate: 8.446350839223123e-06 epoch: 0.7776893165795516
2025-08-26 15:32:30,218 - root - INFO - TRAINER_LOGS - loss: 1.3531 grad_norm: 1.628206491470337 learning_rate: 8.437573178012683e-06 epoch: 0.7799970000115384
2025-08-26 15:33:12,878 - root - INFO - TRAINER_LOGS - loss: 1.3503 grad_norm: 1.803006649017334 learning_rate: 8.428775380082899e-06 epoch: 0.7823046834435252
2025-08-26 15:33:56,337 - root - INFO - TRAINER_LOGS - loss: 1.3411 grad_norm: 1.8269245624542236 learning_rate: 8.419957496969773e-06 epoch: 0.7846123668755121
2025-08-26 15:36:54,504 - root - INFO - TRAINER_LOGS - eval_loss: 1.331333041191101 eval_runtime: 178.162 eval_samples_per_second: 28.064 eval_steps_per_second: 1.173 epoch: 0.7846123668755121
2025-08-26 15:37:38,441 - root - INFO - TRAINER_LOGS - loss: 1.3541 grad_norm: 1.6790103912353516 learning_rate: 8.41111958032697e-06 epoch: 0.7869200503074988
2025-08-26 15:38:20,852 - root - INFO - TRAINER_LOGS - loss: 1.3207 grad_norm: 1.375511646270752 learning_rate: 8.4022616819255e-06 epoch: 0.7892277337394856
2025-08-26 15:39:04,923 - root - INFO - TRAINER_LOGS - loss: 1.3502 grad_norm: 1.3344649076461792 learning_rate: 8.393383853653428e-06 epoch: 0.7915354171714725
2025-08-26 15:39:48,755 - root - INFO - TRAINER_LOGS - loss: 1.3465 grad_norm: 1.4117732048034668 learning_rate: 8.38448614751556e-06 epoch: 0.7938431006034592
2025-08-26 15:40:31,924 - root - INFO - TRAINER_LOGS - loss: 1.3591 grad_norm: 1.4475502967834473 learning_rate: 8.37556861563315e-06 epoch: 0.796150784035446
2025-08-26 15:41:15,222 - root - INFO - TRAINER_LOGS - loss: 1.3257 grad_norm: 1.5313818454742432 learning_rate: 8.366631310243583e-06 epoch: 0.7984584674674328
2025-08-26 15:41:58,195 - root - INFO - TRAINER_LOGS - loss: 1.3714 grad_norm: 1.5936108827590942 learning_rate: 8.357674283700072e-06 epoch: 0.8007661508994196
2025-08-26 15:42:41,221 - root - INFO - TRAINER_LOGS - loss: 1.3441 grad_norm: 1.8506720066070557 learning_rate: 8.34869758847136e-06 epoch: 0.8030738343314064
2025-08-26 15:43:24,081 - root - INFO - TRAINER_LOGS - loss: 1.3474 grad_norm: 1.5051336288452148 learning_rate: 8.339701277141398e-06 epoch: 0.8053815177633932
2025-08-26 15:44:07,483 - root - INFO - TRAINER_LOGS - loss: 1.338 grad_norm: 1.5725475549697876 learning_rate: 8.330685402409052e-06 epoch: 0.80768920119538
2025-08-26 15:44:50,562 - root - INFO - TRAINER_LOGS - loss: 1.3445 grad_norm: 1.507179856300354 learning_rate: 8.321650017087779e-06 epoch: 0.8099968846273669
2025-08-26 15:45:34,760 - root - INFO - TRAINER_LOGS - loss: 1.3271 grad_norm: 1.5497490167617798 learning_rate: 8.312595174105334e-06 epoch: 0.8123045680593536
2025-08-26 15:46:17,868 - root - INFO - TRAINER_LOGS - loss: 1.3766 grad_norm: 1.4190579652786255 learning_rate: 8.303520926503448e-06 epoch: 0.8146122514913404
2025-08-26 15:47:01,015 - root - INFO - TRAINER_LOGS - loss: 1.3322 grad_norm: 1.4886947870254517 learning_rate: 8.29442732743752e-06 epoch: 0.8169199349233273
2025-08-26 15:47:43,740 - root - INFO - TRAINER_LOGS - loss: 1.3391 grad_norm: 1.925368070602417 learning_rate: 8.285314430176306e-06 epoch: 0.819227618355314
2025-08-26 15:48:26,893 - root - INFO - TRAINER_LOGS - loss: 1.336 grad_norm: 1.58493971824646 learning_rate: 8.276182288101612e-06 epoch: 0.8215353017873008
2025-08-26 15:49:09,741 - root - INFO - TRAINER_LOGS - loss: 1.343 grad_norm: 1.72731351852417 learning_rate: 8.267030954707973e-06 epoch: 0.8238429852192877
2025-08-26 15:49:53,996 - root - INFO - TRAINER_LOGS - loss: 1.3483 grad_norm: 1.4787688255310059 learning_rate: 8.257860483602345e-06 epoch: 0.8261506686512744
2025-08-26 15:50:36,881 - root - INFO - TRAINER_LOGS - loss: 1.3031 grad_norm: 1.3548074960708618 learning_rate: 8.248670928503789e-06 epoch: 0.8284583520832612
2025-08-26 15:51:19,361 - root - INFO - TRAINER_LOGS - loss: 1.339 grad_norm: 1.6566789150238037 learning_rate: 8.239462343243152e-06 epoch: 0.830766035515248
2025-08-26 15:54:17,602 - root - INFO - TRAINER_LOGS - eval_loss: 1.3311997652053833 eval_runtime: 178.2369 eval_samples_per_second: 28.053 eval_steps_per_second: 1.173 epoch: 0.830766035515248
2025-08-26 15:55:01,347 - root - INFO - TRAINER_LOGS - loss: 1.3236 grad_norm: 1.6684271097183228 learning_rate: 8.230234781762768e-06 epoch: 0.8330737189472348
2025-08-26 15:55:43,927 - root - INFO - TRAINER_LOGS - loss: 1.3277 grad_norm: 1.5920462608337402 learning_rate: 8.22098829811612e-06 epoch: 0.8353814023792216
2025-08-26 15:56:27,149 - root - INFO - TRAINER_LOGS - loss: 1.3465 grad_norm: 1.5497463941574097 learning_rate: 8.211722946467536e-06 epoch: 0.8376890858112084
2025-08-26 15:57:09,533 - root - INFO - TRAINER_LOGS - loss: 1.3849 grad_norm: 1.2911112308502197 learning_rate: 8.202438781091875e-06 epoch: 0.8399967692431952
2025-08-26 15:57:53,010 - root - INFO - TRAINER_LOGS - loss: 1.3318 grad_norm: 1.4156789779663086 learning_rate: 8.193135856374196e-06 epoch: 0.8423044526751821
2025-08-26 15:58:36,143 - root - INFO - TRAINER_LOGS - loss: 1.3552 grad_norm: 1.224666953086853 learning_rate: 8.183814226809454e-06 epoch: 0.8446121361071688
2025-08-26 15:59:19,197 - root - INFO - TRAINER_LOGS - loss: 1.2931 grad_norm: 1.1783015727996826 learning_rate: 8.174473947002168e-06 epoch: 0.8469198195391556
2025-08-26 16:00:01,759 - root - INFO - TRAINER_LOGS - loss: 1.3156 grad_norm: 1.466350793838501 learning_rate: 8.16511507166611e-06 epoch: 0.8492275029711425
2025-08-26 16:00:44,859 - root - INFO - TRAINER_LOGS - loss: 1.3487 grad_norm: 1.3802824020385742 learning_rate: 8.15573765562398e-06 epoch: 0.8515351864031292
2025-08-26 16:01:28,356 - root - INFO - TRAINER_LOGS - loss: 1.3377 grad_norm: 1.4043760299682617 learning_rate: 8.14634175380709e-06 epoch: 0.853842869835116
2025-08-26 16:02:12,443 - root - INFO - TRAINER_LOGS - loss: 1.3512 grad_norm: 1.5139362812042236 learning_rate: 8.136927421255033e-06 epoch: 0.8561505532671028
2025-08-26 16:02:55,378 - root - INFO - TRAINER_LOGS - loss: 1.3597 grad_norm: 1.8767757415771484 learning_rate: 8.127494713115371e-06 epoch: 0.8584582366990896
2025-08-26 16:03:37,905 - root - INFO - TRAINER_LOGS - loss: 1.3163 grad_norm: 1.9257469177246094 learning_rate: 8.118043684643303e-06 epoch: 0.8607659201310764
2025-08-26 16:04:21,540 - root - INFO - TRAINER_LOGS - loss: 1.3649 grad_norm: 1.4926862716674805 learning_rate: 8.108574391201346e-06 epoch: 0.8630736035630632
2025-08-26 16:05:04,186 - root - INFO - TRAINER_LOGS - loss: 1.342 grad_norm: 1.5768615007400513 learning_rate: 8.099086888259015e-06 epoch: 0.86538128699505
2025-08-26 16:05:46,650 - root - INFO - TRAINER_LOGS - loss: 1.3548 grad_norm: 1.289449691772461 learning_rate: 8.089581231392487e-06 epoch: 0.8676889704270369
2025-08-26 16:06:29,182 - root - INFO - TRAINER_LOGS - loss: 1.3406 grad_norm: 1.2331749200820923 learning_rate: 8.080057476284285e-06 epoch: 0.8699966538590236
2025-08-26 16:07:12,410 - root - INFO - TRAINER_LOGS - loss: 1.3558 grad_norm: 1.3210111856460571 learning_rate: 8.070515678722946e-06 epoch: 0.8723043372910104
2025-08-26 16:07:54,769 - root - INFO - TRAINER_LOGS - loss: 1.3377 grad_norm: 1.650985598564148 learning_rate: 8.0609558946027e-06 epoch: 0.8746120207229973
2025-08-26 16:08:36,784 - root - INFO - TRAINER_LOGS - loss: 1.3607 grad_norm: 1.5832804441452026 learning_rate: 8.051378179923139e-06 epoch: 0.876919704154984
2025-08-26 16:11:34,928 - root - INFO - TRAINER_LOGS - eval_loss: 1.3270646333694458 eval_runtime: 178.1397 eval_samples_per_second: 28.068 eval_steps_per_second: 1.173 epoch: 0.876919704154984
2025-08-26 16:12:18,784 - root - INFO - TRAINER_LOGS - loss: 1.3479 grad_norm: 1.4276368618011475 learning_rate: 8.041782590788883e-06 epoch: 0.8792273875869708
2025-08-26 16:13:01,372 - root - INFO - TRAINER_LOGS - loss: 1.3461 grad_norm: 1.5199190378189087 learning_rate: 8.032169183409265e-06 epoch: 0.8815350710189577
2025-08-26 16:13:45,099 - root - INFO - TRAINER_LOGS - loss: 1.3545 grad_norm: 1.4788326025009155 learning_rate: 8.022538014097991e-06 epoch: 0.8838427544509444
2025-08-26 16:14:28,544 - root - INFO - TRAINER_LOGS - loss: 1.3628 grad_norm: 1.4923261404037476 learning_rate: 8.012889139272812e-06 epoch: 0.8861504378829312
2025-08-26 16:15:11,169 - root - INFO - TRAINER_LOGS - loss: 1.3811 grad_norm: 1.6061010360717773 learning_rate: 8.0032226154552e-06 epoch: 0.888458121314918
2025-08-26 16:15:53,531 - root - INFO - TRAINER_LOGS - loss: 1.3047 grad_norm: 1.652191162109375 learning_rate: 7.993538499270006e-06 epoch: 0.8907658047469048
2025-08-26 16:16:36,421 - root - INFO - TRAINER_LOGS - loss: 1.2999 grad_norm: 1.519932508468628 learning_rate: 7.983836847445137e-06 epoch: 0.8930734881788917
2025-08-26 16:17:18,906 - root - INFO - TRAINER_LOGS - loss: 1.3157 grad_norm: 1.380921721458435 learning_rate: 7.974117716811219e-06 epoch: 0.8953811716108784
2025-08-26 16:18:02,613 - root - INFO - TRAINER_LOGS - loss: 1.3309 grad_norm: 1.2659926414489746 learning_rate: 7.964381164301269e-06 epoch: 0.8976888550428652
2025-08-26 16:18:45,355 - root - INFO - TRAINER_LOGS - loss: 1.3473 grad_norm: 1.4286543130874634 learning_rate: 7.954627246950354e-06 epoch: 0.8999965384748521
2025-08-26 16:19:28,141 - root - INFO - TRAINER_LOGS - loss: 1.3496 grad_norm: 1.533440113067627 learning_rate: 7.944856021895267e-06 epoch: 0.9023042219068388
2025-08-26 16:20:10,624 - root - INFO - TRAINER_LOGS - loss: 1.3636 grad_norm: 1.2446553707122803 learning_rate: 7.935067546374182e-06 epoch: 0.9046119053388256
2025-08-26 16:20:53,079 - root - INFO - TRAINER_LOGS - loss: 1.3744 grad_norm: 1.5450561046600342 learning_rate: 7.925261877726325e-06 epoch: 0.9069195887708125
2025-08-26 16:21:36,240 - root - INFO - TRAINER_LOGS - loss: 1.3619 grad_norm: 1.528748869895935 learning_rate: 7.915635697036055e-06 epoch: 0.9092272722027992
2025-08-26 16:22:19,603 - root - INFO - TRAINER_LOGS - loss: 1.32 grad_norm: 1.5182384252548218 learning_rate: 7.90579615555324e-06 epoch: 0.911534955634786
2025-08-26 16:23:03,275 - root - INFO - TRAINER_LOGS - loss: 1.3179 grad_norm: 1.5863394737243652 learning_rate: 7.895939592410485e-06 epoch: 0.9138426390667728
2025-08-26 16:23:46,213 - root - INFO - TRAINER_LOGS - loss: 1.3449 grad_norm: 1.4974424839019775 learning_rate: 7.886066065345857e-06 epoch: 0.9161503224987596
2025-08-26 16:24:28,656 - root - INFO - TRAINER_LOGS - loss: 1.3654 grad_norm: 1.7135976552963257 learning_rate: 7.876175632196807e-06 epoch: 0.9184580059307464
2025-08-26 16:25:11,773 - root - INFO - TRAINER_LOGS - loss: 1.327 grad_norm: 1.9739112854003906 learning_rate: 7.866268350899806e-06 epoch: 0.9207656893627332
2025-08-26 16:25:54,684 - root - INFO - TRAINER_LOGS - loss: 1.3789 grad_norm: 1.597627878189087 learning_rate: 7.856344279490025e-06 epoch: 0.92307337279472
2025-08-26 16:28:52,898 - root - INFO - TRAINER_LOGS - eval_loss: 1.3264912366867065 eval_runtime: 178.2088 eval_samples_per_second: 28.057 eval_steps_per_second: 1.173 epoch: 0.92307337279472
2025-08-26 16:29:37,071 - root - INFO - TRAINER_LOGS - loss: 1.3678 grad_norm: 1.3870409727096558 learning_rate: 7.846403476100987e-06 epoch: 0.9253810562267069
2025-08-26 16:30:19,781 - root - INFO - TRAINER_LOGS - loss: 1.3484 grad_norm: 1.799749493598938 learning_rate: 7.83644599896423e-06 epoch: 0.9276887396586936
2025-08-26 16:31:02,522 - root - INFO - TRAINER_LOGS - loss: 1.363 grad_norm: 1.4055681228637695 learning_rate: 7.826471906408962e-06 epoch: 0.9299964230906804
2025-08-26 16:31:45,182 - root - INFO - TRAINER_LOGS - loss: 1.3446 grad_norm: 1.7922816276550293 learning_rate: 7.81648125686172e-06 epoch: 0.9323041065226673
2025-08-26 16:32:27,818 - root - INFO - TRAINER_LOGS - loss: 1.3647 grad_norm: 1.8308813571929932 learning_rate: 7.806474108846032e-06 epoch: 0.934611789954654
2025-08-26 16:33:11,383 - root - INFO - TRAINER_LOGS - loss: 1.3618 grad_norm: 1.5982370376586914 learning_rate: 7.79645052098207e-06 epoch: 0.9369194733866408
2025-08-26 16:33:53,599 - root - INFO - TRAINER_LOGS - loss: 1.3435 grad_norm: 1.483974814414978 learning_rate: 7.786410551986308e-06 epoch: 0.9392271568186277
2025-08-26 16:34:36,660 - root - INFO - TRAINER_LOGS - loss: 1.3479 grad_norm: 1.8436840772628784 learning_rate: 7.776354260671179e-06 epoch: 0.9415348402506144
2025-08-26 16:35:19,052 - root - INFO - TRAINER_LOGS - loss: 1.3087 grad_norm: 1.7362895011901855 learning_rate: 7.766281705944724e-06 epoch: 0.9438425236826012
2025-08-26 16:36:02,166 - root - INFO - TRAINER_LOGS - loss: 1.3522 grad_norm: 1.5720298290252686 learning_rate: 7.75619294681026e-06 epoch: 0.946150207114588
2025-08-26 16:36:45,648 - root - INFO - TRAINER_LOGS - loss: 1.3691 grad_norm: 1.6359012126922607 learning_rate: 7.746088042366022e-06 epoch: 0.9484578905465748
2025-08-26 16:37:28,349 - root - INFO - TRAINER_LOGS - loss: 1.3358 grad_norm: 1.911936640739441 learning_rate: 7.73616962887668e-06 epoch: 0.9507655739785617
2025-08-26 16:38:11,087 - root - INFO - TRAINER_LOGS - loss: 1.3499 grad_norm: 1.6155567169189453 learning_rate: 7.72603293144054e-06 epoch: 0.9530732574105484
2025-08-26 16:38:54,699 - root - INFO - TRAINER_LOGS - loss: 1.328 grad_norm: 1.7216105461120605 learning_rate: 7.715880265366871e-06 epoch: 0.9553809408425352
2025-08-26 16:39:37,936 - root - INFO - TRAINER_LOGS - loss: 1.339 grad_norm: 2.00793719291687 learning_rate: 7.70571169012826e-06 epoch: 0.9576886242745221
2025-08-26 16:40:20,775 - root - INFO - TRAINER_LOGS - loss: 1.3146 grad_norm: 1.5276354551315308 learning_rate: 7.695527265290499e-06 epoch: 0.9599963077065088
2025-08-26 16:41:03,217 - root - INFO - TRAINER_LOGS - loss: 1.3463 grad_norm: 1.4077256917953491 learning_rate: 7.685327050512213e-06 epoch: 0.9623039911384956
2025-08-26 16:41:46,435 - root - INFO - TRAINER_LOGS - loss: 1.3394 grad_norm: 1.691112756729126 learning_rate: 7.675111105544527e-06 epoch: 0.9646116745704825
2025-08-26 16:42:29,522 - root - INFO - TRAINER_LOGS - loss: 1.3309 grad_norm: 1.4213206768035889 learning_rate: 7.664879490230712e-06 epoch: 0.9669193580024692
2025-08-26 16:43:12,286 - root - INFO - TRAINER_LOGS - loss: 1.3674 grad_norm: 1.2321707010269165 learning_rate: 7.65463226450583e-06 epoch: 0.969227041434456
2025-08-26 16:46:10,228 - root - INFO - TRAINER_LOGS - eval_loss: 1.326181411743164 eval_runtime: 177.9371 eval_samples_per_second: 28.1 eval_steps_per_second: 1.175 epoch: 0.969227041434456
2025-08-26 16:46:54,119 - root - INFO - TRAINER_LOGS - loss: 1.3471 grad_norm: 1.3540774583816528 learning_rate: 7.644369488396386e-06 epoch: 0.9715347248664428
2025-08-26 16:47:37,028 - root - INFO - TRAINER_LOGS - loss: 1.3293 grad_norm: 1.325292944908142 learning_rate: 7.63409122201998e-06 epoch: 0.9738424082984296
2025-08-26 16:48:19,485 - root - INFO - TRAINER_LOGS - loss: 1.3625 grad_norm: 1.307486891746521 learning_rate: 7.623797525584951e-06 epoch: 0.9761500917304164
2025-08-26 16:49:01,665 - root - INFO - TRAINER_LOGS - loss: 1.3512 grad_norm: 1.5488615036010742 learning_rate: 7.613488459390017e-06 epoch: 0.9784577751624032
2025-08-26 16:49:42,767 - root - INFO - TRAINER_LOGS - loss: 1.3216 grad_norm: 1.3815244436264038 learning_rate: 7.603164083823942e-06 epoch: 0.98076545859439
2025-08-26 16:50:25,876 - root - INFO - TRAINER_LOGS - loss: 1.3091 grad_norm: 1.4075684547424316 learning_rate: 7.592824459365158e-06 epoch: 0.9830731420263769
2025-08-26 16:51:07,881 - root - INFO - TRAINER_LOGS - loss: 1.3696 grad_norm: 1.2745556831359863 learning_rate: 7.58246964658143e-06 epoch: 0.9853808254583636
2025-08-26 16:51:51,035 - root - INFO - TRAINER_LOGS - loss: 1.3204 grad_norm: 1.5707776546478271 learning_rate: 7.572099706129491e-06 epoch: 0.9876885088903504
2025-08-26 16:52:33,748 - root - INFO - TRAINER_LOGS - loss: 1.3304 grad_norm: 1.4639017581939697 learning_rate: 7.56171469875469e-06 epoch: 0.9899961923223373
2025-08-26 16:53:17,314 - root - INFO - TRAINER_LOGS - loss: 1.3056 grad_norm: 1.3724855184555054 learning_rate: 7.551314685290634e-06 epoch: 0.992303875754324
2025-08-26 16:53:59,971 - root - INFO - TRAINER_LOGS - loss: 1.3735 grad_norm: 1.4995297193527222 learning_rate: 7.5408997266588325e-06 epoch: 0.9946115591863108
2025-08-26 16:54:42,930 - root - INFO - TRAINER_LOGS - loss: 1.3335 grad_norm: 1.2436519861221313 learning_rate: 7.530469883868345e-06 epoch: 0.9969192426182977
2025-08-26 16:55:25,568 - root - INFO - TRAINER_LOGS - loss: 1.3606 grad_norm: 1.4747809171676636 learning_rate: 7.520025218015418e-06 epoch: 0.9992269260502844
2025-08-26 16:56:07,864 - root - INFO - TRAINER_LOGS - loss: 1.3364 grad_norm: 1.8452646732330322 learning_rate: 7.509565790283127e-06 epoch: 1.0015230710651113
2025-08-26 16:56:51,045 - root - INFO - TRAINER_LOGS - loss: 1.3631 grad_norm: 1.5465571880340576 learning_rate: 7.499091661941022e-06 epoch: 1.0038307544970981
2025-08-26 16:57:34,727 - root - INFO - TRAINER_LOGS - loss: 1.314 grad_norm: 1.5941966772079468 learning_rate: 7.488602894344769e-06 epoch: 1.006138437929085
2025-08-26 16:58:17,979 - root - INFO - TRAINER_LOGS - loss: 1.3592 grad_norm: 1.6954563856124878 learning_rate: 7.478099548935782e-06 epoch: 1.0084461213610716
2025-08-26 16:59:01,807 - root - INFO - TRAINER_LOGS - loss: 1.359 grad_norm: 1.5080246925354004 learning_rate: 7.467581687240875e-06 epoch: 1.0107538047930584
2025-08-26 16:59:43,743 - root - INFO - TRAINER_LOGS - loss: 1.3099 grad_norm: 1.4714487791061401 learning_rate: 7.457049370871893e-06 epoch: 1.0130614882250453
2025-08-26 17:00:27,379 - root - INFO - TRAINER_LOGS - loss: 1.319 grad_norm: 1.4338195323944092 learning_rate: 7.446502661525355e-06 epoch: 1.015369171657032
2025-08-26 17:03:25,735 - root - INFO - TRAINER_LOGS - eval_loss: 1.322632908821106 eval_runtime: 178.3513 eval_samples_per_second: 28.035 eval_steps_per_second: 1.172 epoch: 1.015369171657032
2025-08-26 17:04:09,722 - root - INFO - TRAINER_LOGS - loss: 1.3401 grad_norm: 1.564414143562317 learning_rate: 7.435941620982093e-06 epoch: 1.017676855089019
2025-08-26 17:04:52,812 - root - INFO - TRAINER_LOGS - loss: 1.3396 grad_norm: 1.3972090482711792 learning_rate: 7.425366311106887e-06 epoch: 1.0199845385210058
2025-08-26 17:05:35,775 - root - INFO - TRAINER_LOGS - loss: 1.3284 grad_norm: 2.105135917663574 learning_rate: 7.414776793848102e-06 epoch: 1.0222922219529924
2025-08-26 17:06:18,057 - root - INFO - TRAINER_LOGS - loss: 1.3314 grad_norm: 1.5100202560424805 learning_rate: 7.404173131237333e-06 epoch: 1.0245999053849792
2025-08-26 17:07:01,775 - root - INFO - TRAINER_LOGS - loss: 1.3072 grad_norm: 1.4356976747512817 learning_rate: 7.3935553853890305e-06 epoch: 1.026907588816966
2025-08-26 17:07:44,803 - root - INFO - TRAINER_LOGS - loss: 1.3249 grad_norm: 1.612356424331665 learning_rate: 7.382923618500148e-06 epoch: 1.029215272248953
2025-08-26 17:08:26,829 - root - INFO - TRAINER_LOGS - loss: 1.3358 grad_norm: 1.5615500211715698 learning_rate: 7.3722778928497676e-06 epoch: 1.0315229556809398
2025-08-26 17:09:10,322 - root - INFO - TRAINER_LOGS - loss: 1.3303 grad_norm: 1.3899110555648804 learning_rate: 7.36161827079874e-06 epoch: 1.0338306391129264
2025-08-26 17:09:52,774 - root - INFO - TRAINER_LOGS - loss: 1.3308 grad_norm: 1.4234883785247803 learning_rate: 7.350944814789318e-06 epoch: 1.0361383225449132
2025-08-26 17:10:35,774 - root - INFO - TRAINER_LOGS - loss: 1.3256 grad_norm: 1.606736183166504 learning_rate: 7.340257587344794e-06 epoch: 1.0384460059769
2025-08-26 17:11:18,630 - root - INFO - TRAINER_LOGS - loss: 1.371 grad_norm: 1.5634912252426147 learning_rate: 7.329556651069131e-06 epoch: 1.040753689408887
2025-08-26 17:12:01,614 - root - INFO - TRAINER_LOGS - loss: 1.3347 grad_norm: 1.3398995399475098 learning_rate: 7.318842068646593e-06 epoch: 1.0430613728408737
2025-08-26 17:12:44,831 - root - INFO - TRAINER_LOGS - loss: 1.3497 grad_norm: 1.4180899858474731 learning_rate: 7.308113902841382e-06 epoch: 1.0453690562728606
2025-08-26 17:13:28,661 - root - INFO - TRAINER_LOGS - loss: 1.3166 grad_norm: 1.4001169204711914 learning_rate: 7.297372216497271e-06 epoch: 1.0476767397048472
2025-08-26 17:14:11,145 - root - INFO - TRAINER_LOGS - loss: 1.3135 grad_norm: 1.3159528970718384 learning_rate: 7.2866170725372306e-06 epoch: 1.049984423136834
2025-08-26 17:14:54,096 - root - INFO - TRAINER_LOGS - loss: 1.3771 grad_norm: 1.6109669208526611 learning_rate: 7.275848533963069e-06 epoch: 1.0522921065688209
2025-08-26 17:15:37,073 - root - INFO - TRAINER_LOGS - loss: 1.2996 grad_norm: 1.6259294748306274 learning_rate: 7.2650666638550535e-06 epoch: 1.0545997900008077
2025-08-26 17:16:20,074 - root - INFO - TRAINER_LOGS - loss: 1.3527 grad_norm: 1.7084343433380127 learning_rate: 7.254271525371546e-06 epoch: 1.0569074734327946
2025-08-26 17:17:03,262 - root - INFO - TRAINER_LOGS - loss: 1.3186 grad_norm: 1.4496484994888306 learning_rate: 7.2434631817486335e-06 epoch: 1.0592151568647812
2025-08-26 17:17:47,644 - root - INFO - TRAINER_LOGS - loss: 1.3162 grad_norm: 1.4842808246612549 learning_rate: 7.232641696299754e-06 epoch: 1.061522840296768
2025-08-26 17:20:46,032 - root - INFO - TRAINER_LOGS - eval_loss: 1.323289155960083 eval_runtime: 178.3834 eval_samples_per_second: 28.03 eval_steps_per_second: 1.172 epoch: 1.061522840296768
2025-08-26 17:21:29,756 - root - INFO - TRAINER_LOGS - loss: 1.3397 grad_norm: 1.389695405960083 learning_rate: 7.221807132415331e-06 epoch: 1.0638305237287549
2025-08-26 17:22:12,276 - root - INFO - TRAINER_LOGS - loss: 1.3553 grad_norm: 1.8950284719467163 learning_rate: 7.210959553562397e-06 epoch: 1.0661382071607417
2025-08-26 17:22:55,229 - root - INFO - TRAINER_LOGS - loss: 1.3126 grad_norm: 1.6522051095962524 learning_rate: 7.200099023284227e-06 epoch: 1.0684458905927285
2025-08-26 17:23:37,872 - root - INFO - TRAINER_LOGS - loss: 1.3167 grad_norm: 1.5844911336898804 learning_rate: 7.18922560519996e-06 epoch: 1.0707535740247154
2025-08-26 17:24:20,037 - root - INFO - TRAINER_LOGS - loss: 1.3529 grad_norm: 1.579250693321228 learning_rate: 7.178339363004232e-06 epoch: 1.073061257456702
2025-08-26 17:25:02,845 - root - INFO - TRAINER_LOGS - loss: 1.3012 grad_norm: 1.6130703687667847 learning_rate: 7.1674403604667965e-06 epoch: 1.0753689408886888
2025-08-26 17:25:46,204 - root - INFO - TRAINER_LOGS - loss: 1.3316 grad_norm: 1.3401845693588257 learning_rate: 7.15652866143216e-06 epoch: 1.0776766243206757
2025-08-26 17:26:28,735 - root - INFO - TRAINER_LOGS - loss: 1.3151 grad_norm: 1.6394455432891846 learning_rate: 7.1456043298192e-06 epoch: 1.0799843077526625
2025-08-26 17:27:12,213 - root - INFO - TRAINER_LOGS - loss: 1.3306 grad_norm: 1.5628552436828613 learning_rate: 7.134667429620796e-06 epoch: 1.0822919911846494
2025-08-26 17:27:56,104 - root - INFO - TRAINER_LOGS - loss: 1.2924 grad_norm: 1.7079850435256958 learning_rate: 7.123718024903446e-06 epoch: 1.0845996746166362
2025-08-26 17:28:38,883 - root - INFO - TRAINER_LOGS - loss: 1.3187 grad_norm: 1.40892493724823 learning_rate: 7.112756179806906e-06 epoch: 1.0869073580486228
2025-08-26 17:29:21,933 - root - INFO - TRAINER_LOGS - loss: 1.3345 grad_norm: 1.729163646697998 learning_rate: 7.101781958543797e-06 epoch: 1.0892150414806097
2025-08-26 17:30:04,356 - root - INFO - TRAINER_LOGS - loss: 1.3362 grad_norm: 1.53681218624115 learning_rate: 7.090795425399246e-06 epoch: 1.0915227249125965
2025-08-26 17:30:47,311 - root - INFO - TRAINER_LOGS - loss: 1.3274 grad_norm: 1.477318286895752 learning_rate: 7.079796644730495e-06 epoch: 1.0938304083445833
2025-08-26 17:31:30,614 - root - INFO - TRAINER_LOGS - loss: 1.3076 grad_norm: 1.6210815906524658 learning_rate: 7.068785680966531e-06 epoch: 1.0961380917765702
2025-08-26 17:32:12,591 - root - INFO - TRAINER_LOGS - loss: 1.2941 grad_norm: 1.7492475509643555 learning_rate: 7.057762598607709e-06 epoch: 1.0984457752085568
2025-08-26 17:32:55,322 - root - INFO - TRAINER_LOGS - loss: 1.3485 grad_norm: 1.4599584341049194 learning_rate: 7.046727462225369e-06 epoch: 1.1007534586405436
2025-08-26 17:33:38,720 - root - INFO - TRAINER_LOGS - loss: 1.2876 grad_norm: 1.5947767496109009 learning_rate: 7.035680336461467e-06 epoch: 1.1030611420725305
2025-08-26 17:34:20,899 - root - INFO - TRAINER_LOGS - loss: 1.3387 grad_norm: 1.6296190023422241 learning_rate: 7.024621286028186e-06 epoch: 1.1053688255045173
2025-08-26 17:35:04,163 - root - INFO - TRAINER_LOGS - loss: 1.3223 grad_norm: 1.5378764867782593 learning_rate: 7.013550375707567e-06 epoch: 1.1076765089365042
2025-08-26 17:38:02,477 - root - INFO - TRAINER_LOGS - eval_loss: 1.32206392288208 eval_runtime: 178.3097 eval_samples_per_second: 28.041 eval_steps_per_second: 1.172 epoch: 1.1076765089365042
2025-08-26 17:38:45,760 - root - INFO - TRAINER_LOGS - loss: 1.3293 grad_norm: 1.3424577713012695 learning_rate: 7.0024676703511165e-06 epoch: 1.1099841923684908
2025-08-26 17:39:27,637 - root - INFO - TRAINER_LOGS - loss: 1.3289 grad_norm: 1.756030559539795 learning_rate: 6.991373234879442e-06 epoch: 1.1122918758004776
2025-08-26 17:40:10,489 - root - INFO - TRAINER_LOGS - loss: 1.3163 grad_norm: 1.678093433380127 learning_rate: 6.980267134281857e-06 epoch: 1.1145995592324645
2025-08-26 17:40:54,486 - root - INFO - TRAINER_LOGS - loss: 1.3208 grad_norm: 1.6513371467590332 learning_rate: 6.969149433616015e-06 epoch: 1.1169072426644513
2025-08-26 17:41:36,974 - root - INFO - TRAINER_LOGS - loss: 1.3325 grad_norm: 1.587456226348877 learning_rate: 6.958020198007513e-06 epoch: 1.1192149260964381
2025-08-26 17:42:19,583 - root - INFO - TRAINER_LOGS - loss: 1.3328 grad_norm: 1.5659934282302856 learning_rate: 6.946879492649525e-06 epoch: 1.121522609528425
2025-08-26 17:43:03,207 - root - INFO - TRAINER_LOGS - loss: 1.3301 grad_norm: 1.7770127058029175 learning_rate: 6.935727382802406e-06 epoch: 1.1238302929604116
2025-08-26 17:43:46,946 - root - INFO - TRAINER_LOGS - loss: 1.3512 grad_norm: 1.6546350717544556 learning_rate: 6.924563933793321e-06 epoch: 1.1261379763923984
2025-08-26 17:44:29,937 - root - INFO - TRAINER_LOGS - loss: 1.3514 grad_norm: 1.6032334566116333 learning_rate: 6.913389211015857e-06 epoch: 1.1284456598243853
2025-08-26 17:45:13,009 - root - INFO - TRAINER_LOGS - loss: 1.3074 grad_norm: 1.6513099670410156 learning_rate: 6.902203279929641e-06 epoch: 1.1307533432563721
2025-08-26 17:45:56,437 - root - INFO - TRAINER_LOGS - loss: 1.3497 grad_norm: 1.4707990884780884 learning_rate: 6.891006206059956e-06 epoch: 1.133061026688359
2025-08-26 17:46:40,027 - root - INFO - TRAINER_LOGS - loss: 1.3501 grad_norm: 1.5663785934448242 learning_rate: 6.8797980549973556e-06 epoch: 1.1353687101203458
2025-08-26 17:47:23,259 - root - INFO - TRAINER_LOGS - loss: 1.3235 grad_norm: 1.5139249563217163 learning_rate: 6.868578892397284e-06 epoch: 1.1376763935523324
2025-08-26 17:48:06,141 - root - INFO - TRAINER_LOGS - loss: 1.3501 grad_norm: 1.5288828611373901 learning_rate: 6.857348783979689e-06 epoch: 1.1399840769843193
2025-08-26 17:48:48,431 - root - INFO - TRAINER_LOGS - loss: 1.3341 grad_norm: 1.6603312492370605 learning_rate: 6.846107795528638e-06 epoch: 1.142291760416306
2025-08-26 17:49:31,878 - root - INFO - TRAINER_LOGS - loss: 1.3358 grad_norm: 1.6459987163543701 learning_rate: 6.834855992891929e-06 epoch: 1.144599443848293
2025-08-26 17:50:15,781 - root - INFO - TRAINER_LOGS - loss: 1.3302 grad_norm: 1.7629539966583252 learning_rate: 6.82359344198071e-06 epoch: 1.1469071272802798
2025-08-26 17:50:58,508 - root - INFO - TRAINER_LOGS - loss: 1.3221 grad_norm: 1.60916006565094 learning_rate: 6.812320208769089e-06 epoch: 1.1492148107122664
2025-08-26 17:51:41,404 - root - INFO - TRAINER_LOGS - loss: 1.3426 grad_norm: 1.6998745203018188 learning_rate: 6.801036359293751e-06 epoch: 1.1515224941442532
2025-08-26 17:52:23,468 - root - INFO - TRAINER_LOGS - loss: 1.2909 grad_norm: 1.8979970216751099 learning_rate: 6.789741959653567e-06 epoch: 1.15383017757624
2025-08-26 17:55:21,685 - root - INFO - TRAINER_LOGS - eval_loss: 1.3221988677978516 eval_runtime: 178.2117 eval_samples_per_second: 28.057 eval_steps_per_second: 1.173 epoch: 1.15383017757624
2025-08-26 17:56:05,251 - root - INFO - TRAINER_LOGS - loss: 1.3588 grad_norm: 1.9095135927200317 learning_rate: 6.778437076009212e-06 epoch: 1.156137861008227
2025-08-26 17:56:48,204 - root - INFO - TRAINER_LOGS - loss: 1.3136 grad_norm: 1.6465333700180054 learning_rate: 6.76712177458277e-06 epoch: 1.1584455444402137
2025-08-26 17:57:31,070 - root - INFO - TRAINER_LOGS - loss: 1.3489 grad_norm: 1.5356884002685547 learning_rate: 6.755796121657356e-06 epoch: 1.1607532278722006
2025-08-26 17:58:14,781 - root - INFO - TRAINER_LOGS - loss: 1.3155 grad_norm: 1.668105125427246 learning_rate: 6.744460183576717e-06 epoch: 1.1630609113041872
2025-08-26 17:58:57,625 - root - INFO - TRAINER_LOGS - loss: 1.3415 grad_norm: 1.3812769651412964 learning_rate: 6.733114026744854e-06 epoch: 1.165368594736174
2025-08-26 17:59:40,620 - root - INFO - TRAINER_LOGS - loss: 1.339 grad_norm: 1.4423964023590088 learning_rate: 6.721757717625623e-06 epoch: 1.1676762781681609
2025-08-26 18:00:23,860 - root - INFO - TRAINER_LOGS - loss: 1.3346 grad_norm: 1.6931160688400269 learning_rate: 6.710391322742356e-06 epoch: 1.1699839616001477
2025-08-26 18:01:06,155 - root - INFO - TRAINER_LOGS - loss: 1.3441 grad_norm: 1.5095406770706177 learning_rate: 6.699014908677457e-06 epoch: 1.1722916450321346
2025-08-26 18:01:49,512 - root - INFO - TRAINER_LOGS - loss: 1.3258 grad_norm: 1.6033201217651367 learning_rate: 6.687628542072029e-06 epoch: 1.1745993284641214
2025-08-26 18:02:32,934 - root - INFO - TRAINER_LOGS - loss: 1.3544 grad_norm: 1.630974292755127 learning_rate: 6.676232289625471e-06 epoch: 1.176907011896108
2025-08-26 18:03:15,496 - root - INFO - TRAINER_LOGS - loss: 1.361 grad_norm: 1.7806133031845093 learning_rate: 6.664826218095093e-06 epoch: 1.1792146953280949
2025-08-26 18:03:57,769 - root - INFO - TRAINER_LOGS - loss: 1.3257 grad_norm: 1.632522702217102 learning_rate: 6.653410394295724e-06 epoch: 1.1815223787600817
2025-08-26 18:04:40,374 - root - INFO - TRAINER_LOGS - loss: 1.3349 grad_norm: 1.4933655261993408 learning_rate: 6.641984885099317e-06 epoch: 1.1838300621920685
2025-08-26 18:05:22,758 - root - INFO - TRAINER_LOGS - loss: 1.3453 grad_norm: 1.7451590299606323 learning_rate: 6.6305497574345654e-06 epoch: 1.1861377456240554
2025-08-26 18:06:05,029 - root - INFO - TRAINER_LOGS - loss: 1.3393 grad_norm: 1.5291390419006348 learning_rate: 6.619105078286502e-06 epoch: 1.188445429056042
2025-08-26 18:06:47,699 - root - INFO - TRAINER_LOGS - loss: 1.342 grad_norm: 1.6877292394638062 learning_rate: 6.607650914696112e-06 epoch: 1.1907531124880288
2025-08-26 18:07:30,909 - root - INFO - TRAINER_LOGS - loss: 1.3376 grad_norm: 1.5736799240112305 learning_rate: 6.596187333759938e-06 epoch: 1.1930607959200157
2025-08-26 18:08:13,546 - root - INFO - TRAINER_LOGS - loss: 1.316 grad_norm: 1.675697922706604 learning_rate: 6.584714402629689e-06 epoch: 1.1953684793520025
2025-08-26 18:08:56,531 - root - INFO - TRAINER_LOGS - loss: 1.326 grad_norm: 1.8396027088165283 learning_rate: 6.573232188511845e-06 epoch: 1.1976761627839894
2025-08-26 18:09:39,189 - root - INFO - TRAINER_LOGS - loss: 1.2875 grad_norm: 1.4962289333343506 learning_rate: 6.561740758667266e-06 epoch: 1.199983846215976
2025-08-26 18:12:37,007 - root - INFO - TRAINER_LOGS - eval_loss: 1.320682168006897 eval_runtime: 177.8136 eval_samples_per_second: 28.119 eval_steps_per_second: 1.175 epoch: 1.199983846215976
2025-08-26 18:13:19,387 - root - INFO - TRAINER_LOGS - loss: 1.324 grad_norm: 1.4163408279418945 learning_rate: 6.5504702811947095e-06 epoch: 1.2022915296479628
2025-08-26 18:14:02,132 - root - INFO - TRAINER_LOGS - loss: 1.3312 grad_norm: 1.8788024187088013 learning_rate: 6.5389608028550885e-06 epoch: 1.2045992130799497
2025-08-26 18:14:44,311 - root - INFO - TRAINER_LOGS - loss: 1.332 grad_norm: 1.5148788690567017 learning_rate: 6.527442309544685e-06 epoch: 1.2069068965119365
2025-08-26 18:15:27,848 - root - INFO - TRAINER_LOGS - loss: 1.3338 grad_norm: 1.6821925640106201 learning_rate: 6.515914868736871e-06 epoch: 1.2092145799439233
2025-08-26 18:16:09,959 - root - INFO - TRAINER_LOGS - loss: 1.3394 grad_norm: 1.794545292854309 learning_rate: 6.504378547957439e-06 epoch: 1.2115222633759102
2025-08-26 18:16:52,115 - root - INFO - TRAINER_LOGS - loss: 1.33 grad_norm: 1.5097174644470215 learning_rate: 6.492833414784192e-06 epoch: 1.2138299468078968
2025-08-26 18:17:34,474 - root - INFO - TRAINER_LOGS - loss: 1.3305 grad_norm: 1.6818313598632812 learning_rate: 6.481279536846561e-06 epoch: 1.2161376302398836
2025-08-26 18:18:17,566 - root - INFO - TRAINER_LOGS - loss: 1.35 grad_norm: 1.445190191268921 learning_rate: 6.4697169818251945e-06 epoch: 1.2184453136718705
2025-08-26 18:19:00,844 - root - INFO - TRAINER_LOGS - loss: 1.357 grad_norm: 1.7883989810943604 learning_rate: 6.4581458174515775e-06 epoch: 1.2207529971038573
2025-08-26 18:19:44,096 - root - INFO - TRAINER_LOGS - loss: 1.338 grad_norm: 1.5364338159561157 learning_rate: 6.446566111507624e-06 epoch: 1.2230606805358442
2025-08-26 18:20:27,653 - root - INFO - TRAINER_LOGS - loss: 1.3348 grad_norm: 1.6638609170913696 learning_rate: 6.434977931825281e-06 epoch: 1.225368363967831
2025-08-26 18:21:10,010 - root - INFO - TRAINER_LOGS - loss: 1.2879 grad_norm: 1.9247432947158813 learning_rate: 6.423381346286137e-06 epoch: 1.2276760473998176
2025-08-26 18:21:52,767 - root - INFO - TRAINER_LOGS - loss: 1.332 grad_norm: 1.812583565711975 learning_rate: 6.41177642282102e-06 epoch: 1.2299837308318045
2025-08-26 18:22:36,411 - root - INFO - TRAINER_LOGS - loss: 1.3281 grad_norm: 1.5547165870666504 learning_rate: 6.400163229409596e-06 epoch: 1.2322914142637913
2025-08-26 18:23:19,222 - root - INFO - TRAINER_LOGS - loss: 1.3139 grad_norm: 1.6260566711425781 learning_rate: 6.38854183407998e-06 epoch: 1.2345990976957781
2025-08-26 18:24:01,734 - root - INFO - TRAINER_LOGS - loss: 1.3001 grad_norm: 1.6591205596923828 learning_rate: 6.376912304908329e-06 epoch: 1.236906781127765
2025-08-26 18:24:45,138 - root - INFO - TRAINER_LOGS - loss: 1.3151 grad_norm: 1.7385751008987427 learning_rate: 6.36527471001845e-06 epoch: 1.2392144645597516
2025-08-26 18:25:28,599 - root - INFO - TRAINER_LOGS - loss: 1.3599 grad_norm: 1.6535831689834595 learning_rate: 6.353629117581395e-06 epoch: 1.2415221479917384
2025-08-26 18:26:11,343 - root - INFO - TRAINER_LOGS - loss: 1.3418 grad_norm: 1.626987099647522 learning_rate: 6.341975595815062e-06 epoch: 1.2438298314237253
2025-08-26 18:26:54,258 - root - INFO - TRAINER_LOGS - loss: 1.3288 grad_norm: 1.6143946647644043 learning_rate: 6.330314212983805e-06 epoch: 1.2461375148557121
2025-08-26 18:29:52,142 - root - INFO - TRAINER_LOGS - eval_loss: 1.3209834098815918 eval_runtime: 177.8793 eval_samples_per_second: 28.109 eval_steps_per_second: 1.175 epoch: 1.2461375148557121
2025-08-26 18:30:36,007 - root - INFO - TRAINER_LOGS - loss: 1.3286 grad_norm: 1.8445202112197876 learning_rate: 6.318645037398019e-06 epoch: 1.248445198287699
2025-08-26 18:31:18,815 - root - INFO - TRAINER_LOGS - loss: 1.3672 grad_norm: 1.8495044708251953 learning_rate: 6.3069681374137534e-06 epoch: 1.2507528817196856
2025-08-26 18:32:02,187 - root - INFO - TRAINER_LOGS - loss: 1.3481 grad_norm: 1.62735915184021 learning_rate: 6.295283581432303e-06 epoch: 1.2530605651516724
2025-08-26 18:32:45,177 - root - INFO - TRAINER_LOGS - loss: 1.3393 grad_norm: 1.8508200645446777 learning_rate: 6.2835914378998095e-06 epoch: 1.2553682485836593
2025-08-26 18:33:28,104 - root - INFO - TRAINER_LOGS - loss: 1.348 grad_norm: 1.5577661991119385 learning_rate: 6.271891775306862e-06 epoch: 1.257675932015646
2025-08-26 18:34:10,553 - root - INFO - TRAINER_LOGS - loss: 1.315 grad_norm: 1.6574722528457642 learning_rate: 6.260184662188097e-06 epoch: 1.259983615447633
2025-08-26 18:34:54,470 - root - INFO - TRAINER_LOGS - loss: 1.3573 grad_norm: 1.6579254865646362 learning_rate: 6.248470167121792e-06 epoch: 1.2622912988796198
2025-08-26 18:35:36,994 - root - INFO - TRAINER_LOGS - loss: 1.3412 grad_norm: 1.5600484609603882 learning_rate: 6.236748358729467e-06 epoch: 1.2645989823116066
2025-08-26 18:36:19,644 - root - INFO - TRAINER_LOGS - loss: 1.2926 grad_norm: 1.5787293910980225 learning_rate: 6.225019305675484e-06 epoch: 1.2669066657435932
2025-08-26 18:37:01,528 - root - INFO - TRAINER_LOGS - loss: 1.3396 grad_norm: 1.9914625883102417 learning_rate: 6.213283076666643e-06 epoch: 1.26921434917558
2025-08-26 18:37:44,802 - root - INFO - TRAINER_LOGS - loss: 1.3206 grad_norm: 1.6024879217147827 learning_rate: 6.201539740451777e-06 epoch: 1.271522032607567
2025-08-26 18:38:27,674 - root - INFO - TRAINER_LOGS - loss: 1.305 grad_norm: 1.8275507688522339 learning_rate: 6.189789365821353e-06 epoch: 1.2738297160395537
2025-08-26 18:39:10,982 - root - INFO - TRAINER_LOGS - loss: 1.3215 grad_norm: 1.9568958282470703 learning_rate: 6.178032021607071e-06 epoch: 1.2761373994715406
2025-08-26 18:39:52,904 - root - INFO - TRAINER_LOGS - loss: 1.3299 grad_norm: 1.7022041082382202 learning_rate: 6.166267776681451e-06 epoch: 1.2784450829035272
2025-08-26 18:40:35,666 - root - INFO - TRAINER_LOGS - loss: 1.2877 grad_norm: 1.74421226978302 learning_rate: 6.154496699957444e-06 epoch: 1.280752766335514
2025-08-26 18:41:18,244 - root - INFO - TRAINER_LOGS - loss: 1.3263 grad_norm: 1.6282674074172974 learning_rate: 6.142718860388014e-06 epoch: 1.2830604497675009
2025-08-26 18:42:00,811 - root - INFO - TRAINER_LOGS - loss: 1.2993 grad_norm: 1.5755274295806885 learning_rate: 6.130934326965743e-06 epoch: 1.2853681331994877
2025-08-26 18:42:44,215 - root - INFO - TRAINER_LOGS - loss: 1.3261 grad_norm: 1.9579572677612305 learning_rate: 6.119143168722425e-06 epoch: 1.2876758166314746
2025-08-26 18:43:27,883 - root - INFO - TRAINER_LOGS - loss: 1.3318 grad_norm: 1.882307529449463 learning_rate: 6.1073454547286625e-06 epoch: 1.2899835000634612
2025-08-26 18:44:10,481 - root - INFO - TRAINER_LOGS - loss: 1.3403 grad_norm: 1.939072608947754 learning_rate: 6.095541254093457e-06 epoch: 1.292291183495448
2025-08-26 18:47:08,406 - root - INFO - TRAINER_LOGS - eval_loss: 1.3176963329315186 eval_runtime: 177.9203 eval_samples_per_second: 28.102 eval_steps_per_second: 1.175 epoch: 1.292291183495448
2025-08-26 18:47:51,689 - root - INFO - TRAINER_LOGS - loss: 1.3123 grad_norm: 1.905798316001892 learning_rate: 6.0837306359638084e-06 epoch: 1.2945988669274349
2025-08-26 18:48:35,260 - root - INFO - TRAINER_LOGS - loss: 1.3491 grad_norm: 1.7225983142852783 learning_rate: 6.071913669524312e-06 epoch: 1.2969065503594217
2025-08-26 18:49:18,326 - root - INFO - TRAINER_LOGS - loss: 1.3456 grad_norm: 1.5382517576217651 learning_rate: 6.060090423996746e-06 epoch: 1.2992142337914085
2025-08-26 18:50:02,386 - root - INFO - TRAINER_LOGS - loss: 1.334 grad_norm: 1.6037620306015015 learning_rate: 6.048260968639677e-06 epoch: 1.3015219172233952
2025-08-26 18:50:45,901 - root - INFO - TRAINER_LOGS - loss: 1.3406 grad_norm: 1.6318944692611694 learning_rate: 6.036425372748041e-06 epoch: 1.3038296006553822
2025-08-26 18:51:29,061 - root - INFO - TRAINER_LOGS - loss: 1.3335 grad_norm: 1.9311468601226807 learning_rate: 6.024583705652744e-06 epoch: 1.3061372840873688
2025-08-26 18:52:12,003 - root - INFO - TRAINER_LOGS - loss: 1.3242 grad_norm: 1.40023672580719 learning_rate: 6.012736036720266e-06 epoch: 1.3084449675193557
2025-08-26 18:52:54,234 - root - INFO - TRAINER_LOGS - loss: 1.3097 grad_norm: 1.8041404485702515 learning_rate: 6.000882435352232e-06 epoch: 1.3107526509513425
2025-08-26 18:53:35,763 - root - INFO - TRAINER_LOGS - loss: 1.3316 grad_norm: 1.8807095289230347 learning_rate: 5.989260217280482e-06 epoch: 1.3130603343833294
2025-08-26 18:54:17,870 - root - INFO - TRAINER_LOGS - loss: 1.3468 grad_norm: 1.8073108196258545 learning_rate: 5.977395074574364e-06 epoch: 1.3153680178153162
2025-08-26 18:55:01,008 - root - INFO - TRAINER_LOGS - loss: 1.3401 grad_norm: 1.4988517761230469 learning_rate: 5.965524206454043e-06 epoch: 1.3176757012473028
2025-08-26 18:55:43,720 - root - INFO - TRAINER_LOGS - loss: 1.3353 grad_norm: 1.6470049619674683 learning_rate: 5.953647682457043e-06 epoch: 1.3199833846792897
2025-08-26 18:56:27,104 - root - INFO - TRAINER_LOGS - loss: 1.3338 grad_norm: 1.886756420135498 learning_rate: 5.941765572154025e-06 epoch: 1.3222910681112765
2025-08-26 18:57:10,562 - root - INFO - TRAINER_LOGS - loss: 1.3189 grad_norm: 1.5149116516113281 learning_rate: 5.929877945148369e-06 epoch: 1.3245987515432633
2025-08-26 18:57:53,610 - root - INFO - TRAINER_LOGS - loss: 1.3511 grad_norm: 1.4692649841308594 learning_rate: 5.9179848710757745e-06 epoch: 1.3269064349752502
2025-08-26 18:58:36,378 - root - INFO - TRAINER_LOGS - loss: 1.3362 grad_norm: 1.442693829536438 learning_rate: 5.906086419603849e-06 epoch: 1.3292141184072368
2025-08-26 18:59:19,232 - root - INFO - TRAINER_LOGS - loss: 1.2698 grad_norm: 1.5183508396148682 learning_rate: 5.8941826604316976e-06 epoch: 1.3315218018392236
2025-08-26 19:00:02,573 - root - INFO - TRAINER_LOGS - loss: 1.3407 grad_norm: 1.9445852041244507 learning_rate: 5.882273663289519e-06 epoch: 1.3338294852712105
2025-08-26 19:00:45,580 - root - INFO - TRAINER_LOGS - loss: 1.3581 grad_norm: 1.656011939048767 learning_rate: 5.870359497938192e-06 epoch: 1.3361371687031973
2025-08-26 19:01:29,639 - root - INFO - TRAINER_LOGS - loss: 1.3612 grad_norm: 1.6777516603469849 learning_rate: 5.858440234168873e-06 epoch: 1.3384448521351842
2025-08-26 19:04:27,457 - root - INFO - TRAINER_LOGS - eval_loss: 1.3184033632278442 eval_runtime: 177.8129 eval_samples_per_second: 28.119 eval_steps_per_second: 1.175 epoch: 1.3384448521351842
2025-08-26 19:05:10,675 - root - INFO - TRAINER_LOGS - loss: 1.3244 grad_norm: 1.6202195882797241 learning_rate: 5.846515941802583e-06 epoch: 1.3407525355671708
2025-08-26 19:05:54,044 - root - INFO - TRAINER_LOGS - loss: 1.3287 grad_norm: 1.6824028491973877 learning_rate: 5.8345866906898006e-06 epoch: 1.3430602189991576
2025-08-26 19:06:37,018 - root - INFO - TRAINER_LOGS - loss: 1.3472 grad_norm: 1.6453393697738647 learning_rate: 5.822652550710051e-06 epoch: 1.3453679024311445
2025-08-26 19:07:20,775 - root - INFO - TRAINER_LOGS - loss: 1.3055 grad_norm: 1.6457468271255493 learning_rate: 5.810713591771496e-06 epoch: 1.3476755858631313
2025-08-26 19:08:04,076 - root - INFO - TRAINER_LOGS - loss: 1.3114 grad_norm: 1.7113348245620728 learning_rate: 5.79876988381053e-06 epoch: 1.3499832692951181
2025-08-26 19:08:47,677 - root - INFO - TRAINER_LOGS - loss: 1.3051 grad_norm: 1.5823907852172852 learning_rate: 5.786821496791363e-06 epoch: 1.352290952727105
2025-08-26 19:09:31,304 - root - INFO - TRAINER_LOGS - loss: 1.3388 grad_norm: 1.6842974424362183 learning_rate: 5.774868500705612e-06 epoch: 1.3545986361590918
2025-08-26 19:10:14,275 - root - INFO - TRAINER_LOGS - loss: 1.342 grad_norm: 1.5409435033798218 learning_rate: 5.762910965571902e-06 epoch: 1.3569063195910784
2025-08-26 19:10:56,798 - root - INFO - TRAINER_LOGS - loss: 1.3313 grad_norm: 1.4931772947311401 learning_rate: 5.750948961435437e-06 epoch: 1.3592140030230653
2025-08-26 19:11:40,396 - root - INFO - TRAINER_LOGS - loss: 1.3331 grad_norm: 1.355272650718689 learning_rate: 5.7389825583676064e-06 epoch: 1.3615216864550521
2025-08-26 19:12:23,986 - root - INFO - TRAINER_LOGS - loss: 1.3147 grad_norm: 1.4796850681304932 learning_rate: 5.727011826465563e-06 epoch: 1.363829369887039
2025-08-26 19:13:07,207 - root - INFO - TRAINER_LOGS - loss: 1.3325 grad_norm: 1.9794389009475708 learning_rate: 5.715036835851821e-06 epoch: 1.3661370533190258
2025-08-26 19:13:49,765 - root - INFO - TRAINER_LOGS - loss: 1.3347 grad_norm: 1.6836137771606445 learning_rate: 5.703057656673839e-06 epoch: 1.3684447367510124
2025-08-26 19:14:32,948 - root - INFO - TRAINER_LOGS - loss: 1.3302 grad_norm: 1.7027100324630737 learning_rate: 5.691074359103612e-06 epoch: 1.3707524201829993
2025-08-26 19:15:16,222 - root - INFO - TRAINER_LOGS - loss: 1.3352 grad_norm: 1.6504950523376465 learning_rate: 5.679087013337262e-06 epoch: 1.373060103614986
2025-08-26 19:15:59,519 - root - INFO - TRAINER_LOGS - loss: 1.3203 grad_norm: 1.473349928855896 learning_rate: 5.667095689594622e-06 epoch: 1.375367787046973
2025-08-26 19:16:41,689 - root - INFO - TRAINER_LOGS - loss: 1.3114 grad_norm: 1.6065441370010376 learning_rate: 5.655100458118828e-06 epoch: 1.3776754704789598
2025-08-26 19:17:25,025 - root - INFO - TRAINER_LOGS - loss: 1.3419 grad_norm: 1.7634202241897583 learning_rate: 5.643101389175906e-06 epoch: 1.3799831539109464
2025-08-26 19:18:08,269 - root - INFO - TRAINER_LOGS - loss: 1.3683 grad_norm: 1.5125751495361328 learning_rate: 5.631098553054363e-06 epoch: 1.3822908373429332
2025-08-26 19:18:51,348 - root - INFO - TRAINER_LOGS - loss: 1.3483 grad_norm: 1.5530307292938232 learning_rate: 5.619092020064774e-06 epoch: 1.38459852077492
2025-08-26 19:21:49,642 - root - INFO - TRAINER_LOGS - eval_loss: 1.315229892730713 eval_runtime: 178.2894 eval_samples_per_second: 28.044 eval_steps_per_second: 1.172 epoch: 1.38459852077492
2025-08-26 19:22:33,102 - root - INFO - TRAINER_LOGS - loss: 1.3139 grad_norm: 1.5027432441711426 learning_rate: 5.607081860539365e-06 epoch: 1.386906204206907
2025-08-26 19:23:16,421 - root - INFO - TRAINER_LOGS - loss: 1.3244 grad_norm: 1.672611117362976 learning_rate: 5.595068144831613e-06 epoch: 1.3892138876388938
2025-08-26 19:23:58,997 - root - INFO - TRAINER_LOGS - loss: 1.308 grad_norm: 1.5190799236297607 learning_rate: 5.583050943315821e-06 epoch: 1.3915215710708804
2025-08-26 19:24:42,359 - root - INFO - TRAINER_LOGS - loss: 1.319 grad_norm: 1.6894713640213013 learning_rate: 5.57103032638671e-06 epoch: 1.3938292545028674
2025-08-26 19:25:25,170 - root - INFO - TRAINER_LOGS - loss: 1.3395 grad_norm: 1.6881263256072998 learning_rate: 5.559006364459017e-06 epoch: 1.396136937934854
2025-08-26 19:26:07,583 - root - INFO - TRAINER_LOGS - loss: 1.362 grad_norm: 1.8194975852966309 learning_rate: 5.546979127967061e-06 epoch: 1.398444621366841
2025-08-26 19:26:51,138 - root - INFO - TRAINER_LOGS - loss: 1.3423 grad_norm: 1.8812236785888672 learning_rate: 5.53494868736435e-06 epoch: 1.4007523047988277
2025-08-26 19:27:34,854 - root - INFO - TRAINER_LOGS - loss: 1.3204 grad_norm: 1.5430397987365723 learning_rate: 5.522915113123163e-06 epoch: 1.4030599882308146
2025-08-26 19:28:17,415 - root - INFO - TRAINER_LOGS - loss: 1.3066 grad_norm: 1.756072759628296 learning_rate: 5.5108784757341285e-06 epoch: 1.4053676716628014
2025-08-26 19:29:00,941 - root - INFO - TRAINER_LOGS - loss: 1.3235 grad_norm: 1.5048500299453735 learning_rate: 5.498838845705824e-06 epoch: 1.407675355094788
2025-08-26 19:29:43,732 - root - INFO - TRAINER_LOGS - loss: 1.3302 grad_norm: 1.8976207971572876 learning_rate: 5.486796293564358e-06 epoch: 1.4099830385267749
2025-08-26 19:30:26,310 - root - INFO - TRAINER_LOGS - loss: 1.3185 grad_norm: 1.8265857696533203 learning_rate: 5.474750889852951e-06 epoch: 1.4122907219587617
2025-08-26 19:31:10,097 - root - INFO - TRAINER_LOGS - loss: 1.3398 grad_norm: 1.6910853385925293 learning_rate: 5.462702705131532e-06 epoch: 1.4145984053907485
2025-08-26 19:31:52,837 - root - INFO - TRAINER_LOGS - loss: 1.3293 grad_norm: 1.6413170099258423 learning_rate: 5.4506518099763175e-06 epoch: 1.4169060888227354
2025-08-26 19:32:35,728 - root - INFO - TRAINER_LOGS - loss: 1.3082 grad_norm: 1.83014714717865 learning_rate: 5.438598274979403e-06 epoch: 1.419213772254722
2025-08-26 19:33:18,917 - root - INFO - TRAINER_LOGS - loss: 1.3445 grad_norm: 1.113195538520813 learning_rate: 5.42654217074835e-06 epoch: 1.4215214556867088
2025-08-26 19:34:02,183 - root - INFO - TRAINER_LOGS - loss: 1.3315 grad_norm: 1.5500813722610474 learning_rate: 5.414483567905766e-06 epoch: 1.4238291391186957
2025-08-26 19:34:45,616 - root - INFO - TRAINER_LOGS - loss: 1.3232 grad_norm: 1.626527190208435 learning_rate: 5.402422537088895e-06 epoch: 1.4261368225506825
2025-08-26 19:35:28,890 - root - INFO - TRAINER_LOGS - loss: 1.3036 grad_norm: 1.700847864151001 learning_rate: 5.390359148949209e-06 epoch: 1.4284445059826694
2025-08-26 19:36:11,876 - root - INFO - TRAINER_LOGS - loss: 1.297 grad_norm: 1.5393304824829102 learning_rate: 5.378293474151982e-06 epoch: 1.430752189414656
2025-08-26 19:39:10,342 - root - INFO - TRAINER_LOGS - eval_loss: 1.3150101900100708 eval_runtime: 178.4612 eval_samples_per_second: 28.017 eval_steps_per_second: 1.171 epoch: 1.430752189414656
2025-08-26 19:39:53,577 - root - INFO - TRAINER_LOGS - loss: 1.3542 grad_norm: 1.6852279901504517 learning_rate: 5.366225583375888e-06 epoch: 1.4330598728466428
2025-08-26 19:40:36,988 - root - INFO - TRAINER_LOGS - loss: 1.3164 grad_norm: 1.7820152044296265 learning_rate: 5.354155547312578e-06 epoch: 1.4353675562786297
2025-08-26 19:41:20,044 - root - INFO - TRAINER_LOGS - loss: 1.3623 grad_norm: 1.6267344951629639 learning_rate: 5.342083436666274e-06 epoch: 1.4376752397106165
2025-08-26 19:42:02,830 - root - INFO - TRAINER_LOGS - loss: 1.3326 grad_norm: 1.4163271188735962 learning_rate: 5.330009322153346e-06 epoch: 1.4399829231426033
2025-08-26 19:42:45,742 - root - INFO - TRAINER_LOGS - loss: 1.3362 grad_norm: 1.7294559478759766 learning_rate: 5.3179332745019066e-06 epoch: 1.44229060657459
2025-08-26 19:43:28,593 - root - INFO - TRAINER_LOGS - loss: 1.3146 grad_norm: 1.3484338521957397 learning_rate: 5.305855364451387e-06 epoch: 1.444598290006577
2025-08-26 19:44:11,618 - root - INFO - TRAINER_LOGS - loss: 1.3369 grad_norm: 1.6859561204910278 learning_rate: 5.293775662752132e-06 epoch: 1.4469059734385636
2025-08-26 19:44:54,211 - root - INFO - TRAINER_LOGS - loss: 1.325 grad_norm: 1.3987911939620972 learning_rate: 5.281694240164984e-06 epoch: 1.4492136568705505
2025-08-26 19:45:37,058 - root - INFO - TRAINER_LOGS - loss: 1.3167 grad_norm: 1.6584659814834595 learning_rate: 5.2696111674608595e-06 epoch: 1.4515213403025373
2025-08-26 19:46:20,355 - root - INFO - TRAINER_LOGS - loss: 1.3646 grad_norm: 1.6789207458496094 learning_rate: 5.257526515420346e-06 epoch: 1.4538290237345242
2025-08-26 19:47:03,317 - root - INFO - TRAINER_LOGS - loss: 1.3046 grad_norm: 2.0503427982330322 learning_rate: 5.245440354833281e-06 epoch: 1.456136707166511
2025-08-26 19:47:45,805 - root - INFO - TRAINER_LOGS - loss: 1.3025 grad_norm: 1.4793339967727661 learning_rate: 5.2333527564983365e-06 epoch: 1.4584443905984976
2025-08-26 19:48:29,247 - root - INFO - TRAINER_LOGS - loss: 1.3526 grad_norm: 1.9644734859466553 learning_rate: 5.221263791222613e-06 epoch: 1.4607520740304845
2025-08-26 19:49:12,085 - root - INFO - TRAINER_LOGS - loss: 1.3583 grad_norm: 1.667043685913086 learning_rate: 5.2091735298212095e-06 epoch: 1.4630597574624713
2025-08-26 19:49:54,118 - root - INFO - TRAINER_LOGS - loss: 1.294 grad_norm: 1.7221484184265137 learning_rate: 5.197082043116825e-06 epoch: 1.4653674408944581
2025-08-26 19:50:36,937 - root - INFO - TRAINER_LOGS - loss: 1.3462 grad_norm: 1.7707490921020508 learning_rate: 5.1849894019393344e-06 epoch: 1.467675124326445
2025-08-26 19:51:19,493 - root - INFO - TRAINER_LOGS - loss: 1.3024 grad_norm: 1.6015129089355469 learning_rate: 5.172895677125371e-06 epoch: 1.4699828077584316
2025-08-26 19:52:01,990 - root - INFO - TRAINER_LOGS - loss: 1.3101 grad_norm: 1.5235953330993652 learning_rate: 5.160800939517921e-06 epoch: 1.4722904911904184
2025-08-26 19:52:44,542 - root - INFO - TRAINER_LOGS - loss: 1.3627 grad_norm: 1.6029068231582642 learning_rate: 5.1487052599659005e-06 epoch: 1.4745981746224053
2025-08-26 19:53:27,000 - root - INFO - TRAINER_LOGS - loss: 1.3384 grad_norm: 2.0530409812927246 learning_rate: 5.136608709323745e-06 epoch: 1.4769058580543921
2025-08-26 19:56:25,124 - root - INFO - TRAINER_LOGS - eval_loss: 1.3157286643981934 eval_runtime: 178.1199 eval_samples_per_second: 28.071 eval_steps_per_second: 1.173 epoch: 1.4769058580543921
2025-08-26 19:57:08,556 - root - INFO - TRAINER_LOGS - loss: 1.3291 grad_norm: 1.653455376625061 learning_rate: 5.124511358450992e-06 epoch: 1.479213541486379
2025-08-26 19:57:51,142 - root - INFO - TRAINER_LOGS - loss: 1.3223 grad_norm: 1.5709984302520752 learning_rate: 5.112413278211866e-06 epoch: 1.4815212249183656
2025-08-26 19:58:34,458 - root - INFO - TRAINER_LOGS - loss: 1.3005 grad_norm: 1.7191838026046753 learning_rate: 5.100314539474863e-06 epoch: 1.4838289083503524
2025-08-26 19:59:16,352 - root - INFO - TRAINER_LOGS - loss: 1.3163 grad_norm: 1.935687780380249 learning_rate: 5.088215213112341e-06 epoch: 1.4861365917823393
2025-08-26 19:59:59,728 - root - INFO - TRAINER_LOGS - loss: 1.3119 grad_norm: 1.8070385456085205 learning_rate: 5.076115370000096e-06 epoch: 1.488444275214326
2025-08-26 20:00:42,484 - root - INFO - TRAINER_LOGS - loss: 1.3168 grad_norm: 1.796399474143982 learning_rate: 5.064015081016951e-06 epoch: 1.490751958646313
2025-08-26 20:01:24,986 - root - INFO - TRAINER_LOGS - loss: 1.3127 grad_norm: 1.7229018211364746 learning_rate: 5.051914417044345e-06 epoch: 1.4930596420782998
2025-08-26 20:02:07,805 - root - INFO - TRAINER_LOGS - loss: 1.3307 grad_norm: 1.7965140342712402 learning_rate: 5.0398134489659065e-06 epoch: 1.4953673255102866
2025-08-26 20:02:51,125 - root - INFO - TRAINER_LOGS - loss: 1.2985 grad_norm: 1.5418659448623657 learning_rate: 5.027712247667051e-06 epoch: 1.4976750089422732
2025-08-26 20:03:33,854 - root - INFO - TRAINER_LOGS - loss: 1.3283 grad_norm: nan learning_rate: 5.015610884034561e-06 epoch: 1.49998269237426
2025-08-26 20:04:16,994 - root - INFO - TRAINER_LOGS - loss: 1.3463 grad_norm: 1.7440615892410278 learning_rate: 5.003751458495398e-06 epoch: 1.502290375806247
2025-08-26 20:04:59,792 - root - INFO - TRAINER_LOGS - loss: 1.3392 grad_norm: 1.8325858116149902 learning_rate: 4.991649982575811e-06 epoch: 1.5045980592382338
2025-08-26 20:05:43,287 - root - INFO - TRAINER_LOGS - loss: 1.3338 grad_norm: 1.6905903816223145 learning_rate: 4.979548555569206e-06 epoch: 1.5069057426702206
2025-08-26 20:06:26,070 - root - INFO - TRAINER_LOGS - loss: 1.3184 grad_norm: 1.6803754568099976 learning_rate: 4.967447248363685e-06 epoch: 1.5092134261022072
2025-08-26 20:07:08,708 - root - INFO - TRAINER_LOGS - loss: 1.32 grad_norm: 1.9321707487106323 learning_rate: 4.955346131846651e-06 epoch: 1.511521109534194
2025-08-26 20:07:52,184 - root - INFO - TRAINER_LOGS - loss: 1.3279 grad_norm: 1.6525858640670776 learning_rate: 4.943245276904386e-06 epoch: 1.513828792966181
2025-08-26 20:08:35,375 - root - INFO - TRAINER_LOGS - loss: 1.326 grad_norm: 1.8192074298858643 learning_rate: 4.9311447544216424e-06 epoch: 1.5161364763981677
2025-08-26 20:09:18,364 - root - INFO - TRAINER_LOGS - loss: 1.3332 grad_norm: 1.6635035276412964 learning_rate: 4.919044635281223e-06 epoch: 1.5184441598301546
2025-08-26 20:10:01,871 - root - INFO - TRAINER_LOGS - loss: 1.3128 grad_norm: 1.7675615549087524 learning_rate: 4.906944990363568e-06 epoch: 1.5207518432621412
2025-08-26 20:10:45,014 - root - INFO - TRAINER_LOGS - loss: 1.3321 grad_norm: 1.6585367918014526 learning_rate: 4.8948458905463425e-06 epoch: 1.5230595266941283
2025-08-26 20:13:43,337 - root - INFO - TRAINER_LOGS - eval_loss: 1.3168963193893433 eval_runtime: 178.3191 eval_samples_per_second: 28.04 eval_steps_per_second: 1.172 epoch: 1.5230595266941283
2025-08-26 20:14:26,184 - root - INFO - TRAINER_LOGS - loss: 1.3125 grad_norm: 1.5624226331710815 learning_rate: 4.882747406704014e-06 epoch: 1.5253672101261149
2025-08-26 20:15:09,026 - root - INFO - TRAINER_LOGS - loss: 1.3174 grad_norm: 1.6386594772338867 learning_rate: 4.870649609707447e-06 epoch: 1.5276748935581017
2025-08-26 20:15:51,749 - root - INFO - TRAINER_LOGS - loss: 1.3118 grad_norm: 1.796095848083496 learning_rate: 4.858552570423479e-06 epoch: 1.5299825769900885
2025-08-26 20:16:34,201 - root - INFO - TRAINER_LOGS - loss: 1.3098 grad_norm: 1.777958631515503 learning_rate: 4.846456359714508e-06 epoch: 1.5322902604220752
2025-08-26 20:17:17,732 - root - INFO - TRAINER_LOGS - loss: 1.3154 grad_norm: 1.549810528755188 learning_rate: 4.834361048438084e-06 epoch: 1.5345979438540622
2025-08-26 20:18:00,864 - root - INFO - TRAINER_LOGS - loss: 1.2901 grad_norm: 1.6462273597717285 learning_rate: 4.822266707446481e-06 epoch: 1.5369056272860488
2025-08-26 20:18:43,600 - root - INFO - TRAINER_LOGS - loss: 1.318 grad_norm: 1.5385078191757202 learning_rate: 4.810173407586296e-06 epoch: 1.5392133107180357
2025-08-26 20:19:26,290 - root - INFO - TRAINER_LOGS - loss: 1.34 grad_norm: 1.6766544580459595 learning_rate: 4.79808121969802e-06 epoch: 1.5415209941500225
2025-08-26 20:20:08,647 - root - INFO - TRAINER_LOGS - loss: 1.3429 grad_norm: 1.6944488286972046 learning_rate: 4.785990214615637e-06 epoch: 1.5438286775820091
2025-08-26 20:20:52,402 - root - INFO - TRAINER_LOGS - loss: 1.3287 grad_norm: 1.9097838401794434 learning_rate: 4.773900463166197e-06 epoch: 1.5461363610139962
2025-08-26 20:21:35,379 - root - INFO - TRAINER_LOGS - loss: 1.3497 grad_norm: 1.6020125150680542 learning_rate: 4.7618120361694124e-06 epoch: 1.5484440444459828
2025-08-26 20:22:18,424 - root - INFO - TRAINER_LOGS - loss: 1.3128 grad_norm: 1.7188425064086914 learning_rate: 4.749725004437231e-06 epoch: 1.5507517278779697
2025-08-26 20:23:00,986 - root - INFO - TRAINER_LOGS - loss: 1.3678 grad_norm: 1.8802145719528198 learning_rate: 4.737639438773431e-06 epoch: 1.5530594113099565
2025-08-26 20:23:44,311 - root - INFO - TRAINER_LOGS - loss: 1.3424 grad_norm: 1.562835454940796 learning_rate: 4.7255554099732015e-06 epoch: 1.5553670947419433
2025-08-26 20:24:27,465 - root - INFO - TRAINER_LOGS - loss: 1.3052 grad_norm: 1.507915735244751 learning_rate: 4.7134729888227296e-06 epoch: 1.5576747781739302
2025-08-26 20:25:10,673 - root - INFO - TRAINER_LOGS - loss: 1.326 grad_norm: 1.9504438638687134 learning_rate: 4.7013922460987814e-06 epoch: 1.5599824616059168
2025-08-26 20:25:53,516 - root - INFO - TRAINER_LOGS - loss: 1.3295 grad_norm: 1.7027816772460938 learning_rate: 4.6893132525683e-06 epoch: 1.5622901450379039
2025-08-26 20:26:35,975 - root - INFO - TRAINER_LOGS - loss: 1.3163 grad_norm: 1.7424260377883911 learning_rate: 4.677236078987973e-06 epoch: 1.5645978284698905
2025-08-26 20:27:19,752 - root - INFO - TRAINER_LOGS - loss: 1.3428 grad_norm: 1.6165589094161987 learning_rate: 4.66516079610383e-06 epoch: 1.5669055119018773
2025-08-26 20:28:02,499 - root - INFO - TRAINER_LOGS - loss: 1.3395 grad_norm: 1.6168560981750488 learning_rate: 4.653087474650826e-06 epoch: 1.5692131953338642
2025-08-26 20:31:00,485 - root - INFO - TRAINER_LOGS - eval_loss: 1.3136907815933228 eval_runtime: 177.9818 eval_samples_per_second: 28.093 eval_steps_per_second: 1.174 epoch: 1.5692131953338642
2025-08-26 20:31:43,643 - root - INFO - TRAINER_LOGS - loss: 1.3215 grad_norm: 1.827962875366211 learning_rate: 4.641016185352426e-06 epoch: 1.5715208787658508
2025-08-26 20:32:26,539 - root - INFO - TRAINER_LOGS - loss: 1.3562 grad_norm: 1.6761964559555054 learning_rate: 4.6289469989201915e-06 epoch: 1.5738285621978378
2025-08-26 20:33:09,072 - root - INFO - TRAINER_LOGS - loss: 1.3474 grad_norm: 1.6130446195602417 learning_rate: 4.616879986053365e-06 epoch: 1.5761362456298245
2025-08-26 20:33:52,411 - root - INFO - TRAINER_LOGS - loss: 1.3272 grad_norm: 1.7368495464324951 learning_rate: 4.604815217438454e-06 epoch: 1.5784439290618113
2025-08-26 20:34:35,619 - root - INFO - TRAINER_LOGS - loss: 1.295 grad_norm: 1.6203514337539673 learning_rate: 4.592752763748825e-06 epoch: 1.5807516124937981
2025-08-26 20:35:18,945 - root - INFO - TRAINER_LOGS - loss: 1.3131 grad_norm: 1.9444739818572998 learning_rate: 4.5809338731706754e-06 epoch: 1.5830592959257848
2025-08-26 20:36:01,292 - root - INFO - TRAINER_LOGS - loss: 1.3574 grad_norm: 1.875009536743164 learning_rate: 4.5688762114801895e-06 epoch: 1.5853669793577718
2025-08-26 20:36:45,069 - root - INFO - TRAINER_LOGS - loss: 1.336 grad_norm: 2.1850054264068604 learning_rate: 4.556821075239571e-06 epoch: 1.5876746627897584
2025-08-26 20:37:27,842 - root - INFO - TRAINER_LOGS - loss: 1.3489 grad_norm: 1.7041040658950806 learning_rate: 4.545009559971107e-06 epoch: 1.5899823462217453
2025-08-26 20:38:10,349 - root - INFO - TRAINER_LOGS - loss: 1.3308 grad_norm: 1.976761817932129 learning_rate: 4.532959632440669e-06 epoch: 1.5922900296537321
2025-08-26 20:38:52,903 - root - INFO - TRAINER_LOGS - loss: 1.3482 grad_norm: 1.777321457862854 learning_rate: 4.520912440753315e-06 epoch: 1.5945977130857187
2025-08-26 20:39:35,379 - root - INFO - TRAINER_LOGS - loss: 1.3351 grad_norm: 1.6076898574829102 learning_rate: 4.508868055479447e-06 epoch: 1.5969053965177058
2025-08-26 20:40:19,147 - root - INFO - TRAINER_LOGS - loss: 1.356 grad_norm: 1.628836989402771 learning_rate: 4.496826547173025e-06 epoch: 1.5992130799496924
2025-08-26 20:41:02,665 - root - INFO - TRAINER_LOGS - loss: 1.3203 grad_norm: 1.7384283542633057 learning_rate: 4.484787986371158e-06 epoch: 1.6015207633816793
2025-08-26 20:41:45,693 - root - INFO - TRAINER_LOGS - loss: 1.3063 grad_norm: 1.6173510551452637 learning_rate: 4.47275244359369e-06 epoch: 1.603828446813666
2025-08-26 20:42:28,258 - root - INFO - TRAINER_LOGS - loss: 1.3364 grad_norm: 1.7229722738265991 learning_rate: 4.4607199893427814e-06 epoch: 1.606136130245653
2025-08-26 20:43:11,392 - root - INFO - TRAINER_LOGS - loss: 1.3147 grad_norm: 1.8235052824020386 learning_rate: 4.4486906941025085e-06 epoch: 1.6084438136776398
2025-08-26 20:43:54,268 - root - INFO - TRAINER_LOGS - loss: 1.3091 grad_norm: 1.8003023862838745 learning_rate: 4.436664628338435e-06 epoch: 1.6107514971096264
2025-08-26 20:44:37,051 - root - INFO - TRAINER_LOGS - loss: 1.3425 grad_norm: 1.7423425912857056 learning_rate: 4.424641862497211e-06 epoch: 1.6130591805416135
2025-08-26 20:45:19,125 - root - INFO - TRAINER_LOGS - loss: 1.3594 grad_norm: 1.6243937015533447 learning_rate: 4.412622467006156e-06 epoch: 1.6153668639736
2025-08-26 20:48:17,168 - root - INFO - TRAINER_LOGS - eval_loss: 1.3146607875823975 eval_runtime: 178.0383 eval_samples_per_second: 28.084 eval_steps_per_second: 1.174 epoch: 1.6153668639736
2025-08-26 20:49:00,350 - root - INFO - TRAINER_LOGS - loss: 1.324 grad_norm: 1.7786065340042114 learning_rate: 4.400606512272841e-06 epoch: 1.617674547405587
2025-08-26 20:49:43,082 - root - INFO - TRAINER_LOGS - loss: 1.3439 grad_norm: 1.6956725120544434 learning_rate: 4.388594068684692e-06 epoch: 1.6199822308375738
2025-08-26 20:50:25,816 - root - INFO - TRAINER_LOGS - loss: 1.3254 grad_norm: 1.8332089185714722 learning_rate: 4.37658520660856e-06 epoch: 1.6222899142695604
2025-08-26 20:51:08,224 - root - INFO - TRAINER_LOGS - loss: 1.3485 grad_norm: 1.9757860898971558 learning_rate: 4.3645799963903166e-06 epoch: 1.6245975977015474
2025-08-26 20:51:51,997 - root - INFO - TRAINER_LOGS - loss: 1.3377 grad_norm: 1.4898041486740112 learning_rate: 4.3525785083544435e-06 epoch: 1.626905281133534
2025-08-26 20:52:35,079 - root - INFO - TRAINER_LOGS - loss: 1.307 grad_norm: 1.6884372234344482 learning_rate: 4.3405808128036164e-06 epoch: 1.629212964565521
2025-08-26 20:53:17,934 - root - INFO - TRAINER_LOGS - loss: 1.337 grad_norm: 1.6236059665679932 learning_rate: 4.328586980018298e-06 epoch: 1.6315206479975077
2025-08-26 20:54:00,995 - root - INFO - TRAINER_LOGS - loss: 1.3181 grad_norm: 1.6417412757873535 learning_rate: 4.316597080256321e-06 epoch: 1.6338283314294944
2025-08-26 20:54:43,124 - root - INFO - TRAINER_LOGS - loss: 1.3144 grad_norm: 1.6679621934890747 learning_rate: 4.304611183752481e-06 epoch: 1.6361360148614814
2025-08-26 20:55:25,927 - root - INFO - TRAINER_LOGS - loss: 1.3204 grad_norm: 1.6182360649108887 learning_rate: 4.2926293607181204e-06 epoch: 1.638443698293468
2025-08-26 20:56:09,380 - root - INFO - TRAINER_LOGS - loss: 1.3519 grad_norm: 1.7049013376235962 learning_rate: 4.280651681340724e-06 epoch: 1.6407513817254549
2025-08-26 20:56:52,000 - root - INFO - TRAINER_LOGS - loss: 1.3002 grad_norm: 1.938466191291809 learning_rate: 4.2686782157834984e-06 epoch: 1.6430590651574417
2025-08-26 20:57:34,199 - root - INFO - TRAINER_LOGS - loss: 1.323 grad_norm: 1.7099848985671997 learning_rate: 4.256709034184974e-06 epoch: 1.6453667485894286
2025-08-26 20:58:17,459 - root - INFO - TRAINER_LOGS - loss: 1.3086 grad_norm: 1.8792611360549927 learning_rate: 4.244744206658579e-06 epoch: 1.6476744320214154
2025-08-26 20:58:59,775 - root - INFO - TRAINER_LOGS - loss: 1.314 grad_norm: 1.7552564144134521 learning_rate: 4.23278380329224e-06 epoch: 1.649982115453402
2025-08-26 20:59:43,085 - root - INFO - TRAINER_LOGS - loss: 1.2868 grad_norm: 1.76216721534729 learning_rate: 4.2208278941479666e-06 epoch: 1.6522897988853888
2025-08-26 21:00:25,734 - root - INFO - TRAINER_LOGS - loss: 1.3199 grad_norm: 1.726831316947937 learning_rate: 4.2088765492614435e-06 epoch: 1.6545974823173757
2025-08-26 21:01:08,559 - root - INFO - TRAINER_LOGS - loss: 1.3182 grad_norm: 1.7423863410949707 learning_rate: 4.196929838641617e-06 epoch: 1.6569051657493625
2025-08-26 21:01:51,773 - root - INFO - TRAINER_LOGS - loss: 1.2922 grad_norm: 1.4764485359191895 learning_rate: 4.184987832270286e-06 epoch: 1.6592128491813494
2025-08-26 21:02:34,759 - root - INFO - TRAINER_LOGS - loss: 1.3325 grad_norm: 1.6078914403915405 learning_rate: 4.173050600101694e-06 epoch: 1.661520532613336
2025-08-26 21:05:32,648 - root - INFO - TRAINER_LOGS - eval_loss: 1.313714861869812 eval_runtime: 177.8845 eval_samples_per_second: 28.108 eval_steps_per_second: 1.175 epoch: 1.661520532613336
2025-08-26 21:06:15,234 - root - INFO - TRAINER_LOGS - loss: 1.3452 grad_norm: 1.5051835775375366 learning_rate: 4.16111821206212e-06 epoch: 1.663828216045323
2025-08-26 21:06:58,667 - root - INFO - TRAINER_LOGS - loss: 1.347 grad_norm: 1.6766620874404907 learning_rate: 4.149190738049461e-06 epoch: 1.6661358994773097
2025-08-26 21:07:41,843 - root - INFO - TRAINER_LOGS - loss: 1.3091 grad_norm: 1.5415503978729248 learning_rate: 4.137268247932835e-06 epoch: 1.6684435829092965
2025-08-26 21:08:24,897 - root - INFO - TRAINER_LOGS - loss: 1.3117 grad_norm: 1.6696401834487915 learning_rate: 4.125350811552162e-06 epoch: 1.6707512663412833
2025-08-26 21:09:08,573 - root - INFO - TRAINER_LOGS - loss: 1.3186 grad_norm: 1.5988136529922485 learning_rate: 4.11343849871776e-06 epoch: 1.67305894977327
2025-08-26 21:09:50,545 - root - INFO - TRAINER_LOGS - loss: 1.3292 grad_norm: 1.7254589796066284 learning_rate: 4.10153137920993e-06 epoch: 1.675366633205257
2025-08-26 21:10:32,878 - root - INFO - TRAINER_LOGS - loss: 1.3492 grad_norm: 2.213719367980957 learning_rate: 4.089629522778556e-06 epoch: 1.6776743166372436
2025-08-26 21:11:15,248 - root - INFO - TRAINER_LOGS - loss: 1.3394 grad_norm: 1.9578920602798462 learning_rate: 4.077732999142689e-06 epoch: 1.6799820000692305
2025-08-26 21:11:58,456 - root - INFO - TRAINER_LOGS - loss: 1.3613 grad_norm: 1.5145059823989868 learning_rate: 4.065841877990144e-06 epoch: 1.6822896835012173
2025-08-26 21:12:41,028 - root - INFO - TRAINER_LOGS - loss: 1.3247 grad_norm: 1.543886423110962 learning_rate: 4.053956228977084e-06 epoch: 1.684597366933204
2025-08-26 21:13:23,919 - root - INFO - TRAINER_LOGS - loss: 1.3041 grad_norm: 1.760035514831543 learning_rate: 4.042076121727622e-06 epoch: 1.686905050365191
2025-08-26 21:14:07,334 - root - INFO - TRAINER_LOGS - loss: 1.3179 grad_norm: 1.623464822769165 learning_rate: 4.030201625833409e-06 epoch: 1.6892127337971776
2025-08-26 21:14:50,505 - root - INFO - TRAINER_LOGS - loss: 1.3227 grad_norm: 1.6033416986465454 learning_rate: 4.018332810853221e-06 epoch: 1.6915204172291645
2025-08-26 21:15:34,586 - root - INFO - TRAINER_LOGS - loss: 1.3023 grad_norm: 1.8292874097824097 learning_rate: 4.006469746312559e-06 epoch: 1.6938281006611513
2025-08-26 21:16:17,259 - root - INFO - TRAINER_LOGS - loss: 1.3051 grad_norm: 2.0747454166412354 learning_rate: 3.994612501703237e-06 epoch: 1.6961357840931381
2025-08-26 21:16:59,177 - root - INFO - TRAINER_LOGS - loss: 1.311 grad_norm: 1.5300101041793823 learning_rate: 3.982761146482982e-06 epoch: 1.698443467525125
2025-08-26 21:17:41,831 - root - INFO - TRAINER_LOGS - loss: 1.2875 grad_norm: 1.5678298473358154 learning_rate: 3.970915750075018e-06 epoch: 1.7007511509571116
2025-08-26 21:18:24,797 - root - INFO - TRAINER_LOGS - loss: 1.3193 grad_norm: 1.7061638832092285 learning_rate: 3.9590763818676604e-06 epoch: 1.7030588343890987
2025-08-26 21:19:07,714 - root - INFO - TRAINER_LOGS - loss: 1.3405 grad_norm: 1.4456874132156372 learning_rate: 3.9472431112139185e-06 epoch: 1.7053665178210853
2025-08-26 21:19:50,701 - root - INFO - TRAINER_LOGS - loss: 1.2969 grad_norm: 1.7705572843551636 learning_rate: 3.9354160074310786e-06 epoch: 1.7076742012530721
2025-08-26 21:22:48,873 - root - INFO - TRAINER_LOGS - eval_loss: 1.3121625185012817 eval_runtime: 178.1676 eval_samples_per_second: 28.063 eval_steps_per_second: 1.173 epoch: 1.7076742012530721
2025-08-26 21:23:32,477 - root - INFO - TRAINER_LOGS - loss: 1.3802 grad_norm: 1.7048048973083496 learning_rate: 3.923595139800305e-06 epoch: 1.709981884685059
2025-08-26 21:24:15,457 - root - INFO - TRAINER_LOGS - loss: 1.3097 grad_norm: 1.5279881954193115 learning_rate: 3.911780577566232e-06 epoch: 1.7122895681170456
2025-08-26 21:24:58,387 - root - INFO - TRAINER_LOGS - loss: 1.3216 grad_norm: 1.6184333562850952 learning_rate: 3.899972389936555e-06 epoch: 1.7145972515490326
2025-08-26 21:25:40,399 - root - INFO - TRAINER_LOGS - loss: 1.2922 grad_norm: 1.759874939918518 learning_rate: 3.888170646081631e-06 epoch: 1.7169049349810193
2025-08-26 21:26:22,562 - root - INFO - TRAINER_LOGS - loss: 1.3658 grad_norm: 1.7050981521606445 learning_rate: 3.8763754151340685e-06 epoch: 1.719212618413006
2025-08-26 21:27:06,126 - root - INFO - TRAINER_LOGS - loss: 1.3136 grad_norm: 1.9183934926986694 learning_rate: 3.864586766188325e-06 epoch: 1.721520301844993
2025-08-26 21:27:48,781 - root - INFO - TRAINER_LOGS - loss: 1.3698 grad_norm: 2.050564765930176 learning_rate: 3.852804768300305e-06 epoch: 1.7238279852769796
2025-08-26 21:28:32,013 - root - INFO - TRAINER_LOGS - loss: 1.3707 grad_norm: 1.7646623849868774 learning_rate: 3.841029490486947e-06 epoch: 1.7261356687089666
2025-08-26 21:29:15,877 - root - INFO - TRAINER_LOGS - loss: 1.3072 grad_norm: 1.555133581161499 learning_rate: 3.829261001725826e-06 epoch: 1.7284433521409532
2025-08-26 21:29:58,583 - root - INFO - TRAINER_LOGS - loss: 1.376 grad_norm: 1.5695538520812988 learning_rate: 3.817499370954751e-06 epoch: 1.73075103557294
2025-08-26 21:30:41,468 - root - INFO - TRAINER_LOGS - loss: 1.346 grad_norm: 1.7964667081832886 learning_rate: 3.805744667071356e-06 epoch: 1.733058719004927
2025-08-26 21:31:24,194 - root - INFO - TRAINER_LOGS - loss: 1.3158 grad_norm: 1.6851634979248047 learning_rate: 3.7939969589326966e-06 epoch: 1.7353664024369138
2025-08-26 21:32:07,176 - root - INFO - TRAINER_LOGS - loss: 1.3765 grad_norm: 2.0204436779022217 learning_rate: 3.78225631535485e-06 epoch: 1.7376740858689006
2025-08-26 21:32:50,178 - root - INFO - TRAINER_LOGS - loss: 1.3324 grad_norm: 1.597397804260254 learning_rate: 3.7705228051125116e-06 epoch: 1.7399817693008872
2025-08-26 21:33:32,719 - root - INFO - TRAINER_LOGS - loss: 1.3058 grad_norm: 1.571825385093689 learning_rate: 3.7587964969385895e-06 epoch: 1.742289452732874
2025-08-26 21:34:16,131 - root - INFO - TRAINER_LOGS - loss: 1.3061 grad_norm: 1.6894190311431885 learning_rate: 3.7470774595238024e-06 epoch: 1.744597136164861
2025-08-26 21:34:59,625 - root - INFO - TRAINER_LOGS - loss: 1.3435 grad_norm: 1.8905094861984253 learning_rate: 3.73536576151628e-06 epoch: 1.7469048195968477
2025-08-26 21:35:42,431 - root - INFO - TRAINER_LOGS - loss: 1.3417 grad_norm: 1.6521592140197754 learning_rate: 3.7236614715211613e-06 epoch: 1.7492125030288346
2025-08-26 21:36:24,950 - root - INFO - TRAINER_LOGS - loss: 1.3334 grad_norm: 1.770266056060791 learning_rate: 3.7119646581001834e-06 epoch: 1.7515201864608212
2025-08-26 21:37:06,969 - root - INFO - TRAINER_LOGS - loss: 1.3038 grad_norm: 1.7462780475616455 learning_rate: 3.700275389771295e-06 epoch: 1.7538278698928083
2025-08-26 21:40:05,104 - root - INFO - TRAINER_LOGS - eval_loss: 1.3121023178100586 eval_runtime: 178.131 eval_samples_per_second: 28.069 eval_steps_per_second: 1.173 epoch: 1.7538278698928083
2025-08-26 21:40:48,914 - root - INFO - TRAINER_LOGS - loss: 1.3531 grad_norm: 1.5437802076339722 learning_rate: 3.6885937350082403e-06 epoch: 1.7561355533247949
2025-08-26 21:41:32,111 - root - INFO - TRAINER_LOGS - loss: 1.3221 grad_norm: 1.7639644145965576 learning_rate: 3.676919762240168e-06 epoch: 1.7584432367567817
2025-08-26 21:42:14,637 - root - INFO - TRAINER_LOGS - loss: 1.3256 grad_norm: 1.7766462564468384 learning_rate: 3.665253539851226e-06 epoch: 1.7607509201887686
2025-08-26 21:42:57,074 - root - INFO - TRAINER_LOGS - loss: 1.2997 grad_norm: 1.7870949506759644 learning_rate: 3.6535951361801624e-06 epoch: 1.7630586036207552
2025-08-26 21:43:39,875 - root - INFO - TRAINER_LOGS - loss: 1.2959 grad_norm: 1.7294039726257324 learning_rate: 3.6419446195199228e-06 epoch: 1.7653662870527422
2025-08-26 21:44:22,268 - root - INFO - TRAINER_LOGS - loss: 1.2931 grad_norm: 1.7306606769561768 learning_rate: 3.630302058117255e-06 epoch: 1.7676739704847289
2025-08-26 21:45:05,238 - root - INFO - TRAINER_LOGS - loss: 1.298 grad_norm: 1.7012319564819336 learning_rate: 3.6186675201723044e-06 epoch: 1.7699816539167157
2025-08-26 21:45:48,301 - root - INFO - TRAINER_LOGS - loss: 1.3233 grad_norm: 1.5448837280273438 learning_rate: 3.607041073838214e-06 epoch: 1.7722893373487025
2025-08-26 21:46:31,366 - root - INFO - TRAINER_LOGS - loss: 1.3172 grad_norm: 1.8770692348480225 learning_rate: 3.5954227872207348e-06 epoch: 1.7745970207806891
2025-08-26 21:47:15,219 - root - INFO - TRAINER_LOGS - loss: 1.3565 grad_norm: 1.6974108219146729 learning_rate: 3.5838127283778117e-06 epoch: 1.7769047042126762
2025-08-26 21:47:58,063 - root - INFO - TRAINER_LOGS - loss: 1.3031 grad_norm: 1.7480173110961914 learning_rate: 3.5722109653191973e-06 epoch: 1.7792123876446628
2025-08-26 21:48:40,256 - root - INFO - TRAINER_LOGS - loss: 1.3422 grad_norm: 1.5455751419067383 learning_rate: 3.5606175660060464e-06 epoch: 1.7815200710766497
2025-08-26 21:49:22,839 - root - INFO - TRAINER_LOGS - loss: 1.3462 grad_norm: 1.5931490659713745 learning_rate: 3.5490325983505227e-06 epoch: 1.7838277545086365
2025-08-26 21:50:05,540 - root - INFO - TRAINER_LOGS - loss: 1.2945 grad_norm: 1.877476692199707 learning_rate: 3.5374561302153953e-06 epoch: 1.7861354379406233
2025-08-26 21:50:48,130 - root - INFO - TRAINER_LOGS - loss: 1.3129 grad_norm: 1.5592645406723022 learning_rate: 3.525888229413649e-06 epoch: 1.7884431213726102
2025-08-26 21:51:29,959 - root - INFO - TRAINER_LOGS - loss: 1.3132 grad_norm: 1.607991337776184 learning_rate: 3.514328963708079e-06 epoch: 1.7907508048045968
2025-08-26 21:52:12,659 - root - INFO - TRAINER_LOGS - loss: 1.3156 grad_norm: 2.103024482727051 learning_rate: 3.5027784008108995e-06 epoch: 1.7930584882365839
2025-08-26 21:52:56,257 - root - INFO - TRAINER_LOGS - loss: 1.3222 grad_norm: 1.5889198780059814 learning_rate: 3.491236608383345e-06 epoch: 1.7953661716685705
2025-08-26 21:53:38,943 - root - INFO - TRAINER_LOGS - loss: 1.3134 grad_norm: 1.470710039138794 learning_rate: 3.4797036540352724e-06 epoch: 1.7976738551005573
2025-08-26 21:54:21,560 - root - INFO - TRAINER_LOGS - loss: 1.2911 grad_norm: 1.7223540544509888 learning_rate: 3.468179605324766e-06 epoch: 1.7999815385325442
2025-08-26 21:57:19,774 - root - INFO - TRAINER_LOGS - eval_loss: 1.3102220296859741 eval_runtime: 178.2097 eval_samples_per_second: 28.057 eval_steps_per_second: 1.173 epoch: 1.7999815385325442
2025-08-26 21:58:03,356 - root - INFO - TRAINER_LOGS - loss: 1.3256 grad_norm: 1.6227473020553589 learning_rate: 3.4566645297577496e-06 epoch: 1.8022892219645308
2025-08-26 21:58:46,508 - root - INFO - TRAINER_LOGS - loss: 1.2953 grad_norm: 1.699055790901184 learning_rate: 3.4451584947875755e-06 epoch: 1.8045969053965178
2025-08-26 21:59:30,417 - root - INFO - TRAINER_LOGS - loss: 1.3241 grad_norm: 1.7872408628463745 learning_rate: 3.43366156781464e-06 epoch: 1.8069045888285045
2025-08-26 22:00:13,640 - root - INFO - TRAINER_LOGS - loss: 1.3292 grad_norm: 1.6456633806228638 learning_rate: 3.422173816185988e-06 epoch: 1.8092122722604913
2025-08-26 22:00:56,867 - root - INFO - TRAINER_LOGS - loss: 1.321 grad_norm: 1.546207070350647 learning_rate: 3.410695307194916e-06 epoch: 1.8115199556924781
2025-08-26 22:01:38,829 - root - INFO - TRAINER_LOGS - loss: 1.3134 grad_norm: 1.5593242645263672 learning_rate: 3.3994554003914336e-06 epoch: 1.8138276391244648
2025-08-26 22:02:22,276 - root - INFO - TRAINER_LOGS - loss: 1.3222 grad_norm: 1.8099740743637085 learning_rate: 3.387995390139165e-06 epoch: 1.8161353225564518
2025-08-26 22:03:05,339 - root - INFO - TRAINER_LOGS - loss: 1.3211 grad_norm: 1.7837198972702026 learning_rate: 3.3765448227358878e-06 epoch: 1.8184430059884384
2025-08-26 22:03:48,460 - root - INFO - TRAINER_LOGS - loss: 1.3245 grad_norm: 1.5695326328277588 learning_rate: 3.3651037652570785e-06 epoch: 1.8207506894204253
2025-08-26 22:04:31,142 - root - INFO - TRAINER_LOGS - loss: 1.3724 grad_norm: 1.7654271125793457 learning_rate: 3.3536722847225056e-06 epoch: 1.8230583728524121
2025-08-26 22:05:14,292 - root - INFO - TRAINER_LOGS - loss: 1.3491 grad_norm: 1.5866557359695435 learning_rate: 3.3422504480958397e-06 epoch: 1.8253660562843987
2025-08-26 22:05:56,726 - root - INFO - TRAINER_LOGS - loss: 1.3364 grad_norm: 1.8638267517089844 learning_rate: 3.3308383222842565e-06 epoch: 1.8276737397163858
2025-08-26 22:06:39,619 - root - INFO - TRAINER_LOGS - loss: 1.3007 grad_norm: 1.8841599225997925 learning_rate: 3.319435974138052e-06 epoch: 1.8299814231483724
2025-08-26 22:07:21,969 - root - INFO - TRAINER_LOGS - loss: 1.3421 grad_norm: 1.6237698793411255 learning_rate: 3.3080434704502428e-06 epoch: 1.8322891065803593
2025-08-26 22:08:04,629 - root - INFO - TRAINER_LOGS - loss: 1.3302 grad_norm: 1.4605414867401123 learning_rate: 3.296660877956177e-06 epoch: 1.834596790012346
2025-08-26 22:08:48,275 - root - INFO - TRAINER_LOGS - loss: 1.3201 grad_norm: 1.6937367916107178 learning_rate: 3.2852882633331482e-06 epoch: 1.836904473444333
2025-08-26 22:09:31,616 - root - INFO - TRAINER_LOGS - loss: 1.3425 grad_norm: 1.5520931482315063 learning_rate: 3.2739256931999998e-06 epoch: 1.8392121568763198
2025-08-26 22:10:15,253 - root - INFO - TRAINER_LOGS - loss: 1.3495 grad_norm: 1.7997045516967773 learning_rate: 3.262573234116734e-06 epoch: 1.8415198403083064
2025-08-26 22:10:58,360 - root - INFO - TRAINER_LOGS - loss: 1.3467 grad_norm: 1.85385262966156 learning_rate: 3.251230952584129e-06 epoch: 1.8438275237402935
2025-08-26 22:11:41,166 - root - INFO - TRAINER_LOGS - loss: 1.2949 grad_norm: 1.8183047771453857 learning_rate: 3.2398989150433415e-06 epoch: 1.84613520717228
2025-08-26 22:14:38,903 - root - INFO - TRAINER_LOGS - eval_loss: 1.3096990585327148 eval_runtime: 177.7324 eval_samples_per_second: 28.132 eval_steps_per_second: 1.176 epoch: 1.84613520717228
2025-08-26 22:15:22,048 - root - INFO - TRAINER_LOGS - loss: 1.3016 grad_norm: 1.5638989210128784 learning_rate: 3.22857718787552e-06 epoch: 1.848442890604267
2025-08-26 22:16:05,551 - root - INFO - TRAINER_LOGS - loss: 1.3304 grad_norm: 1.9518738985061646 learning_rate: 3.217265837401419e-06 epoch: 1.8507505740362538
2025-08-26 22:16:48,313 - root - INFO - TRAINER_LOGS - loss: 1.3259 grad_norm: 1.4816621541976929 learning_rate: 3.2059649298810058e-06 epoch: 1.8530582574682404
2025-08-26 22:17:30,808 - root - INFO - TRAINER_LOGS - loss: 1.2838 grad_norm: 1.5341145992279053 learning_rate: 3.194674531513077e-06 epoch: 1.8553659409002274
2025-08-26 22:18:13,226 - root - INFO - TRAINER_LOGS - loss: 1.3445 grad_norm: 1.871945858001709 learning_rate: 3.183394708434866e-06 epoch: 1.857673624332214
2025-08-26 22:18:55,814 - root - INFO - TRAINER_LOGS - loss: 1.3297 grad_norm: 1.5728551149368286 learning_rate: 3.1721255267216587e-06 epoch: 1.859981307764201
2025-08-26 22:19:38,795 - root - INFO - TRAINER_LOGS - loss: 1.3307 grad_norm: 1.7610692977905273 learning_rate: 3.1608670523864075e-06 epoch: 1.8622889911961877
2025-08-26 22:20:21,993 - root - INFO - TRAINER_LOGS - loss: 1.2799 grad_norm: 1.4566779136657715 learning_rate: 3.149619351379339e-06 epoch: 1.8645966746281744
2025-08-26 22:21:04,670 - root - INFO - TRAINER_LOGS - loss: 1.3326 grad_norm: 2.0139949321746826 learning_rate: 3.1383824895875747e-06 epoch: 1.8669043580601614
2025-08-26 22:21:47,789 - root - INFO - TRAINER_LOGS - loss: 1.3192 grad_norm: 1.7789418697357178 learning_rate: 3.1271565328347427e-06 epoch: 1.869212041492148
2025-08-26 22:22:29,940 - root - INFO - TRAINER_LOGS - loss: 1.3797 grad_norm: 1.8967105150222778 learning_rate: 3.1159415468805863e-06 epoch: 1.8715197249241349
2025-08-26 22:23:12,454 - root - INFO - TRAINER_LOGS - loss: 1.305 grad_norm: 1.8625853061676025 learning_rate: 3.104737597420591e-06 epoch: 1.8738274083561217
2025-08-26 22:23:54,890 - root - INFO - TRAINER_LOGS - loss: 1.3448 grad_norm: 1.4885984659194946 learning_rate: 3.0935447500855842e-06 epoch: 1.8761350917881086
2025-08-26 22:24:37,683 - root - INFO - TRAINER_LOGS - loss: 1.3295 grad_norm: 2.2789201736450195 learning_rate: 3.0823630704413656e-06 epoch: 1.8784427752200954
2025-08-26 22:25:20,589 - root - INFO - TRAINER_LOGS - loss: 1.3251 grad_norm: 2.056306838989258 learning_rate: 3.071192623988312e-06 epoch: 1.880750458652082
2025-08-26 22:26:04,063 - root - INFO - TRAINER_LOGS - loss: 1.3183 grad_norm: 1.5865662097930908 learning_rate: 3.0600334761610017e-06 epoch: 1.8830581420840689
2025-08-26 22:26:46,499 - root - INFO - TRAINER_LOGS - loss: 1.3257 grad_norm: 1.9740089178085327 learning_rate: 3.0488856923278233e-06 epoch: 1.8853658255160557
2025-08-26 22:27:29,518 - root - INFO - TRAINER_LOGS - loss: 1.2868 grad_norm: 1.8166850805282593 learning_rate: 3.037749337790602e-06 epoch: 1.8876735089480425
2025-08-26 22:28:12,620 - root - INFO - TRAINER_LOGS - loss: 1.345 grad_norm: 1.7118302583694458 learning_rate: 3.026624477784209e-06 epoch: 1.8899811923800294
2025-08-26 22:28:55,617 - root - INFO - TRAINER_LOGS - loss: 1.3371 grad_norm: 1.5696334838867188 learning_rate: 3.0155111774761807e-06 epoch: 1.892288875812016
2025-08-26 22:31:53,958 - root - INFO - TRAINER_LOGS - eval_loss: 1.3111032247543335 eval_runtime: 178.3364 eval_samples_per_second: 28.037 eval_steps_per_second: 1.172 epoch: 1.892288875812016
2025-08-26 22:32:36,961 - root - INFO - TRAINER_LOGS - loss: 1.3122 grad_norm: 1.580844521522522 learning_rate: 3.0044095019663456e-06 epoch: 1.894596559244003
2025-08-26 22:33:20,280 - root - INFO - TRAINER_LOGS - loss: 1.3359 grad_norm: 1.723081111907959 learning_rate: 2.99331951628643e-06 epoch: 1.8969042426759897
2025-08-26 22:34:03,092 - root - INFO - TRAINER_LOGS - loss: 1.3378 grad_norm: 2.1113967895507812 learning_rate: 2.982241285399684e-06 epoch: 1.8992119261079765
2025-08-26 22:34:46,084 - root - INFO - TRAINER_LOGS - loss: 1.3016 grad_norm: 1.6543880701065063 learning_rate: 2.9711748742005013e-06 epoch: 1.9015196095399634
2025-08-26 22:35:29,692 - root - INFO - TRAINER_LOGS - loss: 1.3184 grad_norm: 1.7859046459197998 learning_rate: 2.9601203475140385e-06 epoch: 1.90382729297195
2025-08-26 22:36:12,790 - root - INFO - TRAINER_LOGS - loss: 1.3329 grad_norm: 1.6288639307022095 learning_rate: 2.9490777700958328e-06 epoch: 1.906134976403937
2025-08-26 22:36:56,089 - root - INFO - TRAINER_LOGS - loss: 1.3026 grad_norm: 1.8062567710876465 learning_rate: 2.9380472066314245e-06 epoch: 1.9084426598359236
2025-08-26 22:37:39,209 - root - INFO - TRAINER_LOGS - loss: 1.3246 grad_norm: 1.4977490901947021 learning_rate: 2.9270287217359827e-06 epoch: 1.9107503432679105
2025-08-26 22:38:22,995 - root - INFO - TRAINER_LOGS - loss: 1.3275 grad_norm: 1.8693230152130127 learning_rate: 2.9160223799539176e-06 epoch: 1.9130580266998973
2025-08-26 22:39:05,796 - root - INFO - TRAINER_LOGS - loss: 1.3403 grad_norm: 1.7358753681182861 learning_rate: 2.9050282457585053e-06 epoch: 1.915365710131884
2025-08-26 22:39:49,009 - root - INFO - TRAINER_LOGS - loss: 1.3191 grad_norm: 1.6288572549819946 learning_rate: 2.8942659001139682e-06 epoch: 1.917673393563871
2025-08-26 22:40:31,887 - root - INFO - TRAINER_LOGS - loss: 1.3208 grad_norm: 1.8133299350738525 learning_rate: 2.883296126868955e-06 epoch: 1.9199810769958576
2025-08-26 22:41:14,378 - root - INFO - TRAINER_LOGS - loss: 1.2958 grad_norm: 1.583654522895813 learning_rate: 2.8723387529154274e-06 epoch: 1.9222887604278445
2025-08-26 22:41:57,124 - root - INFO - TRAINER_LOGS - loss: 1.333 grad_norm: 1.8868424892425537 learning_rate: 2.8613938424398165e-06 epoch: 1.9245964438598313
2025-08-26 22:42:40,723 - root - INFO - TRAINER_LOGS - loss: 1.3116 grad_norm: 1.793145775794983 learning_rate: 2.850461459555548e-06 epoch: 1.9269041272918181
2025-08-26 22:43:24,010 - root - INFO - TRAINER_LOGS - loss: 1.3608 grad_norm: 1.5690076351165771 learning_rate: 2.8395416683026623e-06 epoch: 1.929211810723805
2025-08-26 22:44:07,680 - root - INFO - TRAINER_LOGS - loss: 1.3183 grad_norm: 1.7385149002075195 learning_rate: 2.8286345326474396e-06 epoch: 1.9315194941557916
2025-08-26 22:44:51,504 - root - INFO - TRAINER_LOGS - loss: 1.3345 grad_norm: 1.6355522871017456 learning_rate: 2.8177401164820282e-06 epoch: 1.9338271775877787
2025-08-26 22:45:34,323 - root - INFO - TRAINER_LOGS - loss: 1.3525 grad_norm: 1.9548909664154053 learning_rate: 2.806858483624063e-06 epoch: 1.9361348610197653
2025-08-26 22:46:17,523 - root - INFO - TRAINER_LOGS - loss: 1.2962 grad_norm: 1.751119613647461 learning_rate: 2.7959896978163036e-06 epoch: 1.9384425444517521
2025-08-26 22:49:15,809 - root - INFO - TRAINER_LOGS - eval_loss: 1.3107078075408936 eval_runtime: 178.2813 eval_samples_per_second: 28.046 eval_steps_per_second: 1.172 epoch: 1.9384425444517521
2025-08-26 22:49:58,931 - root - INFO - TRAINER_LOGS - loss: 1.3373 grad_norm: 1.458788275718689 learning_rate: 2.785133822726248e-06 epoch: 1.940750227883739
2025-08-26 22:50:42,719 - root - INFO - TRAINER_LOGS - loss: 1.334 grad_norm: 1.5375162363052368 learning_rate: 2.774290921945768e-06 epoch: 1.9430579113157256
2025-08-26 22:51:24,501 - root - INFO - TRAINER_LOGS - loss: 1.337 grad_norm: 1.8215081691741943 learning_rate: 2.763461058990732e-06 epoch: 1.9453655947477126
2025-08-26 22:52:07,589 - root - INFO - TRAINER_LOGS - loss: 1.3363 grad_norm: 1.9520739316940308 learning_rate: 2.7526442973006363e-06 epoch: 1.9476732781796993
2025-08-26 22:52:50,430 - root - INFO - TRAINER_LOGS - loss: 1.3421 grad_norm: 1.9988151788711548 learning_rate: 2.741840700238233e-06 epoch: 1.949980961611686
2025-08-26 22:53:33,191 - root - INFO - TRAINER_LOGS - loss: 1.324 grad_norm: 2.005469560623169 learning_rate: 2.731050331089156e-06 epoch: 1.952288645043673
2025-08-26 22:54:15,409 - root - INFO - TRAINER_LOGS - loss: 1.343 grad_norm: 1.7645676136016846 learning_rate: 2.720273253061555e-06 epoch: 1.9545963284756596
2025-08-26 22:54:57,155 - root - INFO - TRAINER_LOGS - loss: 1.3239 grad_norm: 1.9527348279953003 learning_rate: 2.709509529285719e-06 epoch: 1.9569040119076466
2025-08-26 22:55:39,706 - root - INFO - TRAINER_LOGS - loss: 1.3206 grad_norm: 1.7859512567520142 learning_rate: 2.698759222813715e-06 epoch: 1.9592116953396332
2025-08-26 22:56:22,339 - root - INFO - TRAINER_LOGS - loss: 1.3408 grad_norm: 2.0980470180511475 learning_rate: 2.68802239661901e-06 epoch: 1.96151937877162
2025-08-26 22:57:05,191 - root - INFO - TRAINER_LOGS - loss: 1.3124 grad_norm: 1.755637288093567 learning_rate: 2.6772991135961048e-06 epoch: 1.963827062203607
2025-08-26 22:57:48,730 - root - INFO - TRAINER_LOGS - loss: 1.3264 grad_norm: 1.4782601594924927 learning_rate: 2.666589436560172e-06 epoch: 1.9661347456355938
2025-08-26 22:58:32,944 - root - INFO - TRAINER_LOGS - loss: 1.3246 grad_norm: 1.693686604499817 learning_rate: 2.6558934282466773e-06 epoch: 1.9684424290675806
2025-08-26 22:59:15,662 - root - INFO - TRAINER_LOGS - loss: 1.299 grad_norm: 1.9199126958847046 learning_rate: 2.6452111513110203e-06 epoch: 1.9707501124995672
2025-08-26 22:59:59,044 - root - INFO - TRAINER_LOGS - loss: 1.3048 grad_norm: 1.5121387243270874 learning_rate: 2.6345426683281614e-06 epoch: 1.973057795931554
2025-08-26 23:00:42,141 - root - INFO - TRAINER_LOGS - loss: 1.3458 grad_norm: 1.7017707824707031 learning_rate: 2.6238880417922622e-06 epoch: 1.975365479363541
2025-08-26 23:01:25,342 - root - INFO - TRAINER_LOGS - loss: 1.3333 grad_norm: 1.686287760734558 learning_rate: 2.6132473341163135e-06 epoch: 1.9776731627955277
2025-08-26 23:02:08,246 - root - INFO - TRAINER_LOGS - loss: 1.3059 grad_norm: 1.8714399337768555 learning_rate: 2.6026206076317716e-06 epoch: 1.9799808462275146
2025-08-26 23:02:51,524 - root - INFO - TRAINER_LOGS - loss: 1.3152 grad_norm: 1.6652939319610596 learning_rate: 2.5920079245881935e-06 epoch: 1.9822885296595012
2025-08-26 23:03:35,080 - root - INFO - TRAINER_LOGS - loss: 1.3305 grad_norm: 1.5766205787658691 learning_rate: 2.581409347152874e-06 epoch: 1.9845962130914883
2025-08-26 23:06:33,394 - root - INFO - TRAINER_LOGS - eval_loss: 1.309522032737732 eval_runtime: 178.3096 eval_samples_per_second: 28.041 eval_steps_per_second: 1.172 epoch: 1.9845962130914883
2025-08-26 23:07:17,877 - root - INFO - TRAINER_LOGS - loss: 1.2819 grad_norm: 1.8085830211639404 learning_rate: 2.5708249374104753e-06 epoch: 1.9869038965234749
2025-08-26 23:08:01,201 - root - INFO - TRAINER_LOGS - loss: 1.3509 grad_norm: 1.9419037103652954 learning_rate: 2.5602547573626736e-06 epoch: 1.9892115799554617
2025-08-26 23:08:44,015 - root - INFO - TRAINER_LOGS - loss: 1.3398 grad_norm: 1.706491470336914 learning_rate: 2.549698868927787e-06 epoch: 1.9915192633874486
2025-08-26 23:09:26,160 - root - INFO - TRAINER_LOGS - loss: 1.3241 grad_norm: 1.968571424484253 learning_rate: 2.539157333940413e-06 epoch: 1.9938269468194352
2025-08-26 23:10:08,756 - root - INFO - TRAINER_LOGS - loss: 1.3581 grad_norm: 2.0951192378997803 learning_rate: 2.5286302141510733e-06 epoch: 1.9961346302514222
2025-08-26 23:10:51,248 - root - INFO - TRAINER_LOGS - loss: 1.316 grad_norm: 1.6143267154693604 learning_rate: 2.5181175712258444e-06 epoch: 1.9984423136834089
2025-08-26 23:11:33,581 - root - INFO - TRAINER_LOGS - loss: 1.2908 grad_norm: 1.6074994802474976 learning_rate: 2.507619466746005e-06 epoch: 2.000738458698236
2025-08-26 23:12:16,787 - root - INFO - TRAINER_LOGS - loss: 1.3151 grad_norm: 1.656273365020752 learning_rate: 2.497135962207664e-06 epoch: 2.0030461421302226
2025-08-26 23:13:00,265 - root - INFO - TRAINER_LOGS - loss: 1.3254 grad_norm: 1.8851573467254639 learning_rate: 2.48666711902141e-06 epoch: 2.005353825562209
2025-08-26 23:13:42,829 - root - INFO - TRAINER_LOGS - loss: 1.3273 grad_norm: 2.191622257232666 learning_rate: 2.4762129985119463e-06 epoch: 2.0076615089941963
2025-08-26 23:14:25,495 - root - INFO - TRAINER_LOGS - loss: 1.3068 grad_norm: 1.688758134841919 learning_rate: 2.4657736619177346e-06 epoch: 2.009969192426183
2025-08-26 23:15:07,249 - root - INFO - TRAINER_LOGS - loss: 1.338 grad_norm: 1.8560036420822144 learning_rate: 2.455349170390631e-06 epoch: 2.01227687585817
2025-08-26 23:15:50,956 - root - INFO - TRAINER_LOGS - loss: 1.3639 grad_norm: 1.5176292657852173 learning_rate: 2.44493958499554e-06 epoch: 2.0145845592901566
2025-08-26 23:16:34,011 - root - INFO - TRAINER_LOGS - loss: 1.3566 grad_norm: 1.5260246992111206 learning_rate: 2.43454496671004e-06 epoch: 2.016892242722143
2025-08-26 23:17:15,861 - root - INFO - TRAINER_LOGS - loss: 1.3102 grad_norm: 1.8630095720291138 learning_rate: 2.4241653764240393e-06 epoch: 2.0191999261541302
2025-08-26 23:17:59,642 - root - INFO - TRAINER_LOGS - loss: 1.3021 grad_norm: 1.5174914598464966 learning_rate: 2.413800874939413e-06 epoch: 2.021507609586117
2025-08-26 23:18:42,179 - root - INFO - TRAINER_LOGS - loss: 1.2841 grad_norm: 2.122260570526123 learning_rate: 2.4034515229696486e-06 epoch: 2.023815293018104
2025-08-26 23:19:25,535 - root - INFO - TRAINER_LOGS - loss: 1.2827 grad_norm: 1.8655019998550415 learning_rate: 2.3931173811394914e-06 epoch: 2.0261229764500905
2025-08-26 23:20:08,348 - root - INFO - TRAINER_LOGS - loss: 1.3352 grad_norm: 2.0015451908111572 learning_rate: 2.3827985099845867e-06 epoch: 2.028430659882077
2025-08-26 23:20:51,606 - root - INFO - TRAINER_LOGS - loss: 1.3343 grad_norm: 1.8789390325546265 learning_rate: 2.3724949699511286e-06 epoch: 2.030738343314064
2025-08-26 23:23:49,882 - root - INFO - TRAINER_LOGS - eval_loss: 1.3091788291931152 eval_runtime: 178.2718 eval_samples_per_second: 28.047 eval_steps_per_second: 1.172 epoch: 2.030738343314064
2025-08-26 23:24:33,884 - root - INFO - TRAINER_LOGS - loss: 1.3151 grad_norm: 1.7724474668502808 learning_rate: 2.362206821395503e-06 epoch: 2.033046026746051
2025-08-26 23:25:16,580 - root - INFO - TRAINER_LOGS - loss: 1.3615 grad_norm: 1.7161715030670166 learning_rate: 2.3519341245839327e-06 epoch: 2.035353710178038
2025-08-26 23:25:59,636 - root - INFO - TRAINER_LOGS - loss: 1.3384 grad_norm: 1.7316744327545166 learning_rate: 2.341676939692134e-06 epoch: 2.0376613936100245
2025-08-26 23:26:42,078 - root - INFO - TRAINER_LOGS - loss: 1.2898 grad_norm: 1.855431079864502 learning_rate: 2.3314353268049505e-06 epoch: 2.0399690770420116
2025-08-26 23:27:25,404 - root - INFO - TRAINER_LOGS - loss: 1.3197 grad_norm: 1.9687840938568115 learning_rate: 2.3212093459160075e-06 epoch: 2.042276760473998
2025-08-26 23:28:09,956 - root - INFO - TRAINER_LOGS - loss: 1.3131 grad_norm: 1.7959717512130737 learning_rate: 2.310999056927366e-06 epoch: 2.044584443905985
2025-08-26 23:28:52,850 - root - INFO - TRAINER_LOGS - loss: 1.2769 grad_norm: 1.8517550230026245 learning_rate: 2.3008045196491623e-06 epoch: 2.046892127337972
2025-08-26 23:29:36,585 - root - INFO - TRAINER_LOGS - loss: 1.3349 grad_norm: 1.7246819734573364 learning_rate: 2.2906257937992633e-06 epoch: 2.0491998107699585
2025-08-26 23:30:20,137 - root - INFO - TRAINER_LOGS - loss: 1.3451 grad_norm: 1.9459547996520996 learning_rate: 2.2804629390029133e-06 epoch: 2.0515074942019456
2025-08-26 23:31:03,591 - root - INFO - TRAINER_LOGS - loss: 1.334 grad_norm: 1.5155407190322876 learning_rate: 2.2703160147923887e-06 epoch: 2.053815177633932
2025-08-26 23:31:46,699 - root - INFO - TRAINER_LOGS - loss: 1.3114 grad_norm: 1.657374382019043 learning_rate: 2.260185080606647e-06 epoch: 2.056122861065919
2025-08-26 23:32:29,690 - root - INFO - TRAINER_LOGS - loss: 1.3029 grad_norm: 1.6836763620376587 learning_rate: 2.250070195790979e-06 epoch: 2.058430544497906
2025-08-26 23:33:13,692 - root - INFO - TRAINER_LOGS - loss: 1.2759 grad_norm: 1.7383543252944946 learning_rate: 2.2401732368732732e-06 epoch: 2.0607382279298925
2025-08-26 23:33:56,442 - root - INFO - TRAINER_LOGS - loss: 1.3125 grad_norm: 1.8973486423492432 learning_rate: 2.2300903045225266e-06 epoch: 2.0630459113618795
2025-08-26 23:34:39,499 - root - INFO - TRAINER_LOGS - loss: 1.3099 grad_norm: 1.9418798685073853 learning_rate: 2.2200235978319353e-06 epoch: 2.065353594793866
2025-08-26 23:35:23,031 - root - INFO - TRAINER_LOGS - loss: 1.2834 grad_norm: 1.7225894927978516 learning_rate: 2.2099731757705567e-06 epoch: 2.0676612782258528
2025-08-26 23:36:05,504 - root - INFO - TRAINER_LOGS - loss: 1.325 grad_norm: 2.0170934200286865 learning_rate: 2.199939097212055e-06 epoch: 2.06996896165784
2025-08-26 23:36:48,415 - root - INFO - TRAINER_LOGS - loss: 1.3098 grad_norm: 1.6677547693252563 learning_rate: 2.1899214209343563e-06 epoch: 2.0722766450898265
2025-08-26 23:37:32,746 - root - INFO - TRAINER_LOGS - loss: 1.3293 grad_norm: 1.6770029067993164 learning_rate: 2.179920205619305e-06 epoch: 2.0745843285218135
2025-08-26 23:38:15,415 - root - INFO - TRAINER_LOGS - loss: 1.3261 grad_norm: 1.786490559577942 learning_rate: 2.1699355098523194e-06 epoch: 2.0768920119538
2025-08-26 23:41:13,767 - root - INFO - TRAINER_LOGS - eval_loss: 1.3093161582946777 eval_runtime: 178.3472 eval_samples_per_second: 28.035 eval_steps_per_second: 1.172 epoch: 2.0768920119538
2025-08-26 23:41:57,249 - root - INFO - TRAINER_LOGS - loss: 1.3305 grad_norm: 1.9922429323196411 learning_rate: 2.1599673921220536e-06 epoch: 2.079199695385787
2025-08-26 23:42:40,154 - root - INFO - TRAINER_LOGS - loss: 1.3379 grad_norm: 1.7963550090789795 learning_rate: 2.150015910820044e-06 epoch: 2.081507378817774
2025-08-26 23:43:22,387 - root - INFO - TRAINER_LOGS - loss: 1.3067 grad_norm: 1.7196784019470215 learning_rate: 2.1400811242403763e-06 epoch: 2.0838150622497604
2025-08-26 23:44:05,998 - root - INFO - TRAINER_LOGS - loss: 1.3285 grad_norm: 1.5983953475952148 learning_rate: 2.1301630905793435e-06 epoch: 2.0861227456817475
2025-08-26 23:44:49,568 - root - INFO - TRAINER_LOGS - loss: 1.3021 grad_norm: 1.2744295597076416 learning_rate: 2.1202618679351008e-06 epoch: 2.088430429113734
2025-08-26 23:45:32,436 - root - INFO - TRAINER_LOGS - loss: 1.3059 grad_norm: 1.9573581218719482 learning_rate: 2.1103775143073253e-06 epoch: 2.090738112545721
2025-08-26 23:46:15,743 - root - INFO - TRAINER_LOGS - loss: 1.3207 grad_norm: 1.904871940612793 learning_rate: 2.100510087596882e-06 epoch: 2.093045795977708
2025-08-26 23:46:58,230 - root - INFO - TRAINER_LOGS - loss: 1.2998 grad_norm: 1.9074246883392334 learning_rate: 2.090659645605479e-06 epoch: 2.0953534794096944
2025-08-26 23:47:41,150 - root - INFO - TRAINER_LOGS - loss: 1.3069 grad_norm: 1.8653606176376343 learning_rate: 2.0808262460353308e-06 epoch: 2.0976611628416815
2025-08-26 23:48:23,476 - root - INFO - TRAINER_LOGS - loss: 1.3351 grad_norm: 2.030738115310669 learning_rate: 2.07100994648882e-06 epoch: 2.099968846273668
2025-08-26 23:49:06,378 - root - INFO - TRAINER_LOGS - loss: 1.31 grad_norm: 2.0850954055786133 learning_rate: 2.0612108044681615e-06 epoch: 2.102276529705655
2025-08-26 23:49:49,486 - root - INFO - TRAINER_LOGS - loss: 1.3231 grad_norm: 2.0207948684692383 learning_rate: 2.051428877375064e-06 epoch: 2.1045842131376418
2025-08-26 23:50:31,642 - root - INFO - TRAINER_LOGS - loss: 1.3232 grad_norm: 1.6231135129928589 learning_rate: 2.041664222510391e-06 epoch: 2.1068918965696284
2025-08-26 23:51:14,431 - root - INFO - TRAINER_LOGS - loss: 1.3013 grad_norm: 1.615283489227295 learning_rate: 2.0319168970738343e-06 epoch: 2.1091995800016154
2025-08-26 23:51:57,095 - root - INFO - TRAINER_LOGS - loss: 1.3294 grad_norm: 1.6406854391098022 learning_rate: 2.022186958163568e-06 epoch: 2.111507263433602
2025-08-26 23:52:39,790 - root - INFO - TRAINER_LOGS - loss: 1.3424 grad_norm: 2.297595977783203 learning_rate: 2.012474462775921e-06 epoch: 2.113814946865589
2025-08-26 23:53:23,136 - root - INFO - TRAINER_LOGS - loss: 1.2714 grad_norm: 1.567177653312683 learning_rate: 2.0027794678050395e-06 epoch: 2.1161226302975757
2025-08-26 23:54:05,772 - root - INFO - TRAINER_LOGS - loss: 1.3128 grad_norm: 1.8737215995788574 learning_rate: 1.9931020300425558e-06 epoch: 2.1184303137295624
2025-08-26 23:54:49,265 - root - INFO - TRAINER_LOGS - loss: 1.3164 grad_norm: 1.7918901443481445 learning_rate: 1.9834422061772534e-06 epoch: 2.1207379971615494
2025-08-26 23:55:31,560 - root - INFO - TRAINER_LOGS - loss: 1.2912 grad_norm: 1.7709137201309204 learning_rate: 1.9738000527947433e-06 epoch: 2.123045680593536
2025-08-26 23:58:29,505 - root - INFO - TRAINER_LOGS - eval_loss: 1.3084847927093506 eval_runtime: 177.94 eval_samples_per_second: 28.099 eval_steps_per_second: 1.175 epoch: 2.123045680593536
2025-08-26 23:59:13,173 - root - INFO - TRAINER_LOGS - loss: 1.3073 grad_norm: 1.8604027032852173 learning_rate: 1.964175626377118e-06 epoch: 2.125353364025523
2025-08-26 23:59:55,794 - root - INFO - TRAINER_LOGS - loss: 1.3057 grad_norm: 1.8167610168457031 learning_rate: 1.9545689833026327e-06 epoch: 2.1276610474575097
2025-08-27 00:00:38,652 - root - INFO - TRAINER_LOGS - loss: 1.3278 grad_norm: 1.6488789319992065 learning_rate: 1.9449801798453683e-06 epoch: 2.129968730889497
2025-08-27 00:01:22,043 - root - INFO - TRAINER_LOGS - loss: 1.3203 grad_norm: 1.7517502307891846 learning_rate: 1.935409272174904e-06 epoch: 2.1322764143214834
2025-08-27 00:02:04,688 - root - INFO - TRAINER_LOGS - loss: 1.3057 grad_norm: 1.9732120037078857 learning_rate: 1.925856316355994e-06 epoch: 2.13458409775347
2025-08-27 00:02:47,792 - root - INFO - TRAINER_LOGS - loss: 1.3172 grad_norm: 1.8592860698699951 learning_rate: 1.9163213683482277e-06 epoch: 2.136891781185457
2025-08-27 00:03:30,192 - root - INFO - TRAINER_LOGS - loss: 1.3087 grad_norm: 1.7281098365783691 learning_rate: 1.90680448400571e-06 epoch: 2.1391994646174437
2025-08-27 00:04:13,899 - root - INFO - TRAINER_LOGS - loss: 1.3305 grad_norm: 1.8770638704299927 learning_rate: 1.8973057190767307e-06 epoch: 2.1415071480494308
2025-08-27 00:04:56,837 - root - INFO - TRAINER_LOGS - loss: 1.3172 grad_norm: 2.069977045059204 learning_rate: 1.8878251292034412e-06 epoch: 2.1438148314814174
2025-08-27 00:05:40,514 - root - INFO - TRAINER_LOGS - loss: 1.3224 grad_norm: 1.9453210830688477 learning_rate: 1.8783627699215247e-06 epoch: 2.146122514913404
2025-08-27 00:06:22,957 - root - INFO - TRAINER_LOGS - loss: 1.3023 grad_norm: 1.7262790203094482 learning_rate: 1.8689186966598739e-06 epoch: 2.148430198345391
2025-08-27 00:07:06,232 - root - INFO - TRAINER_LOGS - loss: 1.2625 grad_norm: 1.807546854019165 learning_rate: 1.8594929647402643e-06 epoch: 2.1507378817773777
2025-08-27 00:07:49,479 - root - INFO - TRAINER_LOGS - loss: 1.3383 grad_norm: 2.2275657653808594 learning_rate: 1.8500856293770319e-06 epoch: 2.1530455652093647
2025-08-27 00:08:32,498 - root - INFO - TRAINER_LOGS - loss: 1.2999 grad_norm: 1.5732272863388062 learning_rate: 1.8406967456767454e-06 epoch: 2.1553532486413514
2025-08-27 00:09:15,250 - root - INFO - TRAINER_LOGS - loss: 1.3162 grad_norm: 1.7676637172698975 learning_rate: 1.831326368637894e-06 epoch: 2.157660932073338
2025-08-27 00:09:58,260 - root - INFO - TRAINER_LOGS - loss: 1.3133 grad_norm: 1.8939709663391113 learning_rate: 1.8219745531505512e-06 epoch: 2.159968615505325
2025-08-27 00:10:40,867 - root - INFO - TRAINER_LOGS - loss: 1.2824 grad_norm: 1.8724194765090942 learning_rate: 1.8126413539960608e-06 epoch: 2.1622762989373117
2025-08-27 00:11:23,457 - root - INFO - TRAINER_LOGS - loss: 1.3036 grad_norm: 2.0901317596435547 learning_rate: 1.8035129330807644e-06 epoch: 2.1645839823692987
2025-08-27 00:12:06,852 - root - INFO - TRAINER_LOGS - loss: 1.3156 grad_norm: 1.6506595611572266 learning_rate: 1.7942167554541261e-06 epoch: 2.1668916658012853
2025-08-27 00:12:49,980 - root - INFO - TRAINER_LOGS - loss: 1.34 grad_norm: 1.7171826362609863 learning_rate: 1.7849393567608025e-06 epoch: 2.1691993492332724
2025-08-27 00:15:47,934 - root - INFO - TRAINER_LOGS - eval_loss: 1.3085044622421265 eval_runtime: 177.9491 eval_samples_per_second: 28.098 eval_steps_per_second: 1.174 epoch: 2.1691993492332724
2025-08-27 00:16:32,466 - root - INFO - TRAINER_LOGS - loss: 1.315 grad_norm: 1.4712589979171753 learning_rate: 1.7756807913462187e-06 epoch: 2.171507032665259
2025-08-27 00:17:15,438 - root - INFO - TRAINER_LOGS - loss: 1.2831 grad_norm: 1.5496412515640259 learning_rate: 1.7664411134454768e-06 epoch: 2.1738147160972456
2025-08-27 00:17:58,547 - root - INFO - TRAINER_LOGS - loss: 1.3405 grad_norm: 1.8524281978607178 learning_rate: 1.757220377183037e-06 epoch: 2.1761223995292327
2025-08-27 00:18:40,815 - root - INFO - TRAINER_LOGS - loss: 1.3027 grad_norm: 1.5334879159927368 learning_rate: 1.7480186365724089e-06 epoch: 2.1784300829612193
2025-08-27 00:19:23,832 - root - INFO - TRAINER_LOGS - loss: 1.3091 grad_norm: 1.807295799255371 learning_rate: 1.7388359455158232e-06 epoch: 2.1807377663932064
2025-08-27 00:20:06,910 - root - INFO - TRAINER_LOGS - loss: 1.3016 grad_norm: 1.669442892074585 learning_rate: 1.7296723578039227e-06 epoch: 2.183045449825193
2025-08-27 00:20:49,868 - root - INFO - TRAINER_LOGS - loss: 1.3074 grad_norm: 1.7576414346694946 learning_rate: 1.7205279271154473e-06 epoch: 2.1853531332571796
2025-08-27 00:21:32,273 - root - INFO - TRAINER_LOGS - loss: 1.3316 grad_norm: 1.8865749835968018 learning_rate: 1.711402707016917e-06 epoch: 2.1876608166891667
2025-08-27 00:22:16,219 - root - INFO - TRAINER_LOGS - loss: 1.3355 grad_norm: 1.7838853597640991 learning_rate: 1.7022967509623205e-06 epoch: 2.1899685001211533
2025-08-27 00:22:59,214 - root - INFO - TRAINER_LOGS - loss: 1.3016 grad_norm: 1.755965232849121 learning_rate: 1.6932101122928002e-06 epoch: 2.1922761835531404
2025-08-27 00:23:42,267 - root - INFO - TRAINER_LOGS - loss: 1.3004 grad_norm: 1.814431071281433 learning_rate: 1.6841428442363405e-06 epoch: 2.194583866985127
2025-08-27 00:24:25,477 - root - INFO - TRAINER_LOGS - loss: 1.301 grad_norm: 2.0734734535217285 learning_rate: 1.675094999907455e-06 epoch: 2.1968915504171136
2025-08-27 00:25:08,663 - root - INFO - TRAINER_LOGS - loss: 1.3064 grad_norm: 1.751970648765564 learning_rate: 1.6660666323068814e-06 epoch: 2.1991992338491007
2025-08-27 00:25:52,024 - root - INFO - TRAINER_LOGS - loss: 1.3282 grad_norm: 1.6694269180297852 learning_rate: 1.6570577943212607e-06 epoch: 2.2015069172810873
2025-08-27 00:26:34,816 - root - INFO - TRAINER_LOGS - loss: 1.2851 grad_norm: 1.9965431690216064 learning_rate: 1.6480685387228322e-06 epoch: 2.2038146007130743
2025-08-27 00:27:18,158 - root - INFO - TRAINER_LOGS - loss: 1.2819 grad_norm: 1.6966352462768555 learning_rate: 1.6390989181691313e-06 epoch: 2.206122284145061
2025-08-27 00:28:01,351 - root - INFO - TRAINER_LOGS - loss: 1.3051 grad_norm: 1.952278971672058 learning_rate: 1.6301489852026687e-06 epoch: 2.2084299675770476
2025-08-27 00:28:43,698 - root - INFO - TRAINER_LOGS - loss: 1.3301 grad_norm: 1.7520264387130737 learning_rate: 1.6212187922506294e-06 epoch: 2.2107376510090346
2025-08-27 00:29:27,279 - root - INFO - TRAINER_LOGS - loss: 1.3319 grad_norm: 1.8683267831802368 learning_rate: 1.6123083916245668e-06 epoch: 2.2130453344410213
2025-08-27 00:30:10,571 - root - INFO - TRAINER_LOGS - loss: 1.3454 grad_norm: 1.9365154504776 learning_rate: 1.603417835520093e-06 epoch: 2.2153530178730083
2025-08-27 00:33:08,837 - root - INFO - TRAINER_LOGS - eval_loss: 1.307924509048462 eval_runtime: 178.2617 eval_samples_per_second: 28.049 eval_steps_per_second: 1.172 epoch: 2.2153530178730083
2025-08-27 00:33:51,364 - root - INFO - TRAINER_LOGS - loss: 1.294 grad_norm: 1.8123517036437988 learning_rate: 1.5945471760165743e-06 epoch: 2.217660701304995
2025-08-27 00:34:33,644 - root - INFO - TRAINER_LOGS - loss: 1.3056 grad_norm: 1.8868917226791382 learning_rate: 1.5856964650768258e-06 epoch: 2.2199683847369815
2025-08-27 00:35:16,924 - root - INFO - TRAINER_LOGS - loss: 1.2859 grad_norm: 1.9684057235717773 learning_rate: 1.576865754546808e-06 epoch: 2.2222760681689686
2025-08-27 00:35:59,526 - root - INFO - TRAINER_LOGS - loss: 1.3241 grad_norm: 1.5703781843185425 learning_rate: 1.5680550961553226e-06 epoch: 2.2245837516009552
2025-08-27 00:36:41,769 - root - INFO - TRAINER_LOGS - loss: 1.3238 grad_norm: 1.6870149374008179 learning_rate: 1.5592645415137065e-06 epoch: 2.2268914350329423
2025-08-27 00:37:25,435 - root - INFO - TRAINER_LOGS - loss: 1.3251 grad_norm: 1.640179991722107 learning_rate: 1.5504941421155378e-06 epoch: 2.229199118464929
2025-08-27 00:38:08,254 - root - INFO - TRAINER_LOGS - loss: 1.3248 grad_norm: 1.9452569484710693 learning_rate: 1.541743949336324e-06 epoch: 2.231506801896916
2025-08-27 00:38:51,173 - root - INFO - TRAINER_LOGS - loss: 1.3087 grad_norm: 1.8597095012664795 learning_rate: 1.5330140144332067e-06 epoch: 2.2338144853289026
2025-08-27 00:39:33,952 - root - INFO - TRAINER_LOGS - loss: 1.3428 grad_norm: 1.6189239025115967 learning_rate: 1.5243043885446612e-06 epoch: 2.236122168760889
2025-08-27 00:40:17,392 - root - INFO - TRAINER_LOGS - loss: 1.3315 grad_norm: 1.633048415184021 learning_rate: 1.515615122690195e-06 epoch: 2.2384298521928763
2025-08-27 00:41:00,060 - root - INFO - TRAINER_LOGS - loss: 1.2987 grad_norm: 1.850283145904541 learning_rate: 1.5069462677700486e-06 epoch: 2.240737535624863
2025-08-27 00:41:43,126 - root - INFO - TRAINER_LOGS - loss: 1.3164 grad_norm: 1.6843498945236206 learning_rate: 1.4982978745649045e-06 epoch: 2.24304521905685
2025-08-27 00:42:26,739 - root - INFO - TRAINER_LOGS - loss: 1.3314 grad_norm: 1.979723334312439 learning_rate: 1.489669993735578e-06 epoch: 2.2453529024888366
2025-08-27 00:43:10,534 - root - INFO - TRAINER_LOGS - loss: 1.2903 grad_norm: 1.6341345310211182 learning_rate: 1.481062675822728e-06 epoch: 2.247660585920823
2025-08-27 00:43:54,296 - root - INFO - TRAINER_LOGS - loss: 1.3317 grad_norm: 2.1540160179138184 learning_rate: 1.4724759712465608e-06 epoch: 2.2499682693528102
2025-08-27 00:44:37,608 - root - INFO - TRAINER_LOGS - loss: 1.3045 grad_norm: 1.9197733402252197 learning_rate: 1.463909930306529e-06 epoch: 2.252275952784797
2025-08-27 00:45:20,995 - root - INFO - TRAINER_LOGS - loss: 1.3563 grad_norm: 1.947241187095642 learning_rate: 1.4553646031810492e-06 epoch: 2.254583636216784
2025-08-27 00:46:04,648 - root - INFO - TRAINER_LOGS - loss: 1.2904 grad_norm: 1.6897047758102417 learning_rate: 1.4468400399271925e-06 epoch: 2.2568913196487705
2025-08-27 00:46:48,254 - root - INFO - TRAINER_LOGS - loss: 1.3091 grad_norm: 2.003600597381592 learning_rate: 1.4383362904804015e-06 epoch: 2.2591990030807576
2025-08-27 00:47:31,395 - root - INFO - TRAINER_LOGS - loss: 1.3356 grad_norm: 1.7217251062393188 learning_rate: 1.4298534046541955e-06 epoch: 2.2615066865127442
2025-08-27 00:50:29,452 - root - INFO - TRAINER_LOGS - eval_loss: 1.3077162504196167 eval_runtime: 178.0523 eval_samples_per_second: 28.082 eval_steps_per_second: 1.174 epoch: 2.2615066865127442
2025-08-27 00:51:12,399 - root - INFO - TRAINER_LOGS - loss: 1.3265 grad_norm: 1.7681176662445068 learning_rate: 1.4213914321398774e-06 epoch: 2.263814369944731
2025-08-27 00:51:54,600 - root - INFO - TRAINER_LOGS - loss: 1.3196 grad_norm: 1.858188509941101 learning_rate: 1.4129504225062434e-06 epoch: 2.266122053376718
2025-08-27 00:52:37,905 - root - INFO - TRAINER_LOGS - loss: 1.2899 grad_norm: 1.8854033946990967 learning_rate: 1.4045304251992935e-06 epoch: 2.2684297368087045
2025-08-27 00:53:21,120 - root - INFO - TRAINER_LOGS - loss: 1.3123 grad_norm: 1.7601220607757568 learning_rate: 1.3961314895419408e-06 epoch: 2.2707374202406916
2025-08-27 00:54:03,273 - root - INFO - TRAINER_LOGS - loss: 1.3045 grad_norm: 1.4930986166000366 learning_rate: 1.3877536647337225e-06 epoch: 2.273045103672678
2025-08-27 00:54:46,124 - root - INFO - TRAINER_LOGS - loss: 1.3295 grad_norm: 1.6919960975646973 learning_rate: 1.3793969998505124e-06 epoch: 2.275352787104665
2025-08-27 00:55:29,127 - root - INFO - TRAINER_LOGS - loss: 1.3035 grad_norm: 1.864040732383728 learning_rate: 1.371061543844231e-06 epoch: 2.277660470536652
2025-08-27 00:56:12,442 - root - INFO - TRAINER_LOGS - loss: 1.3383 grad_norm: 1.9133857488632202 learning_rate: 1.3627473455425661e-06 epoch: 2.2799681539686385
2025-08-27 00:56:56,262 - root - INFO - TRAINER_LOGS - loss: 1.3295 grad_norm: 1.759255290031433 learning_rate: 1.3544544536486747e-06 epoch: 2.2822758374006256
2025-08-27 00:57:38,147 - root - INFO - TRAINER_LOGS - loss: 1.3078 grad_norm: 1.9213601350784302 learning_rate: 1.3461829167409107e-06 epoch: 2.284583520832612
2025-08-27 00:58:21,054 - root - INFO - TRAINER_LOGS - loss: 1.298 grad_norm: 1.5572059154510498 learning_rate: 1.3379327832725309e-06 epoch: 2.286891204264599
2025-08-27 00:59:03,932 - root - INFO - TRAINER_LOGS - loss: 1.3236 grad_norm: 1.6428648233413696 learning_rate: 1.3297041015714134e-06 epoch: 2.289198887696586
2025-08-27 00:59:47,593 - root - INFO - TRAINER_LOGS - loss: 1.3331 grad_norm: 1.6815602779388428 learning_rate: 1.3214969198397776e-06 epoch: 2.2915065711285725
2025-08-27 01:00:30,678 - root - INFO - TRAINER_LOGS - loss: 1.3188 grad_norm: 1.9373184442520142 learning_rate: 1.3133112861538987e-06 epoch: 2.2938142545605595
2025-08-27 01:01:13,593 - root - INFO - TRAINER_LOGS - loss: 1.3224 grad_norm: 2.0660011768341064 learning_rate: 1.3051472484638283e-06 epoch: 2.296121937992546
2025-08-27 01:01:57,106 - root - INFO - TRAINER_LOGS - loss: 1.3559 grad_norm: 1.7987703084945679 learning_rate: 1.2970048545931097e-06 epoch: 2.2984296214245328
2025-08-27 01:02:40,957 - root - INFO - TRAINER_LOGS - loss: 1.2982 grad_norm: 2.052624225616455 learning_rate: 1.2888841522385037e-06 epoch: 2.30073730485652
2025-08-27 01:03:24,192 - root - INFO - TRAINER_LOGS - loss: 1.3344 grad_norm: 2.0200345516204834 learning_rate: 1.2807851889697038e-06 epoch: 2.3030449882885065
2025-08-27 01:04:06,617 - root - INFO - TRAINER_LOGS - loss: 1.2982 grad_norm: 1.8716644048690796 learning_rate: 1.272708012229058e-06 epoch: 2.3053526717204935
2025-08-27 01:04:49,536 - root - INFO - TRAINER_LOGS - loss: 1.3127 grad_norm: 1.3586779832839966 learning_rate: 1.2646526693312982e-06 epoch: 2.30766035515248
2025-08-27 01:07:47,395 - root - INFO - TRAINER_LOGS - eval_loss: 1.3072818517684937 eval_runtime: 177.8542 eval_samples_per_second: 28.113 eval_steps_per_second: 1.175 epoch: 2.30766035515248
2025-08-27 01:08:30,980 - root - INFO - TRAINER_LOGS - loss: 1.3533 grad_norm: 1.828352451324463 learning_rate: 1.2566192074632528e-06 epoch: 2.3099680385844668
2025-08-27 01:09:14,053 - root - INFO - TRAINER_LOGS - loss: 1.3274 grad_norm: 1.8117685317993164 learning_rate: 1.248607673683575e-06 epoch: 2.312275722016454
2025-08-27 01:09:55,993 - root - INFO - TRAINER_LOGS - loss: 1.3304 grad_norm: 1.554702877998352 learning_rate: 1.240618114922469e-06 epoch: 2.3145834054484404
2025-08-27 01:10:38,281 - root - INFO - TRAINER_LOGS - loss: 1.3426 grad_norm: 1.7630152702331543 learning_rate: 1.2326505779814101e-06 epoch: 2.3168910888804275
2025-08-27 01:11:22,321 - root - INFO - TRAINER_LOGS - loss: 1.3148 grad_norm: 1.713046669960022 learning_rate: 1.2247051095328755e-06 epoch: 2.319198772312414
2025-08-27 01:12:05,230 - root - INFO - TRAINER_LOGS - loss: 1.296 grad_norm: 1.6514822244644165 learning_rate: 1.2167817561200706e-06 epoch: 2.321506455744401
2025-08-27 01:12:48,316 - root - INFO - TRAINER_LOGS - loss: 1.3466 grad_norm: 1.7894914150238037 learning_rate: 1.2088805641566526e-06 epoch: 2.323814139176388
2025-08-27 01:13:31,296 - root - INFO - TRAINER_LOGS - loss: 1.3353 grad_norm: 1.7537192106246948 learning_rate: 1.2010015799264602e-06 epoch: 2.3261218226083744
2025-08-27 01:14:14,305 - root - INFO - TRAINER_LOGS - loss: 1.319 grad_norm: 1.8388116359710693 learning_rate: 1.1931448495832432e-06 epoch: 2.3284295060403615
2025-08-27 01:14:56,752 - root - INFO - TRAINER_LOGS - loss: 1.3342 grad_norm: 1.5563762187957764 learning_rate: 1.1853104191503923e-06 epoch: 2.330737189472348
2025-08-27 01:15:39,210 - root - INFO - TRAINER_LOGS - loss: 1.3259 grad_norm: 1.9345179796218872 learning_rate: 1.1774983345206708e-06 epoch: 2.333044872904335
2025-08-27 01:16:21,893 - root - INFO - TRAINER_LOGS - loss: 1.3099 grad_norm: 2.0162265300750732 learning_rate: 1.1697086414559416e-06 epoch: 2.3353525563363218
2025-08-27 01:17:04,723 - root - INFO - TRAINER_LOGS - loss: 1.2981 grad_norm: 1.8738266229629517 learning_rate: 1.1619413855869033e-06 epoch: 2.3376602397683084
2025-08-27 01:17:47,527 - root - INFO - TRAINER_LOGS - loss: 1.3219 grad_norm: 1.7840931415557861 learning_rate: 1.1541966124128196e-06 epoch: 2.3399679232002955
2025-08-27 01:18:29,840 - root - INFO - TRAINER_LOGS - loss: 1.3017 grad_norm: 1.838120460510254 learning_rate: 1.1464743673012551e-06 epoch: 2.342275606632282
2025-08-27 01:19:13,976 - root - INFO - TRAINER_LOGS - loss: 1.3427 grad_norm: 1.9029929637908936 learning_rate: 1.1387746954878099e-06 epoch: 2.344583290064269
2025-08-27 01:19:57,121 - root - INFO - TRAINER_LOGS - loss: 1.3474 grad_norm: 2.1055960655212402 learning_rate: 1.1312509611926652e-06 epoch: 2.3468909734962558
2025-08-27 01:20:40,113 - root - INFO - TRAINER_LOGS - loss: 1.3213 grad_norm: 2.0366578102111816 learning_rate: 1.123596117445765e-06 epoch: 2.349198656928243
2025-08-27 01:21:23,182 - root - INFO - TRAINER_LOGS - loss: 1.3409 grad_norm: 1.9383810758590698 learning_rate: 1.1159639810138823e-06 epoch: 2.3515063403602294
2025-08-27 01:22:06,293 - root - INFO - TRAINER_LOGS - loss: 1.3074 grad_norm: 1.7615115642547607 learning_rate: 1.1083545966047748e-06 epoch: 2.353814023792216
2025-08-27 01:25:04,146 - root - INFO - TRAINER_LOGS - eval_loss: 1.3075134754180908 eval_runtime: 177.8484 eval_samples_per_second: 28.114 eval_steps_per_second: 1.175 epoch: 2.353814023792216
2025-08-27 01:25:47,579 - root - INFO - TRAINER_LOGS - loss: 1.3075 grad_norm: 1.9786862134933472 learning_rate: 1.1007680087929235e-06 epoch: 2.356121707224203
2025-08-27 01:26:30,842 - root - INFO - TRAINER_LOGS - loss: 1.3397 grad_norm: 1.799913763999939 learning_rate: 1.0932042620192695e-06 epoch: 2.3584293906561897
2025-08-27 01:27:13,547 - root - INFO - TRAINER_LOGS - loss: 1.3228 grad_norm: 1.859423279762268 learning_rate: 1.0856634005909544e-06 epoch: 2.360737074088177
2025-08-27 01:27:56,474 - root - INFO - TRAINER_LOGS - loss: 1.3143 grad_norm: 1.9722471237182617 learning_rate: 1.078145468681066e-06 epoch: 2.3630447575201634
2025-08-27 01:28:39,818 - root - INFO - TRAINER_LOGS - loss: 1.2991 grad_norm: 1.7533224821090698 learning_rate: 1.0706505103283693e-06 epoch: 2.36535244095215
2025-08-27 01:29:23,221 - root - INFO - TRAINER_LOGS - loss: 1.3051 grad_norm: 1.7140398025512695 learning_rate: 1.0631785694370573e-06 epoch: 2.367660124384137
2025-08-27 01:30:06,702 - root - INFO - TRAINER_LOGS - loss: 1.3165 grad_norm: 1.8017995357513428 learning_rate: 1.0557296897764886e-06 epoch: 2.3699678078161237
2025-08-27 01:30:49,797 - root - INFO - TRAINER_LOGS - loss: 1.334 grad_norm: 1.6036700010299683 learning_rate: 1.0483039149809332e-06 epoch: 2.3722754912481108
2025-08-27 01:31:31,852 - root - INFO - TRAINER_LOGS - loss: 1.317 grad_norm: 2.003791570663452 learning_rate: 1.0409012885493202e-06 epoch: 2.3745831746800974
2025-08-27 01:32:14,567 - root - INFO - TRAINER_LOGS - loss: 1.2993 grad_norm: 2.152661085128784 learning_rate: 1.0335218538449754e-06 epoch: 2.376890858112084
2025-08-27 01:32:57,636 - root - INFO - TRAINER_LOGS - loss: 1.325 grad_norm: 1.9905102252960205 learning_rate: 1.0261656540953735e-06 epoch: 2.379198541544071
2025-08-27 01:33:41,617 - root - INFO - TRAINER_LOGS - loss: 1.3256 grad_norm: 1.6783488988876343 learning_rate: 1.018832732391881e-06 epoch: 2.3815062249760577
2025-08-27 01:34:24,561 - root - INFO - TRAINER_LOGS - loss: 1.3109 grad_norm: 1.7747458219528198 learning_rate: 1.0115231316895085e-06 epoch: 2.3838139084080447
2025-08-27 01:35:08,232 - root - INFO - TRAINER_LOGS - loss: 1.2923 grad_norm: 2.061556577682495 learning_rate: 1.0042368948066533e-06 epoch: 2.3861215918400314
2025-08-27 01:35:50,504 - root - INFO - TRAINER_LOGS - loss: 1.3045 grad_norm: 1.7279233932495117 learning_rate: 9.969740644248521e-07 epoch: 2.388429275272018
2025-08-27 01:36:33,673 - root - INFO - TRAINER_LOGS - loss: 1.3006 grad_norm: 1.7543630599975586 learning_rate: 9.897346830885318e-07 epoch: 2.390736958704005
2025-08-27 01:37:17,124 - root - INFO - TRAINER_LOGS - loss: 1.3367 grad_norm: 1.8748875856399536 learning_rate: 9.825187932047569e-07 epoch: 2.3930446421359917
2025-08-27 01:38:01,478 - root - INFO - TRAINER_LOGS - loss: 1.3551 grad_norm: 1.8157479763031006 learning_rate: 9.753264370429843e-07 epoch: 2.3953523255679787
2025-08-27 01:38:43,734 - root - INFO - TRAINER_LOGS - loss: 1.3135 grad_norm: 1.7810968160629272 learning_rate: 9.681576567348121e-07 epoch: 2.3976600089999653
2025-08-27 01:39:25,523 - root - INFO - TRAINER_LOGS - loss: 1.3071 grad_norm: 1.8265315294265747 learning_rate: 9.610124942737392e-07 epoch: 2.399967692431952
2025-08-27 01:42:23,645 - root - INFO - TRAINER_LOGS - eval_loss: 1.3074828386306763 eval_runtime: 178.1172 eval_samples_per_second: 28.071 eval_steps_per_second: 1.173 epoch: 2.399967692431952
2025-08-27 01:43:06,997 - root - INFO - TRAINER_LOGS - loss: 1.3565 grad_norm: 1.962327003479004 learning_rate: 9.538909915149125e-07 epoch: 2.402275375863939
2025-08-27 01:43:49,880 - root - INFO - TRAINER_LOGS - loss: 1.3054 grad_norm: 2.1115732192993164 learning_rate: 9.467931901748817e-07 epoch: 2.4045830592959256
2025-08-27 01:44:32,733 - root - INFO - TRAINER_LOGS - loss: 1.2936 grad_norm: 1.9126423597335815 learning_rate: 9.397191318313648e-07 epoch: 2.4068907427279127
2025-08-27 01:45:16,210 - root - INFO - TRAINER_LOGS - loss: 1.3143 grad_norm: 1.9018313884735107 learning_rate: 9.326688579229903e-07 epoch: 2.4091984261598993
2025-08-27 01:45:59,738 - root - INFO - TRAINER_LOGS - loss: 1.3102 grad_norm: 1.8683565855026245 learning_rate: 9.256424097490652e-07 epoch: 2.411506109591886
2025-08-27 01:46:42,423 - root - INFO - TRAINER_LOGS - loss: 1.3337 grad_norm: 1.5655274391174316 learning_rate: 9.186398284693287e-07 epoch: 2.413813793023873
2025-08-27 01:47:25,948 - root - INFO - TRAINER_LOGS - loss: 1.311 grad_norm: 1.959568738937378 learning_rate: 9.116611551037108e-07 epoch: 2.4161214764558596
2025-08-27 01:48:09,236 - root - INFO - TRAINER_LOGS - loss: 1.3113 grad_norm: 1.7241084575653076 learning_rate: 9.047064305320946e-07 epoch: 2.4184291598878467
2025-08-27 01:48:53,020 - root - INFO - TRAINER_LOGS - loss: 1.3161 grad_norm: 1.9405986070632935 learning_rate: 8.977756954940736e-07 epoch: 2.4207368433198333
2025-08-27 01:49:36,065 - root - INFO - TRAINER_LOGS - loss: 1.2774 grad_norm: 1.8497122526168823 learning_rate: 8.908689905887164e-07 epoch: 2.4230445267518204
2025-08-27 01:50:20,437 - root - INFO - TRAINER_LOGS - loss: 1.3304 grad_norm: 1.836500883102417 learning_rate: 8.83986356274325e-07 epoch: 2.425352210183807
2025-08-27 01:51:04,032 - root - INFO - TRAINER_LOGS - loss: 1.3376 grad_norm: 2.0706005096435547 learning_rate: 8.771278328682031e-07 epoch: 2.4276598936157936
2025-08-27 01:51:47,005 - root - INFO - TRAINER_LOGS - loss: 1.3059 grad_norm: 1.6175284385681152 learning_rate: 8.702934605464141e-07 epoch: 2.4299675770477807
2025-08-27 01:52:30,637 - root - INFO - TRAINER_LOGS - loss: 1.3112 grad_norm: 1.7031190395355225 learning_rate: 8.634832793435493e-07 epoch: 2.4322752604797673
2025-08-27 01:53:14,218 - root - INFO - TRAINER_LOGS - loss: 1.3061 grad_norm: 1.7872169017791748 learning_rate: 8.566973291524928e-07 epoch: 2.4345829439117543
2025-08-27 01:53:57,252 - root - INFO - TRAINER_LOGS - loss: 1.3103 grad_norm: 1.698996901512146 learning_rate: 8.499356497241873e-07 epoch: 2.436890627343741
2025-08-27 01:54:40,509 - root - INFO - TRAINER_LOGS - loss: 1.3179 grad_norm: 1.957985520362854 learning_rate: 8.43198280667401e-07 epoch: 2.439198310775728
2025-08-27 01:55:23,496 - root - INFO - TRAINER_LOGS - loss: 1.3236 grad_norm: 1.8924274444580078 learning_rate: 8.364852614484959e-07 epoch: 2.4415059942077146
2025-08-27 01:56:06,680 - root - INFO - TRAINER_LOGS - loss: 1.3114 grad_norm: 1.8104225397109985 learning_rate: 8.297966313911992e-07 epoch: 2.4438136776397013
2025-08-27 01:56:49,982 - root - INFO - TRAINER_LOGS - loss: 1.3171 grad_norm: 1.7485264539718628 learning_rate: 8.231324296763687e-07 epoch: 2.4461213610716883
2025-08-27 01:59:47,911 - root - INFO - TRAINER_LOGS - eval_loss: 1.3071246147155762 eval_runtime: 177.9233 eval_samples_per_second: 28.102 eval_steps_per_second: 1.175 epoch: 2.4461213610716883
2025-08-27 02:00:31,435 - root - INFO - TRAINER_LOGS - loss: 1.3145 grad_norm: 1.6938550472259521 learning_rate: 8.164926953417646e-07 epoch: 2.448429044503675
2025-08-27 02:01:14,618 - root - INFO - TRAINER_LOGS - loss: 1.3153 grad_norm: 1.830926775932312 learning_rate: 8.098774672818205e-07 epoch: 2.450736727935662
2025-08-27 02:01:57,324 - root - INFO - TRAINER_LOGS - loss: 1.3389 grad_norm: 2.0438530445098877 learning_rate: 8.032867842474207e-07 epoch: 2.4530444113676486
2025-08-27 02:02:39,655 - root - INFO - TRAINER_LOGS - loss: 1.3077 grad_norm: 1.909956455230713 learning_rate: 7.967206848456649e-07 epoch: 2.4553520947996352
2025-08-27 02:03:23,008 - root - INFO - TRAINER_LOGS - loss: 1.3382 grad_norm: 1.9078608751296997 learning_rate: 7.901792075396475e-07 epoch: 2.4576597782316223
2025-08-27 02:04:06,053 - root - INFO - TRAINER_LOGS - loss: 1.2943 grad_norm: 2.1567680835723877 learning_rate: 7.836623906482299e-07 epoch: 2.459967461663609
2025-08-27 02:04:50,135 - root - INFO - TRAINER_LOGS - loss: 1.32 grad_norm: 1.9017746448516846 learning_rate: 7.77170272345818e-07 epoch: 2.462275145095596
2025-08-27 02:05:33,004 - root - INFO - TRAINER_LOGS - loss: 1.3173 grad_norm: 1.788863182067871 learning_rate: 7.707028906621378e-07 epoch: 2.4645828285275826
2025-08-27 02:06:15,500 - root - INFO - TRAINER_LOGS - loss: 1.3248 grad_norm: 1.7383356094360352 learning_rate: 7.642602834820111e-07 epoch: 2.466890511959569
2025-08-27 02:06:57,835 - root - INFO - TRAINER_LOGS - loss: 1.3091 grad_norm: 1.6762373447418213 learning_rate: 7.578424885451364e-07 epoch: 2.4691981953915563
2025-08-27 02:07:40,386 - root - INFO - TRAINER_LOGS - loss: 1.3136 grad_norm: 1.8861042261123657 learning_rate: 7.514495434458646e-07 epoch: 2.471505878823543
2025-08-27 02:08:23,121 - root - INFO - TRAINER_LOGS - loss: 1.2911 grad_norm: 1.8054375648498535 learning_rate: 7.450814856329818e-07 epoch: 2.47381356225553
2025-08-27 02:09:05,844 - root - INFO - TRAINER_LOGS - loss: 1.2973 grad_norm: 2.107259750366211 learning_rate: 7.387383524094871e-07 epoch: 2.4761212456875166
2025-08-27 02:09:48,166 - root - INFO - TRAINER_LOGS - loss: 1.3461 grad_norm: 2.0193026065826416 learning_rate: 7.324201809323795e-07 epoch: 2.478428929119503
2025-08-27 02:10:30,860 - root - INFO - TRAINER_LOGS - loss: 1.351 grad_norm: 1.6571000814437866 learning_rate: 7.26127008212431e-07 epoch: 2.4807366125514902
2025-08-27 02:11:12,761 - root - INFO - TRAINER_LOGS - loss: 1.3249 grad_norm: 1.8367539644241333 learning_rate: 7.198588711139781e-07 epoch: 2.483044295983477
2025-08-27 02:11:55,452 - root - INFO - TRAINER_LOGS - loss: 1.3131 grad_norm: 1.9050387144088745 learning_rate: 7.136158063547038e-07 epoch: 2.485351979415464
2025-08-27 02:12:37,907 - root - INFO - TRAINER_LOGS - loss: 1.3401 grad_norm: 1.8336670398712158 learning_rate: 7.073978505054196e-07 epoch: 2.4876596628474505
2025-08-27 02:13:21,157 - root - INFO - TRAINER_LOGS - loss: 1.3283 grad_norm: 2.4283316135406494 learning_rate: 7.012050399898529e-07 epoch: 2.489967346279437
2025-08-27 02:14:04,593 - root - INFO - TRAINER_LOGS - loss: 1.2706 grad_norm: 1.639256238937378 learning_rate: 6.950374110844366e-07 epoch: 2.4922750297114242
2025-08-27 02:17:02,674 - root - INFO - TRAINER_LOGS - eval_loss: 1.3072446584701538 eval_runtime: 178.0755 eval_samples_per_second: 28.078 eval_steps_per_second: 1.174 epoch: 2.4922750297114242
2025-08-27 02:17:45,593 - root - INFO - TRAINER_LOGS - loss: 1.2892 grad_norm: 1.7951769828796387 learning_rate: 6.88894999918091e-07 epoch: 2.494582713143411
2025-08-27 02:18:28,606 - root - INFO - TRAINER_LOGS - loss: 1.3144 grad_norm: 2.110180616378784 learning_rate: 6.827778424720172e-07 epoch: 2.496890396575398
2025-08-27 02:19:11,821 - root - INFO - TRAINER_LOGS - loss: 1.3214 grad_norm: 1.9822404384613037 learning_rate: 6.766859745794835e-07 epoch: 2.4991980800073845
2025-08-27 02:19:54,831 - root - INFO - TRAINER_LOGS - loss: 1.3054 grad_norm: 1.9803930521011353 learning_rate: 6.70619431925617e-07 epoch: 2.501505763439371
2025-08-27 02:20:37,721 - root - INFO - TRAINER_LOGS - loss: 1.3004 grad_norm: 1.9245285987854004 learning_rate: 6.645782500471921e-07 epoch: 2.503813446871358
2025-08-27 02:21:20,117 - root - INFO - TRAINER_LOGS - loss: 1.3109 grad_norm: 1.7276283502578735 learning_rate: 6.585624643324268e-07 epoch: 2.506121130303345
2025-08-27 02:22:01,994 - root - INFO - TRAINER_LOGS - loss: 1.3004 grad_norm: 1.8546894788742065 learning_rate: 6.52572110020771e-07 epoch: 2.508428813735332
2025-08-27 02:22:44,888 - root - INFO - TRAINER_LOGS - loss: 1.3358 grad_norm: 2.1203901767730713 learning_rate: 6.466072222027015e-07 epoch: 2.5107364971673185
2025-08-27 02:23:27,802 - root - INFO - TRAINER_LOGS - loss: 1.3141 grad_norm: 1.9406849145889282 learning_rate: 6.406678358195173e-07 epoch: 2.513044180599305
2025-08-27 02:24:10,831 - root - INFO - TRAINER_LOGS - loss: 1.3223 grad_norm: 1.8607726097106934 learning_rate: 6.347539856631346e-07 epoch: 2.515351864031292
2025-08-27 02:24:53,500 - root - INFO - TRAINER_LOGS - loss: 1.3232 grad_norm: 1.784797191619873 learning_rate: 6.288657063758818e-07 epoch: 2.5176595474632792
2025-08-27 02:25:35,982 - root - INFO - TRAINER_LOGS - loss: 1.2859 grad_norm: 1.5717681646347046 learning_rate: 6.230030324502978e-07 epoch: 2.519967230895266
2025-08-27 02:26:19,093 - root - INFO - TRAINER_LOGS - loss: 1.3192 grad_norm: 2.1850101947784424 learning_rate: 6.171659982289308e-07 epoch: 2.5222749143272525
2025-08-27 02:27:01,180 - root - INFO - TRAINER_LOGS - loss: 1.2812 grad_norm: 1.7604453563690186 learning_rate: 6.113546379041352e-07 epoch: 2.5245825977592395
2025-08-27 02:27:43,146 - root - INFO - TRAINER_LOGS - loss: 1.3174 grad_norm: 2.446686267852783 learning_rate: 6.055689855178709e-07 epoch: 2.526890281191226
2025-08-27 02:28:25,637 - root - INFO - TRAINER_LOGS - loss: 1.3269 grad_norm: 2.384460926055908 learning_rate: 5.99809074961506e-07 epoch: 2.5291979646232132
2025-08-27 02:29:08,766 - root - INFO - TRAINER_LOGS - loss: 1.3268 grad_norm: 1.9690098762512207 learning_rate: 5.94074939975619e-07 epoch: 2.5315056480552
2025-08-27 02:29:52,375 - root - INFO - TRAINER_LOGS - loss: 1.3112 grad_norm: 1.6853041648864746 learning_rate: 5.884805275200161e-07 epoch: 2.5338133314871865
2025-08-27 02:30:35,414 - root - INFO - TRAINER_LOGS - loss: 1.3278 grad_norm: 1.9527335166931152 learning_rate: 5.827975271139746e-07 epoch: 2.5361210149191735
2025-08-27 02:31:17,887 - root - INFO - TRAINER_LOGS - loss: 1.341 grad_norm: 1.7782621383666992 learning_rate: 5.771404019291655e-07 epoch: 2.53842869835116
2025-08-27 02:34:16,017 - root - INFO - TRAINER_LOGS - eval_loss: 1.3068640232086182 eval_runtime: 178.125 eval_samples_per_second: 28.07 eval_steps_per_second: 1.173 epoch: 2.53842869835116
2025-08-27 02:35:00,161 - root - INFO - TRAINER_LOGS - loss: 1.3387 grad_norm: 1.7991583347320557 learning_rate: 5.715091851040671e-07 epoch: 2.540736381783147
2025-08-27 02:35:42,597 - root - INFO - TRAINER_LOGS - loss: 1.2983 grad_norm: 1.707184076309204 learning_rate: 5.659039096253899e-07 epoch: 2.543044065215134
2025-08-27 02:36:25,933 - root - INFO - TRAINER_LOGS - loss: 1.3714 grad_norm: 1.790588140487671 learning_rate: 5.603246083278835e-07 epoch: 2.5453517486471204
2025-08-27 02:37:09,028 - root - INFO - TRAINER_LOGS - loss: 1.3366 grad_norm: 1.9872910976409912 learning_rate: 5.54771313894149e-07 epoch: 2.5476594320791075
2025-08-27 02:37:51,429 - root - INFO - TRAINER_LOGS - loss: 1.2787 grad_norm: 2.0171163082122803 learning_rate: 5.492440588544401e-07 epoch: 2.549967115511094
2025-08-27 02:38:35,100 - root - INFO - TRAINER_LOGS - loss: 1.3154 grad_norm: 1.7658827304840088 learning_rate: 5.437428755864776e-07 epoch: 2.552274798943081
2025-08-27 02:39:18,512 - root - INFO - TRAINER_LOGS - loss: 1.3015 grad_norm: 1.8168197870254517 learning_rate: 5.382677963152577e-07 epoch: 2.554582482375068
2025-08-27 02:40:00,511 - root - INFO - TRAINER_LOGS - loss: 1.3305 grad_norm: 2.020490884780884 learning_rate: 5.328188531128636e-07 epoch: 2.5568901658070544
2025-08-27 02:40:43,310 - root - INFO - TRAINER_LOGS - loss: 1.3359 grad_norm: 1.834259271621704 learning_rate: 5.27396077898279e-07 epoch: 2.5591978492390415
2025-08-27 02:41:26,151 - root - INFO - TRAINER_LOGS - loss: 1.2707 grad_norm: 1.7105354070663452 learning_rate: 5.219995024371982e-07 epoch: 2.561505532671028
2025-08-27 02:42:08,737 - root - INFO - TRAINER_LOGS - loss: 1.2693 grad_norm: 1.567327857017517 learning_rate: 5.166291583418448e-07 epoch: 2.563813216103015
2025-08-27 02:42:51,983 - root - INFO - TRAINER_LOGS - loss: 1.2985 grad_norm: 2.052874803543091 learning_rate: 5.112850770707806e-07 epoch: 2.5661208995350018
2025-08-27 02:43:34,450 - root - INFO - TRAINER_LOGS - loss: 1.3026 grad_norm: 2.0051448345184326 learning_rate: 5.059672899287255e-07 epoch: 2.5684285829669884
2025-08-27 02:44:16,377 - root - INFO - TRAINER_LOGS - loss: 1.3292 grad_norm: 2.12873911857605 learning_rate: 5.006758280663715e-07 epoch: 2.5707362663989755
2025-08-27 02:44:59,459 - root - INFO - TRAINER_LOGS - loss: 1.3335 grad_norm: 1.942803978919983 learning_rate: 4.954107224802052e-07 epoch: 2.573043949830962
2025-08-27 02:45:42,227 - root - INFO - TRAINER_LOGS - loss: 1.3313 grad_norm: 1.624422311782837 learning_rate: 4.901720040123182e-07 epoch: 2.575351633262949
2025-08-27 02:46:24,662 - root - INFO - TRAINER_LOGS - loss: 1.2847 grad_norm: 1.7847707271575928 learning_rate: 4.849597033502329e-07 epoch: 2.5776593166949358
2025-08-27 02:47:07,516 - root - INFO - TRAINER_LOGS - loss: 1.3002 grad_norm: 1.9148322343826294 learning_rate: 4.797738510267214e-07 epoch: 2.5799670001269224
2025-08-27 02:47:49,028 - root - INFO - TRAINER_LOGS - loss: 1.3374 grad_norm: 1.7572835683822632 learning_rate: 4.746144774196243e-07 epoch: 2.5822746835589094
2025-08-27 02:48:32,114 - root - INFO - TRAINER_LOGS - loss: 1.316 grad_norm: 1.7436892986297607 learning_rate: 4.69481612751676e-07 epoch: 2.584582366990896
2025-08-27 02:51:30,296 - root - INFO - TRAINER_LOGS - eval_loss: 1.3063772916793823 eval_runtime: 178.1775 eval_samples_per_second: 28.062 eval_steps_per_second: 1.173 epoch: 2.584582366990896
2025-08-27 02:52:14,536 - root - INFO - TRAINER_LOGS - loss: 1.3085 grad_norm: 1.986126184463501 learning_rate: 4.6437528709032456e-07 epoch: 2.586890050422883
2025-08-27 02:52:57,458 - root - INFO - TRAINER_LOGS - loss: 1.3048 grad_norm: 1.8780035972595215 learning_rate: 4.592955303475577e-07 epoch: 2.5891977338548697
2025-08-27 02:53:40,167 - root - INFO - TRAINER_LOGS - loss: 1.3193 grad_norm: 1.5462607145309448 learning_rate: 4.542423722797268e-07 epoch: 2.5915054172868563
2025-08-27 02:54:23,586 - root - INFO - TRAINER_LOGS - loss: 1.3007 grad_norm: 1.7938910722732544 learning_rate: 4.492158424873738e-07 epoch: 2.5938131007188434
2025-08-27 02:55:07,625 - root - INFO - TRAINER_LOGS - loss: 1.3003 grad_norm: 1.6621687412261963 learning_rate: 4.442159704150539e-07 epoch: 2.59612078415083
2025-08-27 02:55:49,467 - root - INFO - TRAINER_LOGS - loss: 1.2952 grad_norm: 1.7297366857528687 learning_rate: 4.392427853511705e-07 epoch: 2.598428467582817
2025-08-27 02:56:32,080 - root - INFO - TRAINER_LOGS - loss: 1.3105 grad_norm: 1.7597566843032837 learning_rate: 4.3429631642779414e-07 epoch: 2.6007361510148037
2025-08-27 02:57:13,726 - root - INFO - TRAINER_LOGS - loss: 1.3017 grad_norm: 1.6019341945648193 learning_rate: 4.2937659262049957e-07 epoch: 2.6030438344467903
2025-08-27 02:57:56,626 - root - INFO - TRAINER_LOGS - loss: 1.2986 grad_norm: 1.8073811531066895 learning_rate: 4.2448364274819297e-07 epoch: 2.6053515178787774
2025-08-27 02:58:39,567 - root - INFO - TRAINER_LOGS - loss: 1.3058 grad_norm: 1.8412712812423706 learning_rate: 4.196174954729432e-07 epoch: 2.6076592013107645
2025-08-27 02:59:22,040 - root - INFO - TRAINER_LOGS - loss: 1.3225 grad_norm: 2.170440435409546 learning_rate: 4.147781792998135e-07 epoch: 2.609966884742751
2025-08-27 03:00:04,199 - root - INFO - TRAINER_LOGS - loss: 1.3123 grad_norm: 1.8993839025497437 learning_rate: 4.099657225766951e-07 epoch: 2.6122745681747377
2025-08-27 03:00:47,513 - root - INFO - TRAINER_LOGS - loss: 1.3172 grad_norm: 1.7730835676193237 learning_rate: 4.051801534941413e-07 epoch: 2.6145822516067247
2025-08-27 03:01:31,356 - root - INFO - TRAINER_LOGS - loss: 1.3327 grad_norm: 1.5931732654571533 learning_rate: 4.0042150008520296e-07 epoch: 2.6168899350387114
2025-08-27 03:02:15,618 - root - INFO - TRAINER_LOGS - loss: 1.3385 grad_norm: 1.7438362836837769 learning_rate: 3.9568979022526264e-07 epoch: 2.6191976184706984
2025-08-27 03:02:58,826 - root - INFO - TRAINER_LOGS - loss: 1.3268 grad_norm: 1.9364771842956543 learning_rate: 3.9098505163187194e-07 epoch: 2.621505301902685
2025-08-27 03:03:41,845 - root - INFO - TRAINER_LOGS - loss: 1.2987 grad_norm: 1.7055528163909912 learning_rate: 3.8630731186458994e-07 epoch: 2.6238129853346717
2025-08-27 03:04:25,761 - root - INFO - TRAINER_LOGS - loss: 1.3408 grad_norm: 1.8541767597198486 learning_rate: 3.816565983248216e-07 epoch: 2.6261206687666587
2025-08-27 03:05:09,714 - root - INFO - TRAINER_LOGS - loss: 1.3449 grad_norm: 1.6875929832458496 learning_rate: 3.770329382556559e-07 epoch: 2.6284283521986453
2025-08-27 03:05:53,411 - root - INFO - TRAINER_LOGS - loss: 1.3183 grad_norm: 1.9264196157455444 learning_rate: 3.7243635874170794e-07 epoch: 2.6307360356306324
2025-08-27 03:08:51,506 - root - INFO - TRAINER_LOGS - eval_loss: 1.3063852787017822 eval_runtime: 178.09 eval_samples_per_second: 28.076 eval_steps_per_second: 1.174 epoch: 2.6307360356306324
